<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/DataScienceTutorials.jl/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/franklin.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/pure.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/side-menu.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/extra.css">
  <!-- <link rel="icon" href="/DataScienceTutorials.jl/assets/infra/favicon.gif"> -->
   <title>Fit, predict, transform</title>  
  <!-- LUNR -->
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/DataScienceTutorials.jl/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class="pure-menu-link"><strong>Home</strong></a></li>

    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/processing/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data processing</a></li>
    </ul>

    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Stacking</a></li>
    </ul>

    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>

    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> King County Houses</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Airfoil </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/powergen/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Power Generation </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-flux" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/breastcancer" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Breast Cancer</a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->
<div class="franklin-content"><h1 id="fit_predict_transform"><a href="#fit_predict_transform" class="header-anchor">Fit, predict, transform</a></h1>
<em>Download the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-fit-predict/tutorial.ipynb" target="_blank"><em>notebook</em></a>
  , the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-fit-predict/tutorial.jl" target="_blank"><em>annotated script</em></a>
   or the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-fit-predict/tutorial-raw.jl" target="_blank"><em>raw script</em></a>
   for this tutorial &#40;right-click on the relevant link and save-as&#41;. These rely on <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-fit-predict/Project.toml">this Project.toml</a> and <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-fit-predict/Manifest.toml">this Manifest.toml</a>.</em> <br/>   <em>You can also download the whole <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-fit-predict.tar.gz">project folder</a>.</em> <div class="franklin-toc"><ol><li><a href="#preliminary_steps">Preliminary steps</a><ol><li><a href="#data">Data</a></li><li><a href="#mlj_machine">MLJ Machine</a></li></ol></li><li><a href="#training_and_testing_a_supervised_model">Training and testing a supervised model</a><ol><li><a href="#splitting_the_data">Splitting the data</a></li><li><a href="#fitting_and_testing_the_machine">Fitting and testing the machine</a></li></ol></li><li><a href="#unsupervised_models">Unsupervised models</a></li></ol></div>
<p></p>
<h2 id="preliminary_steps"><a href="#preliminary_steps" class="header-anchor">Preliminary steps</a></h2>
<h3 id="data"><a href="#data" class="header-anchor">Data</a></h3>
<p>As in &quot;<a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/">choosing a model</a>&quot;, let&#39;s load the Iris dataset and unpack it:</p>
<pre><code class="language-julia">using MLJ
import Statistics
using PrettyPrinting
using StableRNGs

X, y &#61; @load_iris;</code></pre>
<p>let&#39;s also load the <code>DecisionTreeClassifier</code>:</p>
<pre><code class="language-julia">DecisionTreeClassifier &#61; @load DecisionTreeClassifier pkg&#61;DecisionTree
tree_model &#61; DecisionTreeClassifier&#40;&#41;</code></pre><pre><code class="plaintext code-output">import MLJDecisionTreeInterface ✔
DecisionTreeClassifier(
    max_depth = -1,
    min_samples_leaf = 1,
    min_samples_split = 2,
    min_purity_increase = 0.0,
    n_subfeatures = 0,
    post_prune = false,
    merge_purity_threshold = 1.0,
    pdf_smoothing = 0.0,
    display_depth = 5,
    rng = Random._GLOBAL_RNG()) @294</code></pre>
<h3 id="mlj_machine"><a href="#mlj_machine" class="header-anchor">MLJ Machine</a></h3>
<p>In MLJ, remember that a <em>model</em> is an object that only serves as a container for the hyperparameters of the model. A <em>machine</em> is an object wrapping both a model and data and can contain information on the <em>trained</em> model; it does <em>not</em> fit the model by itself. However, it does check that the model is compatible with the scientific type of the data and will warn you otherwise.</p>
<pre><code class="language-julia">tree &#61; machine&#40;tree_model, X, y&#41;</code></pre><pre><code class="plaintext code-output">Machine{DecisionTreeClassifier,…} @245 trained 0 times; caches data
  args: 
    1:	Source @048 ⏎ `ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}`
    2:	Source @704 ⏎ `AbstractVector{ScientificTypesBase.Multiclass{3}}`
</code></pre>
<p>A machine is used both for supervised and unsupervised model. In this tutorial we give an example for the supervised model first and then go on with the unsupervised case.</p>
<h2 id="training_and_testing_a_supervised_model"><a href="#training_and_testing_a_supervised_model" class="header-anchor">Training and testing a supervised model</a></h2>
<p>Now that you&#39;ve declared the model you&#39;d like to consider and the data, we are left with the standard training and testing step for a supervised learning algorithm.</p>
<h3 id="splitting_the_data"><a href="#splitting_the_data" class="header-anchor">Splitting the data</a></h3>
<p>To split the data into a <em>training</em> and <em>testing</em> set, you can use the function <code>partition</code> to obtain indices for data points that should be considered either as training or testing data:</p>
<pre><code class="language-julia">rng &#61; StableRNG&#40;566&#41;
train, test &#61; partition&#40;eachindex&#40;y&#41;, 0.7, shuffle&#61;true, rng&#61;rng&#41;
test&#91;1:3&#93;</code></pre><pre><code class="plaintext code-output">3-element Vector{Int64}:
 39
 54
  9</code></pre>
<h3 id="fitting_and_testing_the_machine"><a href="#fitting_and_testing_the_machine" class="header-anchor">Fitting and testing the machine</a></h3>
<p>To fit the machine, you can use the function <code>fit&#33;</code> specifying the rows to be used for the training:</p>
<pre><code class="language-julia">fit&#33;&#40;tree, rows&#61;train&#41;</code></pre><pre><code class="plaintext code-output">Machine{DecisionTreeClassifier,…} @245 trained 1 time; caches data
  args: 
    1:	Source @048 ⏎ `ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}`
    2:	Source @704 ⏎ `AbstractVector{ScientificTypesBase.Multiclass{3}}`
</code></pre>
<p>Note that this <strong>modifies</strong> the machine which now contains the trained parameters of the decision tree. You can inspect the result of the fitting with the <code>fitted_params</code> method:</p>
<pre><code class="language-julia">fitted_params&#40;tree&#41; |&gt; pprint</code></pre><pre><code class="plaintext code-output">(tree = Decision Tree
Leaves: 5
Depth:  4,
 encoding =
     Dict(CategoricalArrays.CategoricalValue{String, UInt32} "virginica" =>
              0x00000003,
          CategoricalArrays.CategoricalValue{String, UInt32} "setosa" =>
              0x00000001,
          CategoricalArrays.CategoricalValue{String, UInt32} "versicolor" =>
              0x00000002))</code></pre>
<p>This <code>fitresult</code> will vary from model to model though classifiers will usually give out a tuple with the first element corresponding to the fitting and the second one keeping track of how classes are named &#40;so that predictions can be appropriately named&#41;.</p>
<p>You can now use the machine to make predictions with the <code>predict</code> function specifying rows to be used for the prediction:</p>
<pre><code class="language-julia">ŷ &#61; predict&#40;tree, rows&#61;test&#41;
@show ŷ&#91;1&#93;</code></pre><pre><code class="plaintext code-output">ŷ[1] = UnivariateFinite{ScientificTypesBase.Multiclass{3}}(setosa=>1.0, versicolor=>0.0, virginica=>0.0)
</code></pre>
<p>Note that the output is <em>probabilistic</em>, effectively a vector with a score for each class. You could get the mode by using the <code>mode</code> function on <code>ŷ</code> or using <code>predict_mode</code>:</p>
<pre><code class="language-julia">ȳ &#61; predict_mode&#40;tree, rows&#61;test&#41;
@show ȳ&#91;1&#93;
@show mode&#40;ŷ&#91;1&#93;&#41;</code></pre><pre><code class="plaintext code-output">ȳ[1] = CategoricalArrays.CategoricalValue{String, UInt32} "setosa"
mode(ŷ[1]) = CategoricalArrays.CategoricalValue{String, UInt32} "setosa"
</code></pre>
<p>To measure the discrepancy between <code>ŷ</code> and <code>y</code> you could use the average cross entropy:</p>
<pre><code class="language-julia">mce &#61; cross_entropy&#40;ŷ, y&#91;test&#93;&#41; |&gt; mean
round&#40;mce, digits&#61;4&#41;</code></pre><pre><code class="plaintext code-output">2.4029</code></pre>
<h2 id="unsupervised_models"><a href="#unsupervised_models" class="header-anchor">Unsupervised models</a></h2>
<p>Unsupervised models define a <code>transform</code> method, and may optionally implement an <code>inverse_transform</code> method. As in the supervised case, we use a machine to wrap the unsupervised model and the data:</p>
<pre><code class="language-julia">v &#61; &#91;1, 2, 3, 4&#93;
stand_model &#61; UnivariateStandardizer&#40;&#41;
stand &#61; machine&#40;stand_model, v&#41;</code></pre><pre><code class="plaintext code-output">Machine{UnivariateStandardizer,…} @965 trained 0 times; caches data
  args: 
    1:	Source @714 ⏎ `AbstractVector{ScientificTypesBase.Count}`
</code></pre>
<p>We can then fit the machine and use it to apply the corresponding <em>data transformation</em>:</p>
<pre><code class="language-julia">fit&#33;&#40;stand&#41;
w &#61; transform&#40;stand, v&#41;
@show round.&#40;w, digits&#61;2&#41;
@show mean&#40;w&#41;
@show std&#40;w&#41;</code></pre><pre><code class="plaintext code-output">round.(w, digits = 2) = [-1.16, -0.39, 0.39, 1.16]
mean(w) = 0.0
std(w) = 1.0
</code></pre>
<p>In this case, the model also has an inverse transform:</p>
<pre><code class="language-julia">vv &#61; inverse_transform&#40;stand, w&#41;
sum&#40;abs.&#40;vv .- v&#41;&#41;</code></pre><pre><code class="plaintext code-output">0.0</code></pre>

<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom, Sebastian Vollmer and collaborators. Last modified: August 09, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>
  
  
      <script src="/DataScienceTutorials.jl/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
