<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/MLJTutorials/libs/highlight/github.min.css"> <link rel=stylesheet  href="/MLJTutorials/css/judoc.css"> <link rel=stylesheet  href="/MLJTutorials/css/pure.css"> <link rel=stylesheet  href="/MLJTutorials/css/side-menu.css"> <link rel=stylesheet  href="/MLJTutorials/css/extra.css"> <title></title> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/MLJTutorials/" id=menu-logo-link > <div class=menu-logo > <img id=menu-logo  alt="MLJ Logo" src="/MLJTutorials/assets/infra/MLJLogo2.svg" /> <p><strong>MLJ Tutorials</strong></p> </div> </a> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/MLJTutorials/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/choosing-a-model.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Choosing a model</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/model-tuning.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Model tuning</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/composing-models.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Composing models</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/learning-networks.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/learning-networks-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist  id=e2e> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/AMES.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> AMES</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/wine.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Wine</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/crabs-xgb.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/horse.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Horse</a> </ul> <li class=pure-menu-sublist-title ><strong>Intro to Stats Learning</strong> <ul class=pure-menu-sublist  id=isl> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 2</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-3.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 3</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-4.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 4</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-5.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 5</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-6b.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 6b</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-8.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 8</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-9.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 9</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-10.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 10</a> </ul> </ul> </div> </div> <div id=main > <div class=jd-content > <h1 id=lab_3_-_linear_regression ><a href="/MLJTutorials/pub/isl/lab-3.html#lab_3_-_linear_regression">Lab 3 - Linear Regression</a></h1> <em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/notebooks/ISL-lab-3.ipynb" target=_blank ><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/ISL-lab-3.jl" target=_blank ><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/master/scripts/ISL-lab-3.jl" target=_blank ><em>annoted script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class=jd-toc ><ol><li><a href="/MLJTutorials/pub/isl/lab-3.html#simple_linear_regression">Simple linear regression</a><li><a href="/MLJTutorials/pub/isl/lab-3.html#interaction_and_transformation">Interaction and transformation</a></ol></div><h2 id=simple_linear_regression ><a href="/MLJTutorials/pub/isl/lab-3.html#simple_linear_regression">Simple linear regression</a></h2> <code>MLJ</code> essentially serves as a unified doorway to many existing Julia packages each of which provide their own functionalities.</p> <p>The simple linear regression demonstrates this, many packages offer it &#40;beyond just using the backslash operator&#41;: here we will use <code>MLJLinearModels</code> but we could also have used <code>GLM</code>, <code>ScikitLearn</code> etc.</p> <p>To load the functionality use <code>@load ModelName pkg&#61;PackageName</code> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ

<span class=hljs-meta >@load</span> LinearRegressor pkg=MLJLinearModels</code></pre><div class=code_output ><pre><code class="plaintext hljs">LinearRegressor(fit_intercept = true,
                solver = nothing,) @ 1…17</code></pre></div> <p>Note: in order to be able to load this, you <strong>must</strong> have the relevant package in your environment, if you don&#39;t, you can always add it &#40;<code>using Pkg; Pkg.add&#40;&quot;MLJLinearModels&quot;&#41;</code>&#41;.</p> <p>Let&#39;s load the boston data set</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> RDatasets, DataFrames
boston = dataset(<span class=hljs-string >"MASS"</span>, <span class=hljs-string >"Boston"</span>)
first(boston, <span class=hljs-number >3</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">3×14 DataFrame
│ Row │ Crim    │ Zn      │ Indus   │ Chas  │ NOx     │ Rm      │ Age     │ Dis     │ Rad   │ Tax   │ PTRatio │ Black   │ LStat   │ MedV    │
│     │ Float64 │ Float64 │ Float64 │ Int64 │ Float64 │ Float64 │ Float64 │ Float64 │ Int64 │ Int64 │ Float64 │ Float64 │ Float64 │ Float64 │
├─────┼─────────┼─────────┼─────────┼───────┼─────────┼─────────┼─────────┼─────────┼───────┼───────┼─────────┼─────────┼─────────┼─────────┤
│ 1   │ 0.00632 │ 18.0    │ 2.31    │ 0     │ 0.538   │ 6.575   │ 65.2    │ 4.09    │ 1     │ 296   │ 15.3    │ 396.9   │ 4.98    │ 24.0    │
│ 2   │ 0.02731 │ 0.0     │ 7.07    │ 0     │ 0.469   │ 6.421   │ 78.9    │ 4.9671  │ 2     │ 242   │ 17.8    │ 396.9   │ 9.14    │ 21.6    │
│ 3   │ 0.02729 │ 0.0     │ 7.07    │ 0     │ 0.469   │ 7.185   │ 61.1    │ 4.9671  │ 2     │ 242   │ 17.8    │ 392.83  │ 4.03    │ 34.7    │</code></pre></div> <p>Let&#39;s get a feel for the data</p> <pre><code class="julia hljs">describe(boston, :mean, :std, :eltype)</code></pre><div class=code_output ><pre><code class="plaintext hljs">14×4 DataFrame
│ Row │ variable │ mean     │ std      │ eltype   │
│     │ Symbol   │ Float64  │ Float64  │ DataType │
├─────┼──────────┼──────────┼──────────┼──────────┤
│ 1   │ Crim     │ 3.61352  │ 8.60155  │ Float64  │
│ 2   │ Zn       │ 11.3636  │ 23.3225  │ Float64  │
│ 3   │ Indus    │ 11.1368  │ 6.86035  │ Float64  │
│ 4   │ Chas     │ 0.06917  │ 0.253994 │ Int64    │
│ 5   │ NOx      │ 0.554695 │ 0.115878 │ Float64  │
│ 6   │ Rm       │ 6.28463  │ 0.702617 │ Float64  │
│ 7   │ Age      │ 68.5749  │ 28.1489  │ Float64  │
│ 8   │ Dis      │ 3.79504  │ 2.10571  │ Float64  │
│ 9   │ Rad      │ 9.54941  │ 8.70726  │ Int64    │
│ 10  │ Tax      │ 408.237  │ 168.537  │ Int64    │
│ 11  │ PTRatio  │ 18.4555  │ 2.16495  │ Float64  │
│ 12  │ Black    │ 356.674  │ 91.2949  │ Float64  │
│ 13  │ LStat    │ 12.6531  │ 7.14106  │ Float64  │
│ 14  │ MedV     │ 22.5328  │ 9.1971   │ Float64  │</code></pre></div> <p>So there&#39;s no missing value and most variables are floating point. In MLJ it&#39;s important to specify the interpretation of the features &#40;should it be considered as a Continuous feature, as a Count, ...?&#41;, see <a href="/MLJTutorials/pub/getting-started/choosing-a-model.html#data_and_its_interpretation">this tutorial section</a> on scientific types.</p> <p>Here we will just interpret the integer features as continuous as we will just use a basic linear regression; the <code>ScientificTypes</code> package helps us with that:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> ScientificTypes
data = coerce(boston, :Tax=&gt;Continuous, :Rad=&gt;Continuous);</code></pre> <p>Let&#39;s also extract the target variable &#40;<code>MedV</code>&#41;:</p> <pre><code class="julia hljs">y = data.MedV
X = select(data, Not(:MedV));</code></pre> <p>Let&#39;s declare a simple multivariate linear regression model:</p> <pre><code class="julia hljs">mdl = LinearRegressor()</code></pre><div class=code_output ><pre><code class="plaintext hljs">LinearRegressor(fit_intercept = true,
                solver = nothing,) @ 9…48</code></pre></div> <p>In order to fit it on the data, we need to wrap it in a <em>machine</em> which, in MLJ, is the composition of a model and data to apply the model on:</p> <pre><code class="julia hljs">mach = machine(mdl, X, y)
fit!(mach)</code></pre><div class=code_output ><pre><code class="plaintext hljs">Machine{LinearRegressor} @ 1…27
</code></pre></div> <p>The <code>fit&#33;</code> operation trains the model on the data and the results are kept inside of the machine. In this case we have trained it on the whole data. You can retrieve the fitted parameters using <code>fitted_params</code>:</p> <pre><code class="julia hljs">fp = fitted_params(mach)
<span class=hljs-meta >@show</span> round.(fp.coefs[<span class=hljs-number >1</span>:<span class=hljs-number >3</span>], sigdigits=<span class=hljs-number >3</span>)
<span class=hljs-meta >@show</span> round(fp.intercept, sigdigits=<span class=hljs-number >3</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">round.(fp.coefs[1:3], sigdigits=3) = [-0.108, 0.0464, 0.0206]
round(fp.intercept, sigdigits=3) = 36.5
</code></pre></div> <p>You can use the <code>machine</code> in order to <em>predict</em> values as well and, for instance, compute the root mean squared error:</p> <pre><code class="julia hljs">ŷ = predict(mach, X)
round(rms(ŷ, y), sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">4.679</code></pre></div>
<h2 id=interaction_and_transformation ><a href="/MLJTutorials/pub/isl/lab-3.html#interaction_and_transformation">Interaction and transformation</a></h2>
<p>Let&#39;s say we want to also consider an interaction term of <code>lstat</code> and <code>age</code> taken together. To do this, just create a new dataframe with an additional column corresponding to the interaction term:</p>
<pre><code class="julia hljs">X2 = hcat(X, X.LStat .* X.Age);</code></pre>
<p>So here we have a DataFrame with one extra column corresponding to the elementwise products between <code>:LStat</code> and <code>Age</code>. DataFrame gives this a default name &#40;<code>:x1</code>&#41; which we can change:</p>
<pre><code class="julia hljs">rename!(X2, :x1 =&gt; :interaction);</code></pre>
<p>Ok cool, now let&#39;s try the linear regression again</p>
<pre><code class="julia hljs">mach = machine(mdl, X2, y)
fit!(mach)
ŷ = predict(mach, X2)
round(rms(ŷ, y), sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">4.676</code></pre></div>
<p>We get slightly better results but nothing spectacular.</p>
<p>Let&#39;s get back to the lab where they consider regressing the target variable on <code>lstat</code> and <code>lstat^2</code>; again, it&#39;s essentially a case of defining the right DataFrame:</p>
<pre><code class="julia hljs">X3 = hcat(X.LStat, X.LStat.^<span class=hljs-number >2</span>)
machine(mdl, X3, y)
fit!(mach)
ŷ = predict(mach, X3)
round(rms(ŷ, y), sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">28.56</code></pre></div>
<p>Unsurprisingly  the results are much  worse since we use far less information than before.
<div class=page-foot >
  <div class=copyright >
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: November 08, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>

      </div> 
  </div> 
  <script src="/MLJTutorials/libs/pure/ui.min.js"></script>