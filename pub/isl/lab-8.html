<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/MLJTutorials/libs/highlight/github.min.css"> <link rel=stylesheet  href="/MLJTutorials/css/judoc.css"> <link rel=stylesheet  href="/MLJTutorials/css/pure.css"> <link rel=stylesheet  href="/MLJTutorials/css/side-menu.css"> <link rel=stylesheet  href="/MLJTutorials/css/extra.css"> <title></title> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/MLJTutorials/" id=menu-logo-link > <div class=menu-logo > <img id=menu-logo  alt="MLJ Logo" src="/MLJTutorials/assets/infra/MLJLogo2.svg" /> <p><strong>MLJ Tutorials</strong></p> </div> </a> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/MLJTutorials/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/choosing-a-model.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Choosing a model</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/model-tuning.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Model tuning</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/composing-models.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Composing models</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/learning-networks.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/learning-networks-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist  id=e2e> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/AMES.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> AMES</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/wine.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Wine</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/crabs-xgb.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/horse.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Horse</a> </ul> <li class=pure-menu-sublist-title ><strong>Intro to Stats Learning</strong> <ul class=pure-menu-sublist  id=isl> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 2</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-3.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 3</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-4.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 4</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-5.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 5</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-6b.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 6b</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-8.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 8</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-9.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 9</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-10.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 10</a> </ul> </ul> </div> </div> <div id=main > <div class=jd-content > <h1 id=lab_8_-_tree-based_models ><a href="/MLJTutorials/pub/isl/lab-8.html#lab_8_-_tree-based_models">Lab 8 - Tree-based models</a></h1> <em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/notebooks/ISL-lab-8.ipynb" target=_blank ><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/ISL-lab-8.jl" target=_blank ><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/master/scripts/ISL-lab-8.jl" target=_blank ><em>annoted script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class=jd-toc ><ol><li><a href="/MLJTutorials/pub/isl/lab-8.html#getting_started">Getting started</a><ol><li><a href="/MLJTutorials/pub/isl/lab-8.html#decision_tree_classifier">Decision Tree Classifier</a><li><a href="/MLJTutorials/pub/isl/lab-8.html#tuning_a_dtc">Tuning a DTC</a><li><a href="/MLJTutorials/pub/isl/lab-8.html#decision_tree_regressor">Decision Tree Regressor</a></ol><li><a href="/MLJTutorials/pub/isl/lab-8.html#random_forest">Random Forest</a><li><a href="/MLJTutorials/pub/isl/lab-8.html#gradient_boosting_machine">Gradient Boosting Machine</a></ol></div><h2 id=getting_started ><a href="/MLJTutorials/pub/isl/lab-8.html#getting_started">Getting started</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ, RDatasets, PrettyPrinting, ScientificTypes

<span class=hljs-meta >@load</span> DecisionTreeClassifier pkg=DecisionTree

carseats = dataset(<span class=hljs-string >"ISLR"</span>, <span class=hljs-string >"Carseats"</span>)

first(carseats, <span class=hljs-number >3</span>) |&gt; pretty</code></pre><div class=code_output ><pre><code class="plaintext hljs">┌────────────┬────────────┬────────────┬─────────────┬────────────┬────────────┬──────────────────────────┬────────────┬────────────┬──────────────────────────┬──────────────────────────┐
│ Sales      │ CompPrice  │ Income     │ Advertising │ Population │ Price      │ ShelveLoc                │ Age        │ Education  │ Urban                    │ US                       │
│ Float64    │ Float64    │ Float64    │ Float64     │ Float64    │ Float64    │ CategoricalString{UInt8} │ Float64    │ Float64    │ CategoricalString{UInt8} │ CategoricalString{UInt8} │
│ Continuous │ Continuous │ Continuous │ Continuous  │ Continuous │ Continuous │ Multiclass{3}            │ Continuous │ Continuous │ Multiclass{2}            │ Multiclass{2}            │
├────────────┼────────────┼────────────┼─────────────┼────────────┼────────────┼──────────────────────────┼────────────┼────────────┼──────────────────────────┼──────────────────────────┤
│ 9.5        │ 138.0      │ 73.0       │ 11.0        │ 276.0      │ 120.0      │ Bad                      │ 42.0       │ 17.0       │ Yes                      │ Yes                      │
│ 11.22      │ 111.0      │ 48.0       │ 16.0        │ 260.0      │ 83.0       │ Good                     │ 65.0       │ 10.0       │ Yes                      │ Yes                      │
│ 10.06      │ 113.0      │ 35.0       │ 10.0        │ 269.0      │ 80.0       │ Medium                   │ 59.0       │ 12.0       │ Yes                      │ Yes                      │
└────────────┴────────────┴────────────┴─────────────┴────────────┴────────────┴──────────────────────────┴────────────┴────────────┴──────────────────────────┴──────────────────────────┘
</code></pre></div> <p>We encode a new variable <code>High</code> based on whether the sales are higher or lower than 8 and add that column to the dataframe:</p> <pre><code class="julia hljs">High = ifelse.(carseats.Sales .&lt;= <span class=hljs-number >8</span>, <span class=hljs-string >"No"</span>, <span class=hljs-string >"Yes"</span>) |&gt; categorical;
carseats[!, :High] = High;</code></pre> <p>Let&#39;s now train a basic decision tree classifier for <code>High</code> given the other features after one-hot-encoding the categorical features:</p> <pre><code class="julia hljs">X = select(carseats, Not([:Sales, :High]))
y = carseats.High;</code></pre> <h3 id=decision_tree_classifier ><a href="/MLJTutorials/pub/isl/lab-8.html#decision_tree_classifier">Decision Tree Classifier</a></h3> <pre><code class="julia hljs"><span class=hljs-meta >@pipeline</span> HotTreeClf(hot = OneHotEncoder(),
                     tree = DecisionTreeClassifier()) is_probabilistic=<span class=hljs-literal >true</span>

mdl = HotTreeClf()
mach = machine(mdl, X, y)
fit!(mach);</code></pre> <p>Note that this is trained on the whole data.</p> <pre><code class="julia hljs">ypred = predict_mode(mach, X)
misclassification_rate(ypred, y)</code></pre><div class=code_output ><pre><code class="plaintext hljs">0.0</code></pre></div>
<p>That&#39;s right... it gets it perfectly; this tends to be classic behaviour for a DTC to overfit the data it&#39;s trained on. Let&#39;s see if it generalises:</p>
<pre><code class="julia hljs">train, test = partition(eachindex(y), <span class=hljs-number >0.5</span>, shuffle=<span class=hljs-literal >true</span>, rng=<span class=hljs-number >333</span>)
fit!(mach, rows=train)
ypred = predict_mode(mach, rows=test)
misclassification_rate(ypred, y[test])</code></pre><div class=code_output ><pre><code class="plaintext hljs">0.29</code></pre></div>
<p>Not really...</p>
<h3 id=tuning_a_dtc ><a href="/MLJTutorials/pub/isl/lab-8.html#tuning_a_dtc">Tuning a DTC</a></h3>
<p>Let&#39;s try to do a bit of tuning</p>
<pre><code class="julia hljs">r_mpi = range(mdl, :(tree.max_depth), lower=<span class=hljs-number >1</span>, upper=<span class=hljs-number >10</span>)
r_msl = range(mdl, :(tree.min_samples_leaf), lower=<span class=hljs-number >1</span>, upper=<span class=hljs-number >50</span>)

tm = TunedModel(model=mdl, ranges=[r_mpi, r_msl], tuning=Grid(resolution=<span class=hljs-number >8</span>),
                resampling=CV(nfolds=<span class=hljs-number >5</span>, rng=<span class=hljs-number >112</span>),
                operation=predict_mode, measure=misclassification_rate)
mtm = machine(tm, X, y)
fit!(mtm, rows=train)

ypred = predict_mode(mtm, rows=test)
misclassification_rate(ypred, y[test])</code></pre><div class=code_output ><pre><code class="plaintext hljs">0.32</code></pre></div>
<p>We can inspect the parameters of the best model</p>
<pre><code class="julia hljs">fitted_params(mtm).best_model.tree</code></pre><div class=code_output ><pre><code class="plaintext hljs">DecisionTreeClassifier(pruning_purity = 1.0,
                       max_depth = 1,
                       min_samples_leaf = 1,
                       min_samples_split = 2,
                       min_purity_increase = 0.0,
                       n_subfeatures = 0,
                       display_depth = 5,
                       post_prune = false,
                       merge_purity_threshold = 0.9,
                       pdf_smoothing = 0.05,) @ 1…12</code></pre></div>
<h3 id=decision_tree_regressor ><a href="/MLJTutorials/pub/isl/lab-8.html#decision_tree_regressor">Decision Tree Regressor</a></h3>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> DecisionTreeRegressor pkg=DecisionTree

boston = dataset(<span class=hljs-string >"MASS"</span>, <span class=hljs-string >"Boston"</span>)

y, X = unpack(boston, ==(:MedV), col -&gt; <span class=hljs-literal >true</span>)

train, test = partition(eachindex(y), <span class=hljs-number >0.5</span>, shuffle=<span class=hljs-literal >true</span>, rng=<span class=hljs-number >551</span>);

scitype(X)</code></pre><div class=code_output ><pre><code class="plaintext hljs">Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}</code></pre></div>
<p>Let&#39;s recode the Count as Continuous and then fit a DTR</p>
<pre><code class="julia hljs">X = coerce(X, autotype(X, rules=(:discrete_to_continuous,)))

dtr_model = DecisionTreeRegressor()
dtr = machine(dtr_model, X, y)

fit!(dtr, rows=train)

ypred = predict(dtr, rows=test)
round(rms(ypred, y[test]), sigdigits=<span class=hljs-number >3</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">4.98</code></pre></div>
<p>Again we can try tuning this a bit, since it&#39;s the same idea as before, let&#39;s just try to adjust the depth of the tree:</p>
<pre><code class="julia hljs">r_depth = range(dtr_model, :max_depth, lower=<span class=hljs-number >2</span>, upper=<span class=hljs-number >20</span>)

tm = TunedModel(model=dtr_model, ranges=[r_depth], tuning=Grid(resolution=<span class=hljs-number >10</span>),
                resampling=CV(nfolds=<span class=hljs-number >5</span>, rng=<span class=hljs-number >1254</span>), measure=rms)
mtm = machine(tm, X, y)

fit!(mtm, rows=train)

ypred = predict(mtm, rows=test)
round(rms(ypred, y[test]), sigdigits=<span class=hljs-number >3</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">5.09</code></pre></div>
<h2 id=random_forest ><a href="/MLJTutorials/pub/isl/lab-8.html#random_forest">Random Forest</a></h2>
<p><strong>Note</strong>: the package DecisionTree.jl also has a RandomForest model but it is not yet interfaced with in MLJ.</p>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> RandomForestRegressor pkg=ScikitLearn

rf_mdl = RandomForestRegressor()
rf = machine(rf_mdl, X, y)
fit!(rf, rows=train)

ypred = predict(rf, rows=test)
round(rms(ypred, y[test]), sigdigits=<span class=hljs-number >3</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">3.78</code></pre></div>
<h2 id=gradient_boosting_machine ><a href="/MLJTutorials/pub/isl/lab-8.html#gradient_boosting_machine">Gradient Boosting Machine</a></h2>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> XGBoostRegressor

xgb_mdl = XGBoostRegressor(num_round=<span class=hljs-number >10</span>, max_depth=<span class=hljs-number >10</span>)
xgb = machine(xgb_mdl, X, y)
fit!(xgb, rows=train)

ypred = predict(xgb, rows=test)
round(rms(ypred, y[test]), sigdigits=<span class=hljs-number >3</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">3.96</code></pre></div>
<p>Again we could do some tuning for this.
<div class=page-foot >
  <div class=copyright >
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: November 18, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>

      </div> 
  </div> 
  <script src="/MLJTutorials/libs/pure/ui.min.js"></script>