<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/MLJTutorials/libs/katex/katex.min.css"> <link rel=stylesheet  href="/MLJTutorials/libs/highlight/github.min.css"> <link rel=stylesheet  href="/MLJTutorials/css/judoc.css"> <link rel=stylesheet  href="/MLJTutorials/css/pure.css"> <link rel=stylesheet  href="/MLJTutorials/css/side-menu.css"> <link rel=stylesheet  href="/MLJTutorials/css/extra.css"> <title></title> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/MLJTutorials/" id=menu-logo-link > <div class=menu-logo > <img id=menu-logo  alt="MLJ Logo" src="/MLJTutorials/assets/infra/MLJLogo2.svg" /> <p><strong>MLJ Tutorials</strong></p> </div> </a> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/MLJTutorials/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/choosing-a-model.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Choosing a model</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/model-tuning.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Model tuning</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/composing-models.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Composing models</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/learning-networks.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/learning-networks-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist  id=e2e> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/AMES.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> AMES</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/wine.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Wine</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/crabs-xgb.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/horse.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Horse</a> </ul> <li class=pure-menu-sublist-title ><strong>Intro to Stats Learning</strong> <ul class=pure-menu-sublist  id=isl> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 2</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-3.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 3</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-4.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 4</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-5.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 5</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-6b.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 6b</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-8.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 8</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/isl/lab-9.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 9</a> </ul> </ul> </div> </div> <div id=main > <div class=jd-content > <h1 id=lab_6b_-_ridge_and_lasso_regression ><a href="/MLJTutorials/pub/isl/lab-6b.html#lab_6b_-_ridge_and_lasso_regression">Lab 6b - Ridge and Lasso regression</a></h1> <em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/notebooks/ISL-lab-6b.ipynb" target=_blank ><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/ISL-lab-6b.jl" target=_blank ><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/master/scripts/ISL-lab-6b.jl" target=_blank ><em>annoted script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class=jd-toc ><ol><li><a href="/MLJTutorials/pub/isl/lab-6b.html#getting_started">Getting started</a><li><a href="/MLJTutorials/pub/isl/lab-6b.html#ridge_pipeline">Ridge pipeline</a><ol><li><a href="/MLJTutorials/pub/isl/lab-6b.html#baseline">Baseline</a><li><a href="/MLJTutorials/pub/isl/lab-6b.html#basic_ridge">Basic ridge</a><li><a href="/MLJTutorials/pub/isl/lab-6b.html#cross_validating">Cross validating</a></ol><li><a href="/MLJTutorials/pub/isl/lab-6b.html#lasso_pipeline">Lasso pipeline</a><li><a href="/MLJTutorials/pub/isl/lab-6b.html#elastic_net_pipeline">Elastic net pipeline</a></ol></div><h2 id=getting_started ><a href="/MLJTutorials/pub/isl/lab-6b.html#getting_started">Getting started</a></h2> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ, RDatasets, ScientificTypes, PrettyPrinting

<span class=hljs-meta >@load</span> LinearRegressor pkg=MLJLinearModels
<span class=hljs-meta >@load</span> RidgeRegressor pkg=MLJLinearModels
<span class=hljs-meta >@load</span> LassoRegressor pkg=MLJLinearModels

hitters = dataset(<span class=hljs-string >"ISLR"</span>, <span class=hljs-string >"Hitters"</span>)
<span class=hljs-meta >@show</span> size(hitters)
names(hitters) |&gt; pprint</code></pre><div class=code_output ><pre><code class="plaintext hljs">size(hitters) = (322, 20)
[:AtBat,
 :Hits,
 :HmRun,
 :Runs,
 :RBI,
 :Walks,
 :Years,
 :CAtBat,
 :CHits,
 :CHmRun,
 :CRuns,
 :CRBI,
 :CWalks,
 :League,
 :Division,
 :PutOuts,
 :Assists,
 :Errors,
 :Salary,
 :NewLeague]
</code></pre></div> <p>The target is <code>Salary</code> <pre><code class="julia hljs">y, X = unpack(hitters, ==(:Salary), col-&gt;<span class=hljs-literal >true</span>);</code></pre>
<p>It has missing values which we will just ignore:</p>
<pre><code class="julia hljs">no_miss = .!ismissing.(y)
y = collect(skipmissing(y))
X = X[no_miss, :]
train, test = partition(eachindex(y), <span class=hljs-number >0.5</span>, shuffle=<span class=hljs-literal >true</span>, rng=<span class=hljs-number >424</span>);</code></pre>
<p>Most features are currently encoded as integers but we will consider them as continuous</p>
<pre><code class="julia hljs">Xc = coerce(X, autotype(X, rules=(:discrete_to_continuous,)))
scitype(Xc)</code></pre><div class=code_output ><pre><code class="plaintext hljs">Table{Union{AbstractArray{Continuous,1}, AbstractArray{Multiclass{2},1}}}</code></pre></div>
<p>There&#39;re a few features that are categorical which we&#39;ll one-hot-encode.</p>
<h2 id=ridge_pipeline ><a href="/MLJTutorials/pub/isl/lab-6b.html#ridge_pipeline">Ridge pipeline</a></h2>  <h3 id=baseline ><a href="/MLJTutorials/pub/isl/lab-6b.html#baseline">Baseline</a></h3>
<p>Let&#39;s first fit a simple pipeline with a standardizer, a one-hot-encoder and a basic linear regression:</p>
<pre><code class="julia hljs"><span class=hljs-meta >@pipeline</span> RegPipe(std = Standardizer(),
                  hot = OneHotEncoder(),
                  reg = LinearRegressor())

model = RegPipe()
pipe  = machine(model, Xc, y)
fit!(pipe, rows=train)
ŷ = predict(pipe, rows=test)
round(rms(ŷ, y[test])^<span class=hljs-number >2</span>, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">123500.0</code></pre></div>
<h3 id=basic_ridge ><a href="/MLJTutorials/pub/isl/lab-6b.html#basic_ridge">Basic ridge</a></h3>
<p>Let&#39;s now swap the linear regressor for a ridge one without specifying the penalty &#40;<code>1</code> by default&#41;:</p>
<pre><code class="julia hljs">pipe.model.reg = RidgeRegressor()
fit!(pipe, rows=train)
ŷ = predict(pipe, rows=test)
round(rms(ŷ, y[test])^<span class=hljs-number >2</span>, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">109600.0</code></pre></div>
<p>Ok that&#39;s a bit better but surely we can do better with an appropriate selection of the hyperparameter.</p>
<h3 id=cross_validating ><a href="/MLJTutorials/pub/isl/lab-6b.html#cross_validating">Cross validating</a></h3>
<p>What penalty should you use? Let&#39;s do a simple CV to try  to find out:</p>
<pre><code class="julia hljs">r  = range(model, :(reg.lambda), lower=<span class=hljs-number >1e-2</span>, upper=<span class=hljs-number >100_000</span>, scale=:log10)
tm = TunedModel(model=model, ranges=r, tuning=Grid(resolution=<span class=hljs-number >50</span>),
                resampling=CV(nfolds=<span class=hljs-number >3</span>, rng=<span class=hljs-number >4141</span>), measure=rms)
mtm = machine(tm, Xc, y)
fit!(mtm, rows=train)

best_mdl = fitted_params(mtm).best_model
round(best_mdl.reg.lambda, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">19.31</code></pre></div>
<p>right, and  with that we get:</p>
<pre><code class="julia hljs">ŷ = predict(mtm, rows=test)
round(rms(ŷ, y[test])^<span class=hljs-number >2</span>, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">93380.0</code></pre></div>
<h2 id=lasso_pipeline ><a href="/MLJTutorials/pub/isl/lab-6b.html#lasso_pipeline">Lasso pipeline</a></h2>
<p>Let&#39;s do the same as above but using a Lasso model and adjusting the range a bit:</p>
<pre><code class="julia hljs">mtm.model.model.reg = LassoRegressor()
mtm.model.ranges = range(model, :(reg.lambda), lower=<span class=hljs-number >500</span>, upper=<span class=hljs-number >100_000</span>, scale=:log10)
fit!(mtm, rows=train)

best_mdl = fitted_params(mtm).best_model
round(best_mdl.reg.lambda, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">1830.0</code></pre></div>
<p>Ok and let&#39;s see how that does:</p>
<pre><code class="julia hljs">ŷ = predict(mtm, rows=test)
round(rms(ŷ, y[test])^<span class=hljs-number >2</span>, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">96730.0</code></pre></div>
<p>Pretty good&#33; and the parameters are reasonably sparse as expected:</p>
<pre><code class="julia hljs">coefs = mtm.fitresult.fitresult.machine.fitresult
round.(coefs, sigdigits=<span class=hljs-number >2</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">23-element Array{Float64,1}:
  -0.0
   0.0
  -0.0
  86.0
  -0.0
  38.0
  -0.0
   0.0
 150.0
  -0.0
   0.0
  33.0
  -0.0
  -9.5
   5.0
   7.9
 -81.0
  68.0
   0.0
  -3.3
  -0.0
   0.0
 580.0</code></pre></div>
<p>with around 50&#37; sparsity:</p>
<pre><code class="julia hljs">sum(coefs .≈ <span class=hljs-number >0</span>) / length(coefs)</code></pre><div class=code_output ><pre><code class="plaintext hljs">0.5217391304347826</code></pre></div>
<h2 id=elastic_net_pipeline ><a href="/MLJTutorials/pub/isl/lab-6b.html#elastic_net_pipeline">Elastic net pipeline</a></h2>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> ElasticNetRegressor pkg=MLJLinearModels

mtm.model.model.reg = ElasticNetRegressor()
mtm.model.ranges = [range(model, :(reg.lambda), lower=<span class=hljs-number >0.1</span>, upper=<span class=hljs-number >100</span>, scale=:log10),
                    range(model, :(reg.gamma),  lower=<span class=hljs-number >500</span>, upper=<span class=hljs-number >10_000</span>, scale=:log10)]
mtm.model.tuning = Grid(resolution=<span class=hljs-number >10</span>)
fit!(mtm, rows=train)

best_mdl = fitted_params(mtm).best_model
<span class=hljs-meta >@show</span> round(best_mdl.reg.lambda, sigdigits=<span class=hljs-number >4</span>)
<span class=hljs-meta >@show</span> round(best_mdl.reg.gamma, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">round(best_mdl.reg.lambda, sigdigits=4) = 21.54
round(best_mdl.reg.gamma, sigdigits=4) = 1357.0
</code></pre></div>
<p>And it&#39;s not too bad in terms of accuracy either</p>
<pre><code class="julia hljs">ŷ = predict(mtm, rows=test)
round(rms(ŷ, y[test])^<span class=hljs-number >2</span>, sigdigits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">95640.0</code></pre></div>
<p>But the simple ridge regression seems to work best here.
<div class=page-foot >
  <div class=copyright >
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: November 15, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>

      </div> 
  </div> 
  <script src="/MLJTutorials/libs/pure/ui.min.js"></script>