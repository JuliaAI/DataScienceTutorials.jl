<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
   
  <link rel="stylesheet" href="/css/judoc.css">
  <link rel="stylesheet" href="/css/pure.css">
  <link rel="stylesheet" href="/css/side-menu.css">
  <link rel="stylesheet" href="/css/extra.css">
  <!-- <link rel="icon" href="/assets/infra/favicon.gif"> -->
   <title></title>  
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/" id="menu-logo-link">
          <div class="menu-logo">
            <img id="menu-logo" alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" />
            <p><strong>MLJ Tutorials</strong></p>
          </div>
        </a>
        <ul class="pure-menu-list">
          <li class="pure-menu-item pure-menu-top-item "><a href="/" class="pure-menu-link"><strong>Home</strong></a></li>

          <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/data/loading.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
            <li class="pure-menu-item "><a href="/pub/data/dataframe.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> DataFrame</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/getting-started/choosing-a-model.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/fit-and-predict.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/model-tuning.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/ensembles.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/ensembles-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/composing-models.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
          <ul class="pure-menu-sublist" id=isl>
            <li class="pure-menu-item "><a href="/pub/isl/lab-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-3.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-4.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-5.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-6b.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-8.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-9.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-10.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
          <ul class="pure-menu-sublist" id=e2e>
            <li class="pure-menu-item "><a href="/pub/end-to-end/AMES.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/wine.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/crabs-xgb.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/horse.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
          </ul>
        </ul>
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->

<div class="jd-content">
<h1 id="lab_10_-_pca_and_clustering"><a href="/pub/isl/lab-10.html#lab_10_-_pca_and_clustering">Lab 10 - PCA and Clustering</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/notebooks/ISL-lab-10.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/ISL-lab-10-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/ISL-lab-10.jl" target="_blank"><em>annoted script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="jd-toc"><ol><li><a href="/pub/isl/lab-10.html#getting_started">Getting started</a></li><li><a href="/pub/isl/lab-10.html#pca_pipeline">PCA pipeline</a></li><li><a href="/pub/isl/lab-10.html#more_interesting_data">More interesting data...</a><ol><li><a href="/pub/isl/lab-10.html#pca_pipeline__2">PCA pipeline</a></li><li><a href="/pub/isl/lab-10.html#clustering">Clustering</a></li></ol></li></ol></div><h2 id="getting_started"><a href="/pub/isl/lab-10.html#getting_started">Getting started</a></h2>
<pre><code class="language-julia">using MLJ, RDatasets, Random

data = dataset("datasets", "USArrests")
names(data)</code></pre><div class="code_output"><pre><code class="plaintext">5-element Array{Symbol,1}:
 :State
 :Murder
 :Assault
 :UrbanPop
 :Rape</code></pre></div>
<p>Let&#39;s have a look at the mean and standard deviation of each feature:</p>
<pre><code class="language-julia">describe(data, :mean, :std)</code></pre><div class="code_output"><pre><code class="plaintext">5×3 DataFrame
│ Row │ variable │ mean   │ std     │
│     │ Symbol   │ Union… │ Union…  │
├─────┼──────────┼────────┼─────────┤
│ 1   │ State    │        │         │
│ 2   │ Murder   │ 7.788  │ 4.35551 │
│ 3   │ Assault  │ 170.76 │ 83.3377 │
│ 4   │ UrbanPop │ 65.54  │ 14.4748 │
│ 5   │ Rape     │ 21.232 │ 9.36638 │</code></pre></div>
<p>Let&#39;s extract the numerical component and coerce</p>
<pre><code class="language-julia">X = select(data, Not(:State))
X = coerce(X, :UrbanPop=>Continuous);</code></pre>
<h2 id="pca_pipeline"><a href="/pub/isl/lab-10.html#pca_pipeline">PCA pipeline</a></h2>
<p>PCA is usually best done after standardization but we won&#39;t do it here:</p>
<pre><code class="language-julia">@load PCA pkg=MultivariateStats

pca_mdl = PCA(pratio=1)
pca = machine(pca_mdl, X)
fit!(pca)

W = transform(pca, X);</code></pre>
<p>W is the PCA&#39;d data; here we&#39;ve used default settings for PCA and it has recovered 2 components:</p>
<pre><code class="language-julia">schema(W).names</code></pre><div class="code_output"><pre><code class="plaintext">(:x1, :x2, :x3, :x4)</code></pre></div>
<p>Let&#39;s inspect the fit:</p>
<pre><code class="language-julia">r = report(pca)
cumsum(r.principalvars ./ r.tvar)</code></pre><div class="code_output"><pre><code class="plaintext">4-element Array{Float64,1}:
 0.9655342205668823
 0.9933515571990573
 0.9991510921213993
 1.0</code></pre></div>
<p>In the second line we look at the explained variance with 1 then 2 PCA features and it seems that with 2 we almost completely recover all of the variance.</p>
<h2 id="more_interesting_data"><a href="/pub/isl/lab-10.html#more_interesting_data">More interesting data...</a></h2>
<p>Instead of just playing with toy data, let&#39;s load the orange juice data and extract only the columns corresponding to price data:</p>
<pre><code class="language-julia">data = dataset("ISLR", "OJ")

X = select(data, [:PriceCH, :PriceMM, :DiscCH, :DiscMM, :SalePriceMM,
                  :SalePriceCH, :PriceDiff, :PctDiscMM, :PctDiscCH]);</code></pre>
<h3 id="pca_pipeline__2"><a href="/pub/isl/lab-10.html#pca_pipeline__2">PCA pipeline</a></h3>
<pre><code class="language-julia">Random.seed!(1515)

@pipeline SPCA(std = Standardizer(),
               pca = PCA(pratio=1-1e-4))
spca_mdl = SPCA()
spca = machine(spca_mdl, X)
fit!(spca)
W = transform(spca, X)
names(W)</code></pre><div class="code_output"><pre><code class="plaintext">6-element Array{Symbol,1}:
 :x1
 :x2
 :x3
 :x4
 :x5
 :x6</code></pre></div>
<p>What kind of variance can we explain?</p>
<pre><code class="language-julia">r  = report(spca).reports[1]
cs = cumsum(r.principalvars ./ r.tvar)</code></pre><div class="code_output"><pre><code class="plaintext">6-element Array{Float64,1}:
 0.4174696748484731
 0.7233074812209765
 0.9436456234171869
 0.9997505816044248
 0.9998956501446636
 0.9999999999999998</code></pre></div>
<p>Let&#39;s visualise this</p>
<pre><code class="language-julia">using PyPlot

figure(figsize=(8,6))

bar(1:length(cs), cs)
plot(1:length(cs), cs, color="red", marker="o")

xlabel("Number of PCA features", fontsize=14)
ylabel("Ratio of explained variance", fontsize=14)
</code></pre>
<p><img src="/assets/literate/ISL-lab-10-g1.svg" alt="PCA explained variance" /></p>
<p>So 4 PCA features are enough to recover most of the variance.</p>
<h3 id="clustering"><a href="/pub/isl/lab-10.html#clustering">Clustering</a></h3>
<pre><code class="language-julia">Random.seed!(1515)

@load KMeans
@pipeline SPCA2(std = Standardizer(),
                pca = PCA(),
                km = KMeans(k=3))

spca2_mdl = SPCA2()
spca2 = machine(spca2_mdl, X)
fit!(spca2)

assignments = report(spca2).reports[1].assignments
mask1 = assignments .== 1
mask2 = assignments .== 2
mask3 = assignments .== 3;</code></pre>
<p>Now we can  try visualising this</p>
<pre><code class="language-julia">using PyPlot

figure(figsize=(8, 6))
for (m, c) in zip((mask1, mask2, mask3), ("red", "green", "blue"))
    plot(W[m, 1], W[m, 2], ls="none", marker=".", markersize=10, color=c)
end

xlabel("PCA-1", fontsize=13)
ylabel("PCA-2", fontsize=13)
legend(["Group 1", "Group 2", "Group 3"], fontsize=13)
</code></pre>
<p><img src="/assets/literate/ISL-lab-10-cluster.svg" alt="" />
<div class="page-foot">
  <div class="copyright">
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: November 18, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>
<!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/libs/pure/ui.min.js"></script>
  
  
      <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
