<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
   
  <link rel="stylesheet" href="/css/judoc.css">
  <link rel="stylesheet" href="/css/pure.css">
  <link rel="stylesheet" href="/css/side-menu.css">
  <link rel="stylesheet" href="/css/extra.css">
  <!-- <link rel="icon" href="/assets/infra/favicon.gif"> -->
   <title></title>  
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/" id="menu-logo-link">
          <div class="menu-logo">
            <img id="menu-logo" alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" />
            <p><strong>MLJ Tutorials</strong></p>
          </div>
        </a>
        <ul class="pure-menu-list">
          <li class="pure-menu-item pure-menu-top-item "><a href="/" class="pure-menu-link"><strong>Home</strong></a></li>

          <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/data/loading.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
            <li class="pure-menu-item "><a href="/pub/data/dataframe.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> DataFrame</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/getting-started/choosing-a-model.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/fit-and-predict.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/model-tuning.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/ensembles.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
            <li class="pure-menu-item pure-menu-selected"><a href="/pub/getting-started/ensembles-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/composing-models.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
          <ul class="pure-menu-sublist" id=isl>
            <li class="pure-menu-item "><a href="/pub/isl/lab-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-3.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-4.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-5.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-6b.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-8.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-9.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-10.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
          <ul class="pure-menu-sublist" id=e2e>
            <li class="pure-menu-item "><a href="/pub/end-to-end/AMES.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/wine.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/crabs-xgb.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/horse.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
          </ul>
        </ul>
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->

<div class="jd-content">
<h1 id="ensemble_models_2"><a href="/pub/getting-started/ensembles-2.html#ensemble_models_2">Ensemble models &#40;2&#41;</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/notebooks/A-ensembles-2.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/A-ensembles-2-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/A-ensembles-2.jl" target="_blank"><em>annoted script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="jd-toc"><ol><li><a href="/pub/getting-started/ensembles-2.html#prelims">Prelims</a></li><li><a href="/pub/getting-started/ensembles-2.html#random_forest">Random forest</a><ol><li><a href="/pub/getting-started/ensembles-2.html#tuning">Tuning</a></li><li><a href="/pub/getting-started/ensembles-2.html#reporting">Reporting</a></li></ol></li></ol></div><h2 id="prelims"><a href="/pub/getting-started/ensembles-2.html#prelims">Prelims</a></h2>
<p>This tutorial builds upon the previous ensemble tutorial with a home-made Random Forest regressor on the &quot;boston&quot; dataset.</p>
<pre><code class="language-julia">using MLJ, PyPlot, PrettyPrinting, Random,
      DataFrames

X, y = @load_boston
sch = schema(X)
p = length(sch.names)
n = sch.nrows
@show (n, p)
describe(y)</code></pre><div class="code_output"><pre><code class="plaintext">(n, p) = (506, 12)
Summary Stats:
Length:         506
Missing Count:  0
Mean:           22.532806
Minimum:        5.000000
1st Quartile:   17.025000
Median:         21.200000
3rd Quartile:   25.000000
Maximum:        50.000000
Type:           Float64
</code></pre></div>
<p>Let&#39;s load the decision tree regressor</p>
<pre><code class="language-julia">@load DecisionTreeRegressor</code></pre><div class="code_output"><pre><code class="plaintext">MLJModels.DecisionTree_.DecisionTreeRegressor(pruning_purity_threshold = 0.0,
                                              max_depth = -1,
                                              min_samples_leaf = 5,
                                              min_samples_split = 2,
                                              min_purity_increase = 0.0,
                                              n_subfeatures = 0,
                                              post_prune = false,) @ 1…52</code></pre></div>
<p>Let&#39;s first check the performances of just a single Decision Tree Regressor &#40;DTR for short&#41;:</p>
<pre><code class="language-julia">tree = machine(DecisionTreeRegressor(), X, y)
e = evaluate!(tree, resampling=Holdout(fraction_train=0.8),
              measure=[rms, rmslp1])
e |> pprint</code></pre><div class="code_output"><pre><code class="plaintext">┌─────────┬────────────────────┐
│ measure │ measurement        │
├─────────┼────────────────────┤
│ rms     │ 7.058450107747528  │
│ rmslp1  │ 0.3275559703714572 │
└─────────┴────────────────────┘
(measure = [rms, rmslp1],
 measurement = [7.058450107747528, 0.3275559703714572],
 per_fold = [[7.058450107747528], [0.3275559703714572]],
 per_observation = [missing, missing])
</code></pre></div>
<p>Note that multiple measures can be reported simultaneously.</p>
<h2 id="random_forest"><a href="/pub/getting-started/ensembles-2.html#random_forest">Random forest</a></h2>
<p>Let&#39;s create an ensemble of DTR and fix the number of subfeatures to 3 for now.</p>
<pre><code class="language-julia">forest = EnsembleModel(atom=DecisionTreeRegressor())
forest.atom.n_subfeatures = 3</code></pre><div class="code_output"><pre><code class="plaintext">3</code></pre></div>
<p>&#40;<strong>NB</strong>: we could have fixed <code>n_subfeatures</code> in the DTR constructor too&#41;.</p>
<p>To get an idea of how many trees are needed, we can follow the evaluation of the error &#40;say the <code>rms</code>&#41; for an increasing number of tree over several sampling round.</p>
<pre><code class="language-julia">Random.seed!(5) # for reproducibility
m = machine(forest, X, y)
r = range(forest, :n, lower=10, upper=1000)
curves = learning_curve!(m, resampling=Holdout(fraction_train=0.8),
                         range=r, measure=rms, n=4);</code></pre>
<p>let&#39;s plot the curves</p>
<pre><code class="language-julia">figure(figsize=(8,6))
plot(curves.parameter_values, curves.measurements)
xlabel("Number of trees", fontsize=14)
xticks([10, 250, 500, 750, 1000])
ylim([4, 5])

savefig("assets/literate/A-ensembles-2-curves.svg")</code></pre>
<p><img src="/assets/literate/A-ensembles-2-curves.svg" alt="RMS vs number of trees" /></p>
<p>So out of this curve we could decide for instance to go for 300 trees:</p>
<pre><code class="language-julia">forest.n = 300;</code></pre>
<h3 id="tuning"><a href="/pub/getting-started/ensembles-2.html#tuning">Tuning</a></h3>
<p>As <code>forest</code> is a composite model, it has nested hyperparameters:</p>
<pre><code class="language-julia">params(forest) |> pprint</code></pre><div class="code_output"><pre><code class="plaintext">(atom = (pruning_purity_threshold = 0.0,
         max_depth = -1,
         min_samples_leaf = 5,
         min_samples_split = 2,
         min_purity_increase = 0.0,
         n_subfeatures = 3,
         post_prune = false),
 weights = [],
 bagging_fraction = 0.8,
 rng = Random._GLOBAL_RNG(),
 n = 300,
 acceleration = ComputationalResources.CPU1{Nothing}(nothing),
 out_of_bag_measure = [])
</code></pre></div>
<p>Let&#39;s define a range for the number of subfeatures and for the bagging fraction:</p>
<pre><code class="language-julia">r_sf = range(forest, :(atom.n_subfeatures), lower=1, upper=12)
r_bf = range(forest, :bagging_fraction, lower=0.4, upper=1.0);</code></pre>
<p>And build a tuned model as usual that we fit on a 80/20 split. We use a low-resolution grid here to make this tutorial faster but you could of course use a finer grid.</p>
<pre><code class="language-julia">tuned_forest = TunedModel(model=forest,
                          tuning=Grid(resolution=3),
                          resampling=CV(nfolds=6, rng=32),
                          ranges=[r_sf, r_bf],
                          measure=rms)
m = machine(tuned_forest, X, y)
e = evaluate!(m, resampling=Holdout(fraction_train=0.8),
              measure=[rms, rmslp1])
e |> pprint</code></pre><div class="code_output"><pre><code class="plaintext">┌─────────┬─────────────────────┐
│ measure │ measurement         │
├─────────┼─────────────────────┤
│ rms     │ 3.9350188285958936  │
│ rmslp1  │ 0.24939052519197716 │
└─────────┴─────────────────────┘
(measure = [rms, rmslp1],
 measurement = [3.9350188285958936, 0.24939052519197716],
 per_fold = [[3.9350188285958936], [0.24939052519197716]],
 per_observation = [missing, missing])
</code></pre></div>
<h3 id="reporting"><a href="/pub/getting-started/ensembles-2.html#reporting">Reporting</a></h3>  Again, you could show a 2D heatmap of the hyperparameters</p>
<pre><code class="language-julia">r = report(m)

figure(figsize=(8,6))

vals_sf = r.parameter_values[:, 1]
vals_bf = r.parameter_values[:, 2]

tricontourf(vals_sf, vals_bf, r.measurements)
xticks(1:3:12, fontsize=12)
xlabel("Number of sub-features", fontsize=14)
yticks(0.4:0.2:1, fontsize=12)
ylabel("Bagging fraction", fontsize=14)
</code></pre>
<p><img src="/assets/literate/A-ensembles-2-heatmap.svg" alt="" /></p>
<p>Even though we&#39;ve only done a very rough search, it seems that around 7 sub-features and a bagging fraction of around <code>0.75</code> work well.</p>
<p>Now that the machine <code>m</code> is trained, you can use use it for predictions &#40;implicitly, this will use the best model&#41;. For instance we could look at predictions on the whole dataset:</p>
<pre><code class="language-julia">ŷ = predict(m, X)
rms(ŷ, y)</code></pre><div class="code_output"><pre><code class="plaintext">2.8253941892113357</code></pre></div>
<div class="page-foot">
  <div class="copyright">
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: October 21, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>
<!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/libs/pure/ui.min.js"></script>
  
  
      <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
