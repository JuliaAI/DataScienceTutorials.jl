<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/MLJTutorials/libs/highlight/github.min.css"> <link rel=stylesheet  href="/MLJTutorials/css/judoc.css"> <link rel=stylesheet  href="/MLJTutorials/css/pure.css"> <link rel=stylesheet  href="/MLJTutorials/css/side-menu.css"> <link rel=stylesheet  href="/MLJTutorials/css/extra.css"> <title></title> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/MLJTutorials/" id=menu-logo-link > <div class=menu-logo > <img id=menu-logo  alt="MLJ Logo" src="/MLJTutorials/assets/infra/MLJLogo2.svg" /> <p><strong>MLJ Tutorials</strong></p> </div> </a> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/MLJTutorials/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/choosing-a-model.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Choosing a model</a> <li class="pure-menu-item pure-menu-selected"><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/model-tuning.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Model tuning</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/ensembles-2.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/composing-models.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Composing models</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/getting-started/learning-networks.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/AMES.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> AMES</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/wine.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Wine</a> <li class="pure-menu-item "><a href="/MLJTutorials/pub/end-to-end/crabs-xgb.html" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a> </ul> </ul> </div> </div> <div id=main > <div class=jd-content > <h1 id=fit_predict_transform ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#fit_predict_transform">Fit, predict, transform</a></h1> <em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/notebooks/A-fit-predict.ipynb" target=_blank ><em>notebook</em></a> <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/A-fit-predict.jl" target=_blank ><em>raw script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class=jd-toc ><ol><li><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#preliminary_steps">Preliminary steps</a><ol><li><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#data">Data</a><li><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#mlj_machine">MLJ Machine</a></ol><li><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#training_and_testing_a_supervised_model">Training and testing a supervised model</a><ol><li><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#splitting_the_data">Splitting the data</a><li><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#fitting_and_testing_the_machine">Fitting and testing the machine</a></ol><li><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#unsupervised_models">Unsupervised models</a></ol></div> <h2 id=preliminary_steps ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#preliminary_steps">Preliminary steps</a></h2> <h3 id=data ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#data">Data</a></h3> <p>As in &quot;<a href=choosing-a-model.html >choosing a model</a>&quot;, let&#39;s load the Iris dataset and unpack it:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ, Statistics, PrettyPrinting
X, y = <span class=hljs-meta >@load_iris</span>;</code></pre> <p>let&#39;s also load the <code>DecisionTreeClassifier</code>:</p> <pre><code class="julia hljs"><span class=hljs-meta >@load</span> DecisionTreeClassifier
tree_model = DecisionTreeClassifier()</code></pre><div class=code_output ><pre><code class="plaintext hljs">MLJModels.DecisionTree_.DecisionTreeClassifier(pruning_purity = 1.0,
                                               max_depth = -1,
                                               min_samples_leaf = 1,
                                               min_samples_split = 2,
                                               min_purity_increase = 0.0,
                                               n_subfeatures = 0,
                                               display_depth = 5,
                                               post_prune = false,
                                               merge_purity_threshold = 0.9,
                                               pdf_smoothing = 0.05,) @ 5…73</code></pre></div> <h3 id=mlj_machine ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#mlj_machine">MLJ Machine</a></h3> <p>In MLJ, remember that a <em>model</em> is an object that only serves as a container for the hyperparameters of the model. A <em>machine</em> is an object wrapping both a model and data and can contain information on the <em>trained</em> model; it does <em>not</em> fit the model by itself. However, it does check that the model is compatible with the scientific type of the data and will warn you otherwise.</p> <pre><code class="julia hljs">tree = machine(tree_model, X, y)</code></pre><div class=code_output ><pre><code class="plaintext hljs">Machine{DecisionTreeClassifier} @ 5…56
</code></pre></div> <p>A machine is used both for supervised and unsupervised model. In this tutorial we give an example for the supervised model first and then go on with the unsupervised case.</p> <h2 id=training_and_testing_a_supervised_model ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#training_and_testing_a_supervised_model">Training and testing a supervised model</a></h2> <p>Now that you&#39;ve declared the model you&#39;d like to consider and the data, we are left with the standard training and testing step for a supervised learning algorithm.</p> <h3 id=splitting_the_data ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#splitting_the_data">Splitting the data</a></h3> <p>To split the data into a <em>training</em> and <em>testing</em> set, you can use the function <code>partition</code> to obtain indices for data points that should be considered either as training or testing data:</p> <pre><code class="julia hljs">train, test = partition(eachindex(y), <span class=hljs-number >0.7</span>, shuffle=<span class=hljs-literal >true</span>)
test[<span class=hljs-number >1</span>:<span class=hljs-number >3</span>]</code></pre><div class=code_output ><pre><code class="plaintext hljs">3-element Array{Int64,1}:
  72
 120
  25</code></pre></div> <h3 id=fitting_and_testing_the_machine ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#fitting_and_testing_the_machine">Fitting and testing the machine</a></h3> <p>To fit the machine, you can use the function <code>fit&#33;</code> specifying the rows to be used for the training:</p> <pre><code class="julia hljs">fit!(tree, rows=train)</code></pre><div class=code_output ><pre><code class="plaintext hljs">Machine{DecisionTreeClassifier} @ 5…56
</code></pre></div> <p>Note that this <strong>modifies</strong> the machine which now contains the trained parameters of the decision tree. You can inspect the result of the fitting with the <code>fitted_params</code> method:</p> <pre><code class="julia hljs">fitted_params(tree) |&gt; pprint</code></pre><div class=code_output ><pre><code class="plaintext hljs">(tree_or_leaf = Decision Tree
Leaves: 6
Depth:  5,
 encoding = Dict("virginica" =&gt; 0x00000003,
                 "setosa" =&gt; 0x00000001,
                 "versicolor" =&gt; 0x00000002))
</code></pre></div> <p>This <code>fitresult</code> will vary from model to model though classifiers will usually give out a tuple with the first element corresponding to the fitting and the second one keeping track of how classes are named &#40;so that predictions can be appropriately named&#41;.</p> <p>You can now use the machine to make predictions with the <code>predict</code> function specifying rows to be used for the prediction:</p> <pre><code class="julia hljs">ŷ = predict(tree, rows=test)
<span class=hljs-meta >@show</span> ŷ[<span class=hljs-number >1</span>]</code></pre><div class=code_output ><pre><code class="plaintext hljs">ŷ[1] = UnivariateFinite(setosa=&gt;0.9677419354838711, versicolor=&gt;0.01612903225806452, virginica=&gt;0.01612903225806452)
</code></pre></div> <p>Note that the output is <em>probabilistic</em>, effectively a vector with a score for each class. You could get the mode by using the <code>mode</code> function on <code>ŷ</code> or using <code>predict_mode</code>:</p> <pre><code class="julia hljs">ȳ = predict_mode(tree, rows=test)
<span class=hljs-meta >@show</span> ȳ[<span class=hljs-number >1</span>]
<span class=hljs-meta >@show</span> mode(ŷ[<span class=hljs-number >1</span>])</code></pre><div class=code_output ><pre><code class="plaintext hljs">ȳ[1] = "setosa"
mode(ŷ[1]) = "setosa"
</code></pre></div> <p>To measure the discrepancy between <code>ŷ</code> and <code>y</code> you could use the average cross entropy:</p> <pre><code class="julia hljs">mce = cross_entropy(ŷ, y[test]) |&gt; mean
round(mce, digits=<span class=hljs-number >4</span>)</code></pre><div class=code_output ><pre><code class="plaintext hljs">3.3993</code></pre></div>
<h2 id=unsupervised_models ><a href="/MLJTutorials/pub/getting-started/fit-and-predict.html#unsupervised_models">Unsupervised models</a></h2>
<p>Unsupervised models define a <code>transform</code> method, and may optionally implement an <code>inverse_transform</code> method. As in the supervised case, we use a machine to wrap the unsupervised model and the data:</p>
<pre><code class="julia hljs">v = [<span class=hljs-number >1</span>, <span class=hljs-number >2</span>, <span class=hljs-number >3</span>, <span class=hljs-number >4</span>]
stand_model = UnivariateStandardizer()
stand = machine(stand_model, v)</code></pre><div class=code_output ><pre><code class="plaintext hljs">Machine{UnivariateStandardizer} @ 4…10
</code></pre></div>
<p>We can then fit the machine and use it to apply the corresponding <em>data transformation</em>:</p>
<pre><code class="julia hljs">fit!(stand)
w = transform(stand, v)
<span class=hljs-meta >@show</span> round.(w, digits=<span class=hljs-number >2</span>)
<span class=hljs-meta >@show</span> mean(w)
<span class=hljs-meta >@show</span> std(w)</code></pre><div class=code_output ><pre><code class="plaintext hljs">round.(w, digits=2) = [-1.16, -0.39, 0.39, 1.16]
mean(w) = 0.0
std(w) = 1.0
</code></pre></div>
<p>In this case, the model also has an inverse transform:</p>
<pre><code class="julia hljs">vv = inverse_transform(stand, w)
sum(abs.(vv .- v))</code></pre><div class=code_output ><pre><code class="plaintext hljs">0.0</code></pre></div>
<div class=page-foot >
  <div class=copyright >
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: October 10, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>

      </div> 
  </div> 
  <script src="/MLJTutorials/libs/pure/ui.min.js"></script>