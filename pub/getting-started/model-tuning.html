<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
   
  <link rel="stylesheet" href="/css/judoc.css">
  <link rel="stylesheet" href="/css/pure.css">
  <link rel="stylesheet" href="/css/side-menu.css">
  <link rel="stylesheet" href="/css/extra.css">
  <!-- <link rel="icon" href="/assets/infra/favicon.gif"> -->
   <title></title>  
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/" id="menu-logo-link">
          <div class="menu-logo">
            <img id="menu-logo" alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" />
            <p><strong>MLJ Tutorials</strong></p>
          </div>
        </a>
        <ul class="pure-menu-list">
          <li class="pure-menu-item pure-menu-top-item "><a href="/" class="pure-menu-link"><strong>Home</strong></a></li>

          <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/data/loading.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
            <li class="pure-menu-item "><a href="/pub/data/dataframe.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> DataFrame</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
          <ul class="pure-menu-sublist">
            <li class="pure-menu-item "><a href="/pub/getting-started/choosing-a-model.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/fit-and-predict.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
            <li class="pure-menu-item pure-menu-selected"><a href="/pub/getting-started/model-tuning.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/ensembles.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/ensembles-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/composing-models.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
            <li class="pure-menu-item "><a href="/pub/getting-started/learning-networks-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
          <ul class="pure-menu-sublist" id=isl>
            <li class="pure-menu-item "><a href="/pub/isl/lab-2.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-3.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-4.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-5.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-6b.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-8.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-9.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
            <li class="pure-menu-item "><a href="/pub/isl/lab-10.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
          </ul>

          <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
          <ul class="pure-menu-sublist" id=e2e>
            <li class="pure-menu-item "><a href="/pub/end-to-end/AMES.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/wine.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/crabs-xgb.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
            <li class="pure-menu-item "><a href="/pub/end-to-end/horse.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
          </ul>
        </ul>
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->

<div class="jd-content">
<h1 id="tuning_a_model"><a href="/pub/getting-started/model-tuning.html#tuning_a_model">Tuning a model</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/notebooks/A-model-tuning.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/A-model-tuning-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/scripts/A-model-tuning.jl" target="_blank"><em>annoted script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="jd-toc"><ol><li><a href="/pub/getting-started/model-tuning.html#tuning_a_single_hyperparameter">Tuning a single hyperparameter</a><ol><li><a href="/pub/getting-started/model-tuning.html#specifying_a_range_of_value">Specifying a range of value</a></li><li><a href="/pub/getting-started/model-tuning.html#fitting_and_inspecting_a_tuned_model">Fitting and inspecting a tuned model</a></li></ol></li><li><a href="/pub/getting-started/model-tuning.html#tuning_nested_hyperparameters">Tuning nested hyperparameters</a></li></ol></div> <h2 id="tuning_a_single_hyperparameter"><a href="/pub/getting-started/model-tuning.html#tuning_a_single_hyperparameter">Tuning a single hyperparameter</a></h2>
<p>In MLJ, tuning is implemented as a model wrapper. After wrapping a model in a <em>tuning strategy</em> &#40;e.g. cross-validation&#41; and binding the wrapped model to data in a <em>machine</em>, fitting the machine initiates a search for optimal model hyperparameters.</p>
<p>Let&#39;s use a decision tree classifier and tune the maximum depth of the tree. As usual, start by loading data and the model</p>
<pre><code class="language-julia">using MLJ, PrettyPrinting
X, y = @load_iris
@load DecisionTreeClassifier</code></pre><div class="code_output"><pre><code class="plaintext">DecisionTreeClassifier(pruning_purity = 1.0,
                       max_depth = -1,
                       min_samples_leaf = 1,
                       min_samples_split = 2,
                       min_purity_increase = 0.0,
                       n_subfeatures = 0,
                       display_depth = 5,
                       post_prune = false,
                       merge_purity_threshold = 0.9,
                       pdf_smoothing = 0.05,) @ 8…78</code></pre></div>
<h3 id="specifying_a_range_of_value"><a href="/pub/getting-started/model-tuning.html#specifying_a_range_of_value">Specifying a range of value</a></h3>
<p>To specify a range of value, you can use the <code>range</code> function:</p>
<pre><code class="language-julia">dtc = DecisionTreeClassifier()
r   = range(dtc, :max_depth, lower=1, upper=5)</code></pre><div class="code_output"><pre><code class="plaintext">MLJ.NumericRange(field = :max_depth,
                 lower = 1,
                 upper = 5,
                 scale = :linear,) @ 3…41</code></pre></div>
<p>As you can see, the range function takes a model &#40;<code>dtc</code>&#41;, a symbol for the hyperparameter of interest &#40;<code>:max_depth</code>&#41; and indication of how to samples values. For hyperparameters of type <code>&lt;:Real</code>, you should specify a range of values as done above. For hyperparameters of other type &#40;e.g. <code>Symbol</code>&#41;, you should use the <code>values&#61;...</code> keyword.</p>
<p>Once a range of values has been defined, you can then wrap the model in a <code>TunedModel</code> specifying the tuning strategy:</p>
<pre><code class="language-julia">tm = TunedModel(model=dtc, ranges=[r, ], measure=cross_entropy)</code></pre><div class="code_output"><pre><code class="plaintext">MLJ.ProbabilisticTunedModel(model = DecisionTreeClassifier(pruning_purity = 1.0,
                                                           max_depth = -1,
                                                           min_samples_leaf = 1,
                                                           min_samples_split = 2,
                                                           min_purity_increase = 0.0,
                                                           n_subfeatures = 0,
                                                           display_depth = 5,
                                                           post_prune = false,
                                                           merge_purity_threshold = 0.9,
                                                           pdf_smoothing = 0.05,),
                            tuning = Grid(resolution = 10,
                                          acceleration = ComputationalResources.CPU1{Nothing}(nothing),),
                            resampling = Holdout(fraction_train = 0.7,
                                                 shuffle = false,
                                                 rng = Random._GLOBAL_RNG(),),
                            measure = MLJBase.CrossEntropy(),
                            weights = nothing,
                            operation = StatsBase.predict,
                            ranges = MLJ.NumericRange{Int64,Symbol}[NumericRange @ 3…41],
                            full_report = true,
                            train_best = true,) @ 1…61</code></pre></div>
<h3 id="fitting_and_inspecting_a_tuned_model"><a href="/pub/getting-started/model-tuning.html#fitting_and_inspecting_a_tuned_model">Fitting and inspecting a tuned model</a></h3>
<p>To fit a tuned model, you can use the usual syntax:</p>
<pre><code class="language-julia">m = machine(tm, X, y)
fit!(m)</code></pre><div class="code_output"><pre><code class="plaintext">Machine{ProbabilisticTunedModel} @ 1…30
</code></pre></div>
<p>In order to inspect the best model, you can use the function <code>fitted_params</code> on the machine and inspect the <code>best_model</code> field:</p>
<pre><code class="language-julia">fitted_params(m).best_model.max_depth</code></pre><div class="code_output"><pre><code class="plaintext">4</code></pre></div>
<p>Note that here we have tuned a probabilistic model and consequently used a probabilistic measure for the tuning. We could also have decided we only cared about the mode and the misclassification rate, to do this, just use <code>operation&#61;predict_mode</code> in the tuned model:</p>
<pre><code class="language-julia">tm = TunedModel(model=dtc, ranges=r, operation=predict_mode,
                measure=misclassification_rate)
m = machine(tm, X, y)
fit!(m)
fitted_params(m).best_model.max_depth</code></pre><div class="code_output"><pre><code class="plaintext">2</code></pre></div>
<p>Let&#39;s check the misclassification rate for the best model:</p>
<pre><code class="language-julia">r = report(m)
r.best_measurement</code></pre><div class="code_output"><pre><code class="plaintext">0.1111111111111111</code></pre></div>
<p>Anyone wants plots? of course:</p>
<pre><code class="language-julia">using PyPlot
figure(figsize=(8,6))
plot(r.parameter_values, r.measurements)

xticks(1:5, fontsize=12)
yticks(fontsize=12)
xlabel("Maximum depth", fontsize=14)
ylabel("Misclassification rate", fontsize=14)
ylim([0, 1])
</code></pre>
<p><img src="/assets/literate/A-model-tuning-hpt.svg" alt="Hyperparameter heatmap" /></p>
<h2 id="tuning_nested_hyperparameters"><a href="/pub/getting-started/model-tuning.html#tuning_nested_hyperparameters">Tuning nested hyperparameters</a></h2>
<p>Let&#39;s generate simple dummy regression data</p>
<pre><code class="language-julia">X = (x1=rand(100), x2=rand(100), x3=rand(100))
y = 2X.x1 - X.x2 + 0.05 * randn(100);</code></pre>
<p>Let&#39;s then build a simple ensemble model with decision tree regressors:</p>
<pre><code class="language-julia">dtr = @load DecisionTreeRegressor
forest = EnsembleModel(atom=dtr)</code></pre><div class="code_output"><pre><code class="plaintext">MLJ.DeterministicEnsembleModel(atom = DecisionTreeRegressor(pruning_purity_threshold = 0.0,
                                                            max_depth = -1,
                                                            min_samples_leaf = 5,
                                                            min_samples_split = 2,
                                                            min_purity_increase = 0.0,
                                                            n_subfeatures = 0,
                                                            post_prune = false,),
                               weights = Float64[],
                               bagging_fraction = 0.8,
                               rng = Random._GLOBAL_RNG(),
                               n = 100,
                               acceleration = ComputationalResources.CPU1{Nothing}(nothing),
                               out_of_bag_measure = Any[],) @ 5…97</code></pre></div>
<p>Such a model has <em>nested</em> hyperparameters in that the ensemble has hyperparameters &#40;e.g. the <code>:bagging_fraction</code>&#41; and the atom has hyperparameters &#40;e.g. <code>:n_subfeatures</code> or <code>:max_depth</code>&#41;. You can see this by inspecting the parameters using <code>params</code>:</p>
<pre><code class="language-julia">params(forest) |> pprint</code></pre><div class="code_output"><pre><code class="plaintext">(atom = (pruning_purity_threshold = 0.0,
         max_depth = -1,
         min_samples_leaf = 5,
         min_samples_split = 2,
         min_purity_increase = 0.0,
         n_subfeatures = 0,
         post_prune = false),
 weights = [],
 bagging_fraction = 0.8,
 rng = Random._GLOBAL_RNG(),
 n = 100,
 acceleration = ComputationalResources.CPU1{Nothing}(nothing),
 out_of_bag_measure = [])
</code></pre></div>
<p>Range for nested hyperparameters are specified using dot syntax, the rest is done in much the same way as before:</p>
<pre><code class="language-julia">r1 = range(forest, :(atom.n_subfeatures), lower=1, upper=3)
r2 = range(forest, :bagging_fraction, lower=0.4, upper=1.0)
tm = TunedModel(model=forest, tuning=Grid(resolution=12),
                resampling=CV(nfolds=6), ranges=[r1, r2],
                measure=rms)
m = machine(tm, X, y)
fit!(m);</code></pre>
<p>A useful function to inspect a model after fitting it is the <code>report</code> function which collects information on the model and the tuning, for instance you can use it to recover the best measurement:</p>
<pre><code class="language-julia">r = report(m)
r.best_measurement</code></pre><div class="code_output"><pre><code class="plaintext">0.1601503766377997</code></pre></div>
<p>Let&#39;s visualise this</p>
<pre><code class="language-julia">figure(figsize=(8,6))

vals_sf = r.parameter_values[:, 1]
vals_bf = r.parameter_values[:, 2]

tricontourf(vals_sf, vals_bf, r.measurements)
xlabel("Number of sub-features", fontsize=14)
ylabel("Bagging fraction", fontsize=14)
xticks([1, 2, 3], fontsize=12)
yticks(fontsize=12)
</code></pre>
<p><img src="/assets/literate/A-model-tuning-hm.svg" alt="Hyperparameter heatmap" />
<div class="page-foot">
  <div class="copyright">
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: October 10, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>
<!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/libs/pure/ui.min.js"></script>
  
  
      <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
