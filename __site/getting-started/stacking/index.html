<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/css/landing.css">
  <link rel="stylesheet" href="/css/franklin.css">
  <link rel="stylesheet" href="/css/pure.css">
  <link rel="stylesheet" href="/css/side-menu.css">
  <link rel="stylesheet" href="/css/nav.css">
  <link rel="stylesheet" href="/css/extra.css">
  <!-- <link rel="icon" href="/assets/infra/favicon.gif"> -->
   <title>Stacking</title> 
  <!-- LUNR -->
  <script src="/libs/lunr/lunr.min.js"></script>
  <script src="/libs/lunr/lunr_index.js"></script>
  <script src="/libs/lunr/lunrclient.min.js"></script>
</head>

<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu" style="display: none;">
      <div class="pure-menu">
        <a href="/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Search in tutorials..." type="text">
          <input type="submit" value="Search" formaction="/search/index.html" style="display:none">
        </form>
        <!-- LIST OF MENU ITEMS -->
        <ul class="pure-menu-list">
          <li class="pure-menu-item pure-menu-top-item "><a href="/"
              class="pure-menu-link"><strong>Home</strong></a></li>

          <!-- DATA BASICS -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Data Basics</strong></li>
          </div>
          <div class="collapse dropdown-content">
            <ul class="pure-menu-sublist">
              <li class="pure-menu-item "><a
                  href="/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading
                  data</a></li>
              <li class="pure-menu-item "><a
                  href="/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data
                  Frames</a></li>
              <li class="pure-menu-item "><a
                  href="/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Categorical Arrays</a></li>
              <li class="pure-menu-item "><a
                  href="/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific
                  Type</a></li>
              <li class="pure-menu-item "><a
                  href="/data/processing/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data
                  processing</a></li>
            </ul>
          </div>

          <!-- GETTING STARTED WITH MLJ -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Getting Started</strong></li>
          </div>
          <div class="collapse dropdown-content">
            <ul class="pure-menu-sublist">
              <li
                class="pure-menu-item ">
                <a href="/getting-started/choosing-a-model/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Choosing a model</a>
              </li>
              <li class="pure-menu-item ">
                <a href="/getting-started/fit-and-predict/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Fit, predict, transform</a>
              </li>
              <li class="pure-menu-item "><a
                  href="/getting-started/model-tuning/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Model tuning</a></li>
              <li class="pure-menu-item "><a
                  href="/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Ensembles</a></li>
              <li class="pure-menu-item "><a
                  href="/getting-started/ensembles-2/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Ensembles 2</a></li>
              <li
                class="pure-menu-item ">
                <a href="/getting-started/composing-models/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Composing models</a>
              </li>
              <li class="pure-menu-item "><a
                  href="/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Stacking</a></li>
            </ul>
          </div>
          <!-- INTRO TO STATS LEARNING -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
          </div>
          <div class="collapse dropdown-content">
            <ul class="pure-menu-sublist" id=isl>
              <li class="pure-menu-item "><a href="/isl/lab-2/"
                  class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
              <li class="pure-menu-item "><a href="/isl/lab-3/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 3</a></li>
              <li class="pure-menu-item "><a href="/isl/lab-4/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 4</a></li>
              <li class="pure-menu-item "><a href="/isl/lab-5/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 5</a></li>
              <li class="pure-menu-item "><a href="/isl/lab-6b/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
              <li class="pure-menu-item "><a href="/isl/lab-8/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 8</a></li>
              <li class="pure-menu-item "><a href="/isl/lab-9/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 9</a></li>
              <li class="pure-menu-item "><a href="/isl/lab-10/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 10</a></li>
            </ul>
          </div>
          <!-- End to End -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>End to End</strong></li>
          </div>
          <div class="dropdown-content collapse">
            <ul class="pure-menu-sublist" >
              <li class="pure-menu-item "><a
                  href="/end-to-end/telco/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>Telco
                  Churn</a></li>
              <li class="pure-menu-item "><a
                  href="/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a>
              </li>
              <li class="pure-menu-item "><a href="/end-to-end/wine/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Wine</a></li>
              <li class="pure-menu-item "><a
                  href="/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Crabs (XGB)</a></li>
              <li class="pure-menu-item "><a href="/end-to-end/horse/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Horse</a></li>
              <li class="pure-menu-item "><a href="/end-to-end/HouseKingCounty/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> King County Houses</a></li>
              <li class="pure-menu-item "><a href="/end-to-end/airfoil" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Airfoil </a></li>
              <li class="pure-menu-item "><a href="/end-to-end/boston-lgbm" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
              <li class="pure-menu-item "><a href="/end-to-end/glm/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
              <li class="pure-menu-item "><a href="/end-to-end/powergen/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Power Generation </a></li>
              <li class="pure-menu-item "><a href="/end-to-end/boston-flux" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
              <li class="pure-menu-item "><a href="/end-to-end/breastcancer" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Breast Cancer</a></li>
              <li class="pure-menu-item "><a href="/end-to-end/creditfraud" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Credit Fraud</a></li>
            </ul>
          </div>
          <!-- ADVANCED EXAMPLES -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Advanced Examples</strong></li>
          </div>
          <div class="dropdown-content collapse">
            <ul class="pure-menu-sublist" id=adv>
              <li class="pure-menu-item "><a href="/advanced/ensembles-3/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
            </ul>
          </div>
      </div>
      </ul>
      <!-- END OF LIST OF MENU ITEMS -->
    </div>
  </div>
  <div id="nav" class="navigation">
    <div class="nav-container">
      <div class="brand">
        <a href="/">DataScienceTutorials.jl</a>
      </div>
      <nav>
        <div class="nav-mobile"><a id="nav-toggle" href="#!"><span></span></a></div>
        <ul class="nav-list">
        <!-- horizontal navigation bar gets injected -->
        </ul>
      </nav>
    </div>
  </div>
  <div id="main"> <!-- Closed in foot -->
    

    <!-- Content appended here --><div class="franklin-content"><h1 id="stacking"><a href="#stacking" class="header-anchor">Stacking</a></h1>
<em>To ensure code in this tutorial runs as shown, download the tutorial <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-stacking.tar.gz">project folder</a> and follow <a href="/#learning_by_doing">these instructions</a>.</em></p>
<p><em>If you have questions or suggestions about this tutorial, please open an issue <a href="https://github.com/JuliaAI/DataScienceTutorials.jl/issues/new">here</a>.</em></p>
<p><div class="franklin-toc"><ol><li><a href="#basic_stacking_using_out-of-sample_base_learner_predictions">Basic stacking using out-of-sample base learner predictions</a><ol><li><a href="#warm-up_exercise_define_a_model_type_to_average_predictions">Warm-up exercise: Define a model type to average predictions</a></li></ol></li><li><a href="#stacking_proper">Stacking proper</a><ol><li><a href="#helper_functions">Helper functions:</a></li><li><a href="#choose_some_test_data_optional_and_some_component_models_defaults_for_the_composite_model">Choose some test data &#40;optional&#41; and some component models &#40;defaults for the composite model&#41;:</a></li><li><a href="#define_the_training_nodes">Define the training nodes</a></li><li><a href="#define_nodes_still_needed_for_prediction">Define nodes still needed for prediction</a></li></ol></li><li><a href="#export_the_learning_network_as_a_new_model_type">Export the learning network as a new model type</a></li><li><a href="#applying_mytwomodelstack_to_some_data">Applying <code>MyTwoModelStack</code> to some data</a></li></ol></div>
<p>An advanced illustration of learning networks.</p>
<p>In stacking one blends the predictions of different regressors or classifiers to gain, in some cases, better performance than naive averaging or majority vote. The gains may small, their statistical significance in doubt, and the approach is computationally intensive. Nevertheless, stacking has been used successfully by teams in data science science competitions.</p>
<p>For routine stacking tasks the MLJ user should use the <code>Stack</code> model documented <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Model-Stacking">here</a>. Internally, <code>Stack</code> is implemented using MLJ&#39;s learning networks feature, and the purpose of this tutorial give an advanced illustration of MLJ learning networks by presenting a simplified version of this implementation. Familiarity with model stacking is not essential, but we assume the reader is already familiar with learning network basics, as illustrated in the <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/learning_networks/">Learning networks</a> section of the MLJ manual. The &quot;Ensembles &#40;learning networks&#41;&quot; tutorial also gives a simple illustration.</p>
<p>Specifically, we build a two-model stack, first as an MLJ learning network, and then as an &quot;exported&quot; stand-alone composite model type <code>MyTwoStack</code>.</p>
<p>As we shall see, as a new stand-alone model type, we can apply the usual meta-algorithms, such as performance evaluation and tuning, to <code>MyTwoStack</code>.</p>
<div class="dropdown"><h2 id="basic_stacking_using_out-of-sample_base_learner_predictions"><a href="#basic_stacking_using_out-of-sample_base_learner_predictions" class="header-anchor">Basic stacking using out-of-sample base learner predictions</a></h2></div>
<div class="dropdown-content"><p>A rather general stacking protocol was first described in a <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608005800231">1992 paper</a> by David Wolpert. For a generic introduction to the basic two-layer stack described here, see <a href="https://burakhimmetoglu.com/2016/12/01/stacking-models-for-improved-predictions/">this blog post</a> of Burak Himmetoglu.</p>
<p>A basic stack consists of a number of base learners &#40;two, in this illustration&#41; and a single adjudicating model.</p>
<p>When a stacked model is called to make a prediction, the individual predictions of the base learners are made the columns of an <em>input</em> table for the adjudicating model, which then outputs the final prediction. However, it is crucial to understand that the flow of data <em>during training</em> is not the same.</p>
<p>The base model predictions used to train the adjudicating model are <em>not</em> the predictions of the base learners fitted to all the training data. Rather, to prevent the adjudicator giving too much weight to the base learners with low <em>training</em> error, the input data is first split into a number of folds &#40;as in cross-validation&#41;, a base learner is trained on each fold complement individually, and corresponding predictions on the folds are spliced together to form a full-length prediction called the <em>out-of-sample prediction</em>.</p>
<p>For illustrative purposes we use just three folds. Each base learner will get three separate machines, for training on each fold complement, and a fourth machine, trained on all the supplied data, for use in the prediction flow.</p>
<p>We build the learning network with dummy data at the source nodes, so the reader inspects the workings of the network as it is built &#40;by calling <code>fit&#33;</code> on nodes, and by calling the nodes themselves&#41;. As usual, this data is not seen by the exported composite model type, and the component models we choose are just default values for the hyperparameters of the composite model.</p>
<pre><code class="language-julia">using MLJ
import StableRNGs.StableRNG</code></pre>
<p>Some models we will use:</p>
<pre><code class="language-julia">linear &#61; &#40;@load LinearRegressor pkg&#61;MLJLinearModels&#41;&#40;&#41;
knn &#61; &#40;@load KNNRegressor&#41;&#40;&#41;

tree_booster &#61; &#40;@load EvoTreeRegressor&#41;&#40;&#41;
forest &#61; &#40;@load RandomForestRegressor pkg&#61;DecisionTree&#41;&#40;&#41;
svm &#61; &#40;@load EpsilonSVR pkg&#61;LIBSVM&#41;&#40;&#41;</code></pre><pre><code class="plaintext code-output">import MLJLinearModels ✔
import NearestNeighborModels ✔
import EvoTrees ✔
import MLJDecisionTreeInterface ✔
import MLJLIBSVMInterface ✔
EpsilonSVR(
  kernel = LIBSVM.Kernel.RadialBasis, 
  gamma = 0.0, 
  epsilon = 0.1, 
  cost = 1.0, 
  cachesize = 200.0, 
  degree = 3, 
  coef0 = 0.0, 
  tolerance = 0.001, 
  shrinking = true)</code></pre>
<div class="dropdown"><h3 id="warm-up_exercise_define_a_model_type_to_average_predictions"><a href="#warm-up_exercise_define_a_model_type_to_average_predictions" class="header-anchor">Warm-up exercise: Define a model type to average predictions</a></h3></div>
<div class="dropdown-content"><p>Let&#39;s define a composite model type <code>MyAverageTwo</code> that averages the predictions of two deterministic regressors. Here&#39;s the learning network:</p>
<pre><code class="language-julia">mutable struct MyAverageTwo &lt;: DeterministicNetworkComposite
    regressor1
    regressor2
end

import MLJ.MLJBase.prefit
function prefit&#40;::MyAverageTwo, verbosity, X, y&#41;

    Xs &#61; source&#40;X&#41;
    ys &#61; source&#40;y&#41;

    m1 &#61; machine&#40;:regressor1, Xs, ys&#41;
    y1 &#61; predict&#40;m1, Xs&#41;

    m2 &#61; machine&#40;:regressor2, Xs, ys&#41;
    y2 &#61; predict&#40;m2, Xs&#41;

    yhat &#61; 0.5*y1 &#43; 0.5*y2

    return &#40;predict&#61;yhat,&#41;
end</code></pre><pre><code class="plaintext code-output">prefit (generic function with 7 methods)</code></pre>
<p>Let&#39;s create an instance of the new type:</p>
<pre><code class="language-julia">average_two &#61; MyAverageTwo&#40;linear, knn&#41;</code></pre><pre><code class="plaintext code-output">MyAverageTwo(
  regressor1 = LinearRegressor(
        fit_intercept = true, 
        solver = nothing), 
  regressor2 = KNNRegressor(
        K = 5, 
        algorithm = :kdtree, 
        metric = Distances.Euclidean(0.0), 
        leafsize = 10, 
        reorder = true, 
        weights = NearestNeighborModels.Uniform()))</code></pre>
<p>Evaluating this average model on the Boston data set, and comparing with the base model predictions:</p>
<pre><code class="language-julia">function print_performance&#40;model, data...&#41;
    e &#61; evaluate&#40;model, data...;
                 resampling&#61;CV&#40;rng&#61;StableRNG&#40;1234&#41;, nfolds&#61;8&#41;,
                 measure&#61;rms,
                 verbosity&#61;0&#41;
    μ &#61; round&#40;e.measurement&#91;1&#93;, sigdigits&#61;5&#41;
    ste &#61; round&#40;std&#40;e.per_fold&#91;1&#93;&#41;/sqrt&#40;8&#41;, digits&#61;5&#41;
    println&#40;&quot;&#36;&#40;MLJ.name&#40;model&#41;&#41; &#61; &#36;μ ± &#36;&#40;2*ste&#41;&quot;&#41;
end;

X, y &#61; @load_boston

print_performance&#40;linear, X, y&#41;
print_performance&#40;knn, X, y&#41;
print_performance&#40;average_two, X, y&#41;</code></pre><pre><code class="plaintext code-output">LinearRegressor = 4.8641 ± 0.34864
KNNRegressor = 6.2241 ± 0.44292
MyAverageTwo = 4.8532 ± 0.36264
</code></pre>
<p>‎</p></div>
<p>‎</p></div>
<div class="dropdown"><h2 id="stacking_proper"><a href="#stacking_proper" class="header-anchor">Stacking proper</a></h2></div>
<div class="dropdown-content"><div class="dropdown"><h3 id="helper_functions"><a href="#helper_functions" class="header-anchor">Helper functions:</a></h3></div>
<div class="dropdown-content"><p>To generate folds for generating out-of-sample predictions, we define</p>
<pre><code class="language-julia">folds&#40;data, nfolds&#41; &#61;
    partition&#40;1:nrows&#40;data&#41;, &#40;1/nfolds for i in 1:&#40;nfolds-1&#41;&#41;...&#41;;</code></pre>
<p>For example, we have:</p>
<pre><code class="language-julia">f &#61; folds&#40;1:10, 3&#41;</code></pre><pre><code class="plaintext code-output">([1, 2, 3], [4, 5, 6], [7, 8, 9, 10])</code></pre>
<p>It will also be convenient to use the MLJ method <code>restrict&#40;X, f, i&#41;</code> that restricts data <code>X</code> to the <code>i</code>th element &#40;fold&#41; of <code>f</code>, and <code>corestrict&#40;X, f, i&#41;</code> that restricts to the corresponding fold complement &#40;the concatenation of all but the <code>i</code>th fold&#41;.</p>
<p>For example, we have:</p>
<pre><code class="language-julia">corestrict&#40;string.&#40;1:10&#41;, f, 2&#41;</code></pre><pre><code class="plaintext code-output">7-element Vector{String}:
 "1"
 "2"
 "3"
 "7"
 "8"
 "9"
 "10"</code></pre>
<p>‎</p></div>
<div class="dropdown"><h3 id="choose_some_test_data_optional_and_some_component_models_defaults_for_the_composite_model"><a href="#choose_some_test_data_optional_and_some_component_models_defaults_for_the_composite_model" class="header-anchor">Choose some test data &#40;optional&#41; and some component models &#40;defaults for the composite model&#41;:</a></h3></div>
<div class="dropdown-content"><pre><code class="language-julia">using Plots

steps&#40;x&#41; &#61; x &lt; -3/2 ? -1 : &#40;x &lt; 3/2 ? 0 : 1&#41;
x &#61; Float64&#91;-4, -1, 2, -3, 0, 3, -2, 1, 4&#93;
Xraw &#61; &#40;x &#61; x, &#41;
yraw &#61; steps.&#40;x&#41;;
idxsort &#61; sortperm&#40;x&#41;
xsort &#61; x&#91;idxsort&#93;
ysort &#61; yraw&#91;idxsort&#93;
plot&#40;xsort, ysort, linetype&#61;:stepmid, label&#61;&quot;truth&quot;&#41;
plot&#33;&#40;x, yraw, seriestype&#61;:scatter, markershape&#61;:circle, label&#61;&quot;data&quot;, xlim&#61;&#40;-4.5, 4.5&#41;&#41;</code></pre>
<img src="/assets/getting-started/stacking/code/output/s1.svg" alt="">
<p>Some models to stack &#40;which we can change later&#41;:</p>
<pre><code class="language-julia">model1 &#61; linear
model2 &#61; knn</code></pre><pre><code class="plaintext code-output">KNNRegressor(
  K = 5, 
  algorithm = :kdtree, 
  metric = Distances.Euclidean(0.0), 
  leafsize = 10, 
  reorder = true, 
  weights = NearestNeighborModels.Uniform())</code></pre>
<p>The adjudicating model:</p>
<pre><code class="language-julia">judge &#61; linear</code></pre><pre><code class="plaintext code-output">LinearRegressor(
  fit_intercept = true, 
  solver = nothing)</code></pre>
<p>‎</p></div>
<div class="dropdown"><h3 id="define_the_training_nodes"><a href="#define_the_training_nodes" class="header-anchor">Define the training nodes</a></h3></div>
<div class="dropdown-content"><p>Let&#39;s instantiate some input and target source nodes for the learning network, wrapping the play data defined above in source nodes:</p>
<pre><code class="language-julia">X &#61; source&#40;Xraw&#41;
y &#61; source&#40;yraw&#41;</code></pre><pre><code class="plaintext code-output">Source @963 ⏎ `AbstractVector{ScientificTypesBase.Count}`</code></pre>
<p>Our first internal node will represent the three folds &#40;vectors of row indices&#41; for creating the out-of-sample predictions. We would like to define <code>f &#61; folds&#40;X, 3&#41;</code> but this will not work because <code>X</code> is not a table, just a node representing a table. So instead we do this:</p>
<pre><code class="language-julia">f &#61; node&#40;X&#41; do x
    folds&#40;x, 3&#41;
end</code></pre><pre><code class="plaintext code-output">Node @329
  args:
    1:	Source @177
  formula:
    #5(
      Source @177)</code></pre>
<p>Now <code>f</code> is itself a node, and so callable:</p>
<pre><code class="language-julia">f&#40;&#41;</code></pre><pre><code class="plaintext code-output">([1, 2, 3], [4, 5, 6], [7, 8, 9])</code></pre>
<p>We&#39;ll overload <code>restrict</code> and <code>corestrict</code> for nodes, to save us having to write <code>node&#40;....&#41;</code> all the time:</p>
<pre><code class="language-julia">MLJ.restrict&#40;X::AbstractNode, f::AbstractNode, i&#41; &#61;  node&#40;X, f&#41; do XX, ff
    restrict&#40;XX, ff, i&#41;
end
MLJ.corestrict&#40;X::AbstractNode, f::AbstractNode, i&#41; &#61; node&#40;X, f&#41; do XX, ff
    corestrict&#40;XX, ff, i&#41;
end</code></pre>
<p>We are now ready to define machines for training <code>model1</code> on each fold-complement:</p>
<pre><code class="language-julia">m11 &#61; machine&#40;model1, corestrict&#40;X, f, 1&#41;, corestrict&#40;y, f, 1&#41;&#41;
m12 &#61; machine&#40;model1, corestrict&#40;X, f, 2&#41;, corestrict&#40;y, f, 2&#41;&#41;
m13 &#61; machine&#40;model1, corestrict&#40;X, f, 3&#41;, corestrict&#40;y, f, 3&#41;&#41;</code></pre><pre><code class="plaintext code-output">untrained Machine; caches model-specific representations of data
  model: LinearRegressor(fit_intercept = true, …)
  args: 
    1:	Node @861
    2:	Node @101
</code></pre>
<p>Define each out-of-sample prediction of <code>model1</code>:</p>
<pre><code class="language-julia">y11 &#61; predict&#40;m11, restrict&#40;X, f, 1&#41;&#41;;
y12 &#61; predict&#40;m12, restrict&#40;X, f, 2&#41;&#41;;
y13 &#61; predict&#40;m13, restrict&#40;X, f, 3&#41;&#41;;</code></pre>
<p>Splice together the out-of-sample predictions for model1:</p>
<pre><code class="language-julia">y1_oos &#61; vcat&#40;y11, y12, y13&#41;;</code></pre>
<p>Note there is no need to overload the <code>vcat</code> function to work on nodes; it does so out of the box, as does <code>hcat</code> and basic arithmetic operations.</p>
<p>Since our source nodes are wrapping data, we can optionally check our network so far, by calling fitting and calling <code>y1_oos</code>:</p>
<pre><code class="language-julia">fit&#33;&#40;y1_oos, verbosity&#61;0&#41;

plot&#40;xsort, ysort, linetype&#61;:stepmid, label&#61;&quot;truth&quot;&#41;
plot&#33;&#40;
    x,
    y1_oos&#40;&#41;,
    seriestype&#61;:scatter,
    markershape&#61;:circle,
    label&#61;&quot;linear oos&quot;,
    xlim&#61;&#40;-4.5, 4.5&#41;,
&#41;</code></pre>
<img src="/assets/getting-started/stacking/code/output/s2.svg" alt="">
<p>We now repeat the procedure for the other model:</p>
<pre><code class="language-julia">m21 &#61; machine&#40;model2, corestrict&#40;X, f, 1&#41;, corestrict&#40;y, f, 1&#41;&#41;
m22 &#61; machine&#40;model2, corestrict&#40;X, f, 2&#41;, corestrict&#40;y, f, 2&#41;&#41;
m23 &#61; machine&#40;model2, corestrict&#40;X, f, 3&#41;, corestrict&#40;y, f, 3&#41;&#41;
y21 &#61; predict&#40;m21, restrict&#40;X, f, 1&#41;&#41;;
y22 &#61; predict&#40;m22, restrict&#40;X, f, 2&#41;&#41;;
y23 &#61; predict&#40;m23, restrict&#40;X, f, 3&#41;&#41;;</code></pre>
<p>And testing the knn out-of-sample prediction:</p>
<pre><code class="language-julia">y2_oos &#61; vcat&#40;y21, y22, y23&#41;;
fit&#33;&#40;y2_oos, verbosity&#61;0&#41;

plot&#40;xsort, ysort, linetype&#61;:stepmid, label&#61;&quot;truth&quot;&#41;
plot&#33;&#40;
    x,
    y2_oos&#40;&#41;,
    seriestype&#61;:scatter,
    markershape&#61;:circle,
    label&#61;&quot;knn oos&quot;,
    xlim&#61;&#40;-4.5, 4.5&#41;,
&#41;</code></pre>
<img src="/assets/getting-started/stacking/code/output/s3.svg" alt="">
<p>Now that we have the out-of-sample base learner predictions, we are ready to merge them into the adjudicator&#39;s input table and construct the machine for training the adjudicator:</p>
<pre><code class="language-julia">X_oos &#61; MLJ.table&#40;hcat&#40;y1_oos, y2_oos&#41;&#41;
m_judge &#61; machine&#40;judge, X_oos, y&#41;</code></pre><pre><code class="plaintext code-output">untrained Machine; caches model-specific representations of data
  model: LinearRegressor(fit_intercept = true, …)
  args: 
    1:	Node @612
    2:	Source @963 ⏎ AbstractVector{ScientificTypesBase.Count}
</code></pre>
<p>Are we done with constructing machines? Well, not quite. Recall that when we use the stack to make predictions on new data, we will be feeding the adjudicator ordinary predictions of the base learners &#40;rather than out-of-sample predictions&#41;. But so far, we have only defined machines to train the base learners on fold complements, not on the full data, which we do now:</p>
<pre><code class="language-julia">m1 &#61; machine&#40;model1, X, y&#41;
m2 &#61; machine&#40;model2, X, y&#41;</code></pre><pre><code class="plaintext code-output">untrained Machine; caches model-specific representations of data
  model: KNNRegressor(K = 5, …)
  args: 
    1:	Source @177 ⏎ ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}
    2:	Source @963 ⏎ AbstractVector{ScientificTypesBase.Count}
</code></pre>
<p>‎</p></div>
<div class="dropdown"><h3 id="define_nodes_still_needed_for_prediction"><a href="#define_nodes_still_needed_for_prediction" class="header-anchor">Define nodes still needed for prediction</a></h3></div>
<div class="dropdown-content"><p>To obtain the final prediction, <code>yhat</code>, we get the base learner predictions, based on training with all data, and feed them to the adjudicator:</p>
<pre><code class="language-julia">y1 &#61; predict&#40;m1, X&#41;;
y2 &#61; predict&#40;m2, X&#41;;
X_judge &#61; MLJ.table&#40;hcat&#40;y1, y2&#41;&#41;
yhat &#61; predict&#40;m_judge, X_judge&#41;</code></pre><pre><code class="plaintext code-output">Node @623 → LinearRegressor(…)
  args:
    1:	Node @887
  formula:
    predict(
      machine(LinearRegressor(fit_intercept = true, …), …), 
      table(
        hcat(
          predict(
            machine(LinearRegressor(fit_intercept = true, …), …), 
            Source @177),
          predict(
            machine(KNNRegressor(K = 5, …), …), 
            Source @177))))</code></pre>
<p>Let&#39;s check the final prediction node can be fit and called:</p>
<pre><code class="language-julia">fit&#33;&#40;yhat, verbosity&#61;0&#41;

plot&#40;xsort, ysort, linetype&#61;:stepmid, label&#61;&quot;truth&quot;&#41;
plot&#33;&#40;x, yhat&#40;&#41;, seriestype&#61;:scatter, markershape&#61;:circle, label&#61;&quot;yhat&quot;, xlim&#61;&#40;-4.5, 4.5&#41;&#41;</code></pre>
<img src="/assets/getting-started/stacking/code/output/s4.svg" alt="">
<p>We note only in passing that, in this baby example at least, stacking has a worse <em>training</em> error than naive averaging:</p>
<pre><code class="language-julia">e1 &#61; rms&#40;y1&#40;&#41;, y&#40;&#41;&#41;
e2 &#61; rms&#40;y2&#40;&#41;, y&#40;&#41;&#41;
emean &#61; rms&#40;0.5*y1&#40;&#41; &#43; 0.5*y2&#40;&#41;, y&#40;&#41;&#41;
estack &#61; rms&#40;yhat&#40;&#41;, y&#40;&#41;&#41;
@show e1 e2 emean estack;</code></pre><pre><code class="plaintext code-output">e1 = 0.2581988897471611
e2 = 0.3771236166328254
emean = 0.2808716591058786
estack = 0.3373908215636326
</code></pre>
<p>‎</p></div>
<p>‎</p></div>
<div class="dropdown"><h2 id="export_the_learning_network_as_a_new_model_type"><a href="#export_the_learning_network_as_a_new_model_type" class="header-anchor">Export the learning network as a new model type</a></h2></div>
<div class="dropdown-content"><p>The learning network &#40;less the data wrapped in the source nodes&#41; amounts to a specification of a new composite model type for two-model stacks, trained with three-fold resampling of base model predictions. Let&#39;s create the new &quot;exported&quot; type <code>MyTwoModelStack</code>, in the same way we exported the network for model averaging &#40;essentially a copy and paste exercise&#41;:</p>
<pre><code class="language-julia">mutable struct MyTwoModelStack &lt;: DeterministicNetworkComposite
    model1
    model2
    judge
end

function prefit&#40;::MyTwoModelStack, verbosity, X, y&#41;

    Xs &#61; source&#40;X&#41;
    ys &#61; source&#40;y&#41;

    f &#61; node&#40;Xs&#41; do x
        folds&#40;x, 3&#41;
    end

    m11 &#61; machine&#40;:model1, corestrict&#40;Xs, f, 1&#41;, corestrict&#40;ys, f, 1&#41;&#41;
    m12 &#61; machine&#40;:model1, corestrict&#40;Xs, f, 2&#41;, corestrict&#40;ys, f, 2&#41;&#41;
    m13 &#61; machine&#40;:model1, corestrict&#40;Xs, f, 3&#41;, corestrict&#40;ys, f, 3&#41;&#41;

    y11 &#61; predict&#40;m11, restrict&#40;Xs, f, 1&#41;&#41;;
    y12 &#61; predict&#40;m12, restrict&#40;Xs, f, 2&#41;&#41;;
    y13 &#61; predict&#40;m13, restrict&#40;Xs, f, 3&#41;&#41;;

    y1_oos &#61; vcat&#40;y11, y12, y13&#41;;

    m21 &#61; machine&#40;:model2, corestrict&#40;Xs, f, 1&#41;, corestrict&#40;ys, f, 1&#41;&#41;
    m22 &#61; machine&#40;:model2, corestrict&#40;Xs, f, 2&#41;, corestrict&#40;ys, f, 2&#41;&#41;
    m23 &#61; machine&#40;:model2, corestrict&#40;Xs, f, 3&#41;, corestrict&#40;ys, f, 3&#41;&#41;
    y21 &#61; predict&#40;m21, restrict&#40;Xs, f, 1&#41;&#41;;
    y22 &#61; predict&#40;m22, restrict&#40;Xs, f, 2&#41;&#41;;
    y23 &#61; predict&#40;m23, restrict&#40;Xs, f, 3&#41;&#41;;

    y2_oos &#61; vcat&#40;y21, y22, y23&#41;;

    X_oos &#61; MLJ.table&#40;hcat&#40;y1_oos, y2_oos&#41;&#41;
    m_judge &#61; machine&#40;:judge, X_oos, ys&#41;

    m1 &#61; machine&#40;:model1, Xs, ys&#41;
    m2 &#61; machine&#40;:model2, Xs, ys&#41;

    y1 &#61; predict&#40;m1, Xs&#41;;
    y2 &#61; predict&#40;m2, Xs&#41;;
    X_judge &#61; MLJ.table&#40;hcat&#40;y1, y2&#41;&#41;
    yhat &#61; predict&#40;m_judge, X_judge&#41;

    return &#40;predict&#61;yhat,&#41;
end</code></pre><pre><code class="plaintext code-output">prefit (generic function with 8 methods)</code></pre>
<p>For convenience, we&#39;ll give this a keywork argument constructor:</p>
<pre><code class="language-julia">MyTwoModelStack&#40;; model1&#61;linear, model2&#61;knn, judge&#61;linear&#41; &#61;
    MyTwoModelStack&#40;model1, model2, judge&#41;</code></pre><pre><code class="plaintext code-output">MyTwoModelStack</code></pre>
<p>And this completes the definition of our re-usable stacking model type.</p>
<p>‎</p></div>
<div class="dropdown"><h2 id="applying_mytwomodelstack_to_some_data"><a href="#applying_mytwomodelstack_to_some_data" class="header-anchor">Applying <code>MyTwoModelStack</code> to some data</a></h2></div>
<div class="dropdown-content"><p>Without undertaking any hyperparameter optimization, we evaluate the performance of a tree boosting algorithm and a support vector machine on a synthetic data set. As adjudicator, we&#39;ll use a random forest.</p>
<p>We use a synthetic set to give an example where stacking is effective but the data is not too large. &#40;As synthetic data is based on perturbations to linear models, we are deliberately avoiding linear models in stacking illustration.&#41;</p>
<pre><code class="language-julia">X, y &#61; make_regression&#40;1000, 20; sparse&#61;0.75, noise&#61;0.1, rng&#61;StableRNG&#40;1&#41;&#41;;</code></pre>
<h4 id="define_the_stack_and_compare_performance"><a href="#define_the_stack_and_compare_performance" class="header-anchor">Define the stack and compare performance</a></h4>
<pre><code class="language-julia">avg &#61; MyAverageTwo&#40;tree_booster,svm&#41;
stack &#61; MyTwoModelStack&#40;model1&#61;tree_booster, model2&#61;svm, judge&#61;forest&#41;
all_models &#61; &#91;tree_booster, svm, forest, avg, stack&#93;;

for model in all_models
    print_performance&#40;model, X, y&#41;
end</code></pre><pre><code class="plaintext code-output">EvoTreeRegressor = 1.5015 ± 0.06594
EpsilonSVR = 1.06 ± 0.06462
RandomForestRegressor = 2.0783 ± 0.05788
MyAverageTwo = 1.1539 ± 0.0567
MyTwoModelStack = 0.85645 ± 0.0469
</code></pre>
<h4 id="tuning_a_stack"><a href="#tuning_a_stack" class="header-anchor">Tuning a stack</a></h4>
<p>A standard abuse of good data hygiene is to optimize stack component models <em>separately</em> and then tune the adjudicating model hyperparameters &#40;using the same resampling of the data&#41; with the base learners fixed. Although more computationally expensive, better generalization might be expected by applying tuning to the stack as a whole, either simultaneously, or in cheaper sequential steps. Since our stack is a stand-alone model, this is readily implemented.</p>
<p>As a proof of concept, let&#39;s see how to tune one of the base model hyperparameters, based on performance of the stack as a whole:</p>
<pre><code class="language-julia">r &#61; range&#40;stack, :&#40;model2.cost&#41;, lower &#61; 0.01, upper &#61; 10, scale&#61;:log&#41;
tuned_stack &#61; TunedModel&#40;
    model&#61;stack,
    ranges&#61;r,
    tuning&#61;Grid&#40;shuffle&#61;false&#41;,
    measure&#61;rms,
    resampling&#61;Holdout&#40;&#41;,
&#41;

mach &#61; fit&#33;&#40;machine&#40;tuned_stack,  X, y&#41;, verbosity&#61;0&#41;
best_stack &#61; fitted_params&#40;mach&#41;.best_model
best_stack.model2.cost</code></pre><pre><code class="plaintext code-output">10.000000000000002</code></pre>
<p>Let&#39;s evaluate the best stack using the same data resampling used to evaluate the various untuned models earlier &#40;now we are neglecting data hygiene&#33;&#41;:</p>
<pre><code class="language-julia">print_performance&#40;best_stack, X, y&#41;</code></pre><pre><code class="plaintext code-output">MyTwoModelStack = 0.84448 ± 0.04078
</code></pre>
<p>‎</p></div>

<div class="bottom-nav-container">
  <a id="prev-tutorial" style="text-decoration: none"><Button class="bottom-nav">
        <div>← Previous Tutorial</div>
        <div id="prev-label" class="button-label"> Home</div>
    </Button></a>
  <a id="next-tutorial" style="text-decoration: none"><Button class="bottom-nav">
        <div>Next Tutorial →</div>
        <div id="next-label" class="button-label">Home</div> 
    </Button></a>
</div>
<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom, Sebastian Vollmer and collaborators. Last modified: April 02, 2024. Website built with <a
      href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div></div><!-- CONTENT ENDS HERE -->
</div> <!-- end of id=main -->
</div> <!-- end of id=layout -->
<!-- for collapse functionality -->
<script src="/libs/collapse/collapse.js"></script>
<script src="/libs/pure/ui.min.js"></script>
<!-- head and footer-nav -->
<script src="/libs/nav/head.js"></script>
<script src="/libs/nav/footer-nav.js"></script>
<!-- landing page -->
<script src="/libs/landing/landing.js"></script>
<!-- navigation bar -->
<script src="/libs/nav/nav.js"></script>
<!-- responsive navigation bar -->
<script src="/libs/nav/responsive.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>


</body>

</html>