<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/DataScienceTutorials.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/franklin.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/pure.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/side-menu.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/extra.css"> <title>Tuning a model</title> <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script> <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script> <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/DataScienceTutorials.jl/" id=menu-logo-link > <div class=menu-logo > <img id=menu-logo  alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> <p><strong>MLJ Tutorials</strong></p> </div> </a> <form id=lunrSearchForm  name=lunrSearchForm > <input class=search-input  name=q  placeholder="Enter search term" type=text > <input type=submit  value=Search  formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden"> </form> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Data basics</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Loading data</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Data Frames</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Scientific Type</a> </ul> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Choosing a model</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Model tuning</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Composing models</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Stacking</a> </ul> <li class=pure-menu-sublist-title ><strong>Intro to Stats Learning</strong> <ul class=pure-menu-sublist  id=isl> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 2</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 3</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 4</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 5</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 6b</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 8</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 9</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 10</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist  id=e2e> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> AMES</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Wine</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Horse</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> King County Houses</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Airfoil </a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a> </ul> </ul> </div> </div> <div id=main > <div class=franklin-content ><h1 id=tuning_a_model ><a href="#tuning_a_model">Tuning a model</a></h1> <em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/notebooks/A-model-tuning.ipynb" target=_blank ><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/scripts/A-model-tuning-raw.jl" target=_blank ><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/scripts/A-model-tuning.jl" target=_blank ><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class=franklin-toc ><ol><li><a href="#tuning_a_single_hyperparameter">Tuning a single hyperparameter</a><ol><li><a href="#specifying_a_range_of_value">Specifying a range of value</a><li><a href="#fitting_and_inspecting_a_tuned_model">Fitting and inspecting a tuned model</a></ol><li><a href="#tuning_nested_hyperparameters">Tuning nested hyperparameters</a></ol></div> <h2 id=tuning_a_single_hyperparameter ><a href="#tuning_a_single_hyperparameter">Tuning a single hyperparameter</a></h2> <p>In MLJ, tuning is implemented as a model wrapper. After wrapping a model in a <em>tuning strategy</em> &#40;e.g. cross-validation&#41; and binding the wrapped model to data in a <em>machine</em>, fitting the machine initiates a search for optimal model hyperparameters.</p> <p>Let&#39;s use a decision tree classifier and tune the maximum depth of the tree. As usual, start by loading data and the model</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ
<span class=hljs-keyword >using</span> PrettyPrinting
X, y = <span class=hljs-meta >@load_iris</span>
<span class=hljs-meta >@load</span> DecisionTreeClassifier</code></pre><pre><code class="plaintext hljs">DecisionTreeClassifier(
    max_depth = -1,
    min_samples_leaf = 1,
    min_samples_split = 2,
    min_purity_increase = 0.0,
    n_subfeatures = 0,
    post_prune = false,
    merge_purity_threshold = 1.0,
    pdf_smoothing = 0.0,
    display_depth = 5) @ 8…90</code></pre> <h3 id=specifying_a_range_of_value ><a href="#specifying_a_range_of_value">Specifying a range of value</a></h3> <p>To specify a range of value, you can use the <code>range</code> function:</p> <pre><code class="julia hljs">dtc = DecisionTreeClassifier()
r   = range(dtc, :max_depth, lower=<span class=hljs-number >1</span>, upper=<span class=hljs-number >5</span>)</code></pre><pre><code class="plaintext hljs">MLJBase.NumericRange(Int64, :max_depth, ... )</code></pre>
<p>As you can see, the range function takes a model &#40;<code>dtc</code>&#41;, a symbol for the hyperparameter of interest &#40;<code>:max_depth</code>&#41; and indication of how to samples values. For hyperparameters of type <code>&lt;:Real</code>, you should specify a range of values as done above. For hyperparameters of other type &#40;e.g. <code>Symbol</code>&#41;, you should use the <code>values&#61;...</code> keyword.</p>
<p>Once a range of values has been defined, you can then wrap the model in a <code>TunedModel</code> specifying the tuning strategy:</p>
<pre><code class="julia hljs">tm = TunedModel(model=dtc, ranges=[r, ], measure=cross_entropy)</code></pre><pre><code class="plaintext hljs">ProbabilisticTunedModel(
    model = DecisionTreeClassifier(
            max_depth = -1,
            min_samples_leaf = 1,
            min_samples_split = 2,
            min_purity_increase = 0.0,
            n_subfeatures = 0,
            post_prune = false,
            merge_purity_threshold = 1.0,
            pdf_smoothing = 0.0,
            display_depth = 5),
    tuning = Grid(
            goal = nothing,
            resolution = 10,
            shuffle = true,
            rng = Random._GLOBAL_RNG()),
    resampling = Holdout(
            fraction_train = 0.7,
            shuffle = false,
            rng = Random._GLOBAL_RNG()),
    measure = cross_entropy(
            eps = 2.220446049250313e-16),
    weights = nothing,
    operation = MLJModelInterface.predict,
    range = MLJBase.NumericRange{Int64,MLJBase.Bounded,Symbol}[NumericRange{Int64,…} @ 2…26],
    train_best = true,
    repeats = 1,
    n = nothing,
    acceleration = CPU1{Nothing}(nothing),
    acceleration_resampling = CPU1{Nothing}(nothing),
    check_measure = true) @ 1…22</code></pre>
<h3 id=fitting_and_inspecting_a_tuned_model ><a href="#fitting_and_inspecting_a_tuned_model">Fitting and inspecting a tuned model</a></h3>
<p>To fit a tuned model, you can use the usual syntax:</p>
<pre><code class="julia hljs">m = machine(tm, X, y)
fit!(m)</code></pre><pre><code class="plaintext hljs">Machine{ProbabilisticTunedModel{Grid,…}} @ 1…92
</code></pre>
<p>In order to inspect the best model, you can use the function <code>fitted_params</code> on the machine and inspect the <code>best_model</code> field:</p>
<pre><code class="julia hljs">fitted_params(m).best_model.max_depth</code></pre><pre><code class="plaintext hljs">1</code></pre>
<p>Note that here we have tuned a probabilistic model and consequently used a probabilistic measure for the tuning. We could also have decided we only cared about the mode and the misclassification rate, to do this, just use <code>operation&#61;predict_mode</code> in the tuned model:</p>
<pre><code class="julia hljs">tm = TunedModel(model=dtc, ranges=r, operation=predict_mode,
                measure=misclassification_rate)
m = machine(tm, X, y)
fit!(m)
fitted_params(m).best_model.max_depth</code></pre><pre><code class="plaintext hljs">2</code></pre>
<p>Let&#39;s check the misclassification rate for the best model:</p>
<pre><code class="julia hljs">r = report(m)
r.best_result</code></pre><pre><code class="plaintext hljs">(measure = [misclassification_rate],
 measurement = [0.2],)</code></pre>
<p>Anyone wants plots? of course:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> PyPlot
figure(figsize=(<span class=hljs-number >8</span>,<span class=hljs-number >6</span>))
res = r.plotting <span class=hljs-comment ># contains all you need for plotting</span>
plot(res.parameter_values, res.measurements, ls=<span class=hljs-string >"none"</span>, marker=<span class=hljs-string >"o"</span>)

xticks(<span class=hljs-number >1</span>:<span class=hljs-number >5</span>, fontsize=<span class=hljs-number >12</span>)
yticks(fontsize=<span class=hljs-number >12</span>)
xlabel(<span class=hljs-string >"Maximum depth"</span>, fontsize=<span class=hljs-number >14</span>)
ylabel(<span class=hljs-string >"Misclassification rate"</span>, fontsize=<span class=hljs-number >14</span>)
ylim([<span class=hljs-number >0</span>, <span class=hljs-number >1</span>])</code></pre>
<img src="/DataScienceTutorials.jl/assets/getting-started/model-tuning/code/output/A-model-tuning-hpt.svg" alt="hyperparameter heatmap">
<h2 id=tuning_nested_hyperparameters ><a href="#tuning_nested_hyperparameters">Tuning nested hyperparameters</a></h2>
<p>Let&#39;s generate simple dummy regression data</p>
<pre><code class="julia hljs">X = (x1=rand(<span class=hljs-number >100</span>), x2=rand(<span class=hljs-number >100</span>), x3=rand(<span class=hljs-number >100</span>))
y = <span class=hljs-number >2</span>X.x1 - X.x2 + <span class=hljs-number >0.05</span> * randn(<span class=hljs-number >100</span>);</code></pre>
<p>Let&#39;s then build a simple ensemble model with decision tree regressors:</p>
<pre><code class="julia hljs">dtr = <span class=hljs-meta >@load</span> DecisionTreeRegressor
forest = EnsembleModel(atom=dtr)</code></pre><pre><code class="plaintext hljs">DeterministicEnsembleModel(
    atom = DecisionTreeRegressor(
            max_depth = -1,
            min_samples_leaf = 5,
            min_samples_split = 2,
            min_purity_increase = 0.0,
            n_subfeatures = 0,
            post_prune = false,
            merge_purity_threshold = 1.0),
    atomic_weights = Float64[],
    bagging_fraction = 0.8,
    rng = Random._GLOBAL_RNG(),
    n = 100,
    acceleration = CPU1{Nothing}(nothing),
    out_of_bag_measure = Any[]) @ 1…51</code></pre>
<p>Such a model has <em>nested</em> hyperparameters in that the ensemble has hyperparameters &#40;e.g. the <code>:bagging_fraction</code>&#41; and the atom has hyperparameters &#40;e.g. <code>:n_subfeatures</code> or <code>:max_depth</code>&#41;. You can see this by inspecting the parameters using <code>params</code>:</p>
<pre><code class="julia hljs">params(forest) |&gt; pprint</code></pre><pre><code class="plaintext hljs">(atom = (max_depth = -1,
         min_samples_leaf = 5,
         min_samples_split = 2,
         min_purity_increase = 0.0,
         n_subfeatures = 0,
         post_prune = false,
         merge_purity_threshold = 1.0),
 atomic_weights = [],
 bagging_fraction = 0.8,
 rng = Random._GLOBAL_RNG(),
 n = 100,
 acceleration = CPU1{Nothing}(nothing),
 out_of_bag_measure = [])</code></pre>
<p>Range for nested hyperparameters are specified using dot syntax, the rest is done in much the same way as before:</p>
<pre><code class="julia hljs">r1 = range(forest, :(atom.n_subfeatures), lower=<span class=hljs-number >1</span>, upper=<span class=hljs-number >3</span>)
r2 = range(forest, :bagging_fraction, lower=<span class=hljs-number >0.4</span>, upper=<span class=hljs-number >1.0</span>)
tm = TunedModel(model=forest, tuning=Grid(resolution=<span class=hljs-number >12</span>),
                resampling=CV(nfolds=<span class=hljs-number >6</span>), ranges=[r1, r2],
                measure=rms)
m = machine(tm, X, y)
fit!(m);</code></pre>
<p>A useful function to inspect a model after fitting it is the <code>report</code> function which collects information on the model and the tuning, for instance you can use it to recover the best measurement:</p>
<pre><code class="julia hljs">r = report(m)
r.best_result</code></pre><pre><code class="plaintext hljs">(measure = [rms],
 measurement = [0.1582066958450919],)</code></pre>
<p>Let&#39;s visualise this</p>
<pre><code class="julia hljs">figure(figsize=(<span class=hljs-number >8</span>,<span class=hljs-number >6</span>))

res = r.plotting

vals_sf = res.parameter_values[:, <span class=hljs-number >1</span>]
vals_bf = res.parameter_values[:, <span class=hljs-number >2</span>]

tricontourf(vals_sf, vals_bf, res.measurements)
xlabel(<span class=hljs-string >"Number of sub-features"</span>, fontsize=<span class=hljs-number >14</span>)
ylabel(<span class=hljs-string >"Bagging fraction"</span>, fontsize=<span class=hljs-number >14</span>)
xticks([<span class=hljs-number >1</span>, <span class=hljs-number >2</span>, <span class=hljs-number >3</span>], fontsize=<span class=hljs-number >12</span>)
yticks(fontsize=<span class=hljs-number >12</span>)</code></pre>
<img src="/DataScienceTutorials.jl/assets/getting-started/model-tuning/code/output/A-model-tuning-hm.svg" alt="Hyperparameter heatmap">
<div class=page-foot >
  <div class=copyright >
    &copy; Thibaut Lienart, Anthony Blaom and collaborators. Last modified: May 24, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div>
      </div> 
  </div> 
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>