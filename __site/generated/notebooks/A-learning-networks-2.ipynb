{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the environment\n",
    "corresponding to [this `Project.toml`](https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/master/Project.toml) and [this `Manifest.toml`](https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/master/Manifest.toml)\n",
    "so that you get an environment which matches the one used to generate the tutorials:\n",
    "\n",
    "```julia\n",
    "cd(\"DataScienceTutorials\") # cd to folder with the *.toml\n",
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminary steps\n",
    "\n",
    "Let's start as with the previous tutorial:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "using StableRNGs\n",
    "import DataFrames\n",
    "@load RidgeRegressor pkg=MultivariateStats\n",
    "\n",
    "rng = StableRNG(6616) # for reproducibility\n",
    "x1 = rand(rng, 300)\n",
    "x2 = rand(rng, 300)\n",
    "x3 = rand(rng, 300)\n",
    "y = exp.(x1 - x2 -2x3 + 0.1*rand(rng, 300))\n",
    "X = DataFrames.DataFrame(x1=x1, x2=x2, x3=x3)\n",
    "\n",
    "test, train = partition(eachindex(y), 0.8);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial we will show how to generate a model from a network; there are two approaches:\n",
    "* using the `@from_network` macro\n",
    "* writing the model in full\n",
    "\n",
    "the first approach should usually be the one considered as it's simpler.\n",
    "\n",
    "Generating a model from a network allows subsequent composition of that network with other tasks and tuning of that network.\n",
    "\n",
    "## Using the `@from_network` macro\n",
    "\n",
    "Let's define a simple network\n",
    "\n",
    "_Input layer_"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xs = source(X)\n",
    "ys = source(y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "_First layer_"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "std_model = Standardizer()\n",
    "stand = machine(std_model, Xs)\n",
    "W = MLJ.transform(stand, Xs)\n",
    "\n",
    "box_model = UnivariateBoxCoxTransformer()\n",
    "box_mach = machine(box_model, ys)\n",
    "z = MLJ.transform(box_mach, ys)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Second layer_"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ridge_model = RidgeRegressor(lambda=0.1)\n",
    "ridge = machine(ridge_model, W, z)\n",
    "ẑ = predict(ridge, W)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Output_"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ŷ = inverse_transform(box_mach, ẑ)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "No fitting has been done thus far, we have just defined a sequence of operations.\n",
    "\n",
    "As we show next, a learning network needs to be exported to create a new stand-alone model type. Instances of that type can be bound with data in a machine, which can then be evaluated, for example. Somewhat paradoxically, one can wrap a learning network in a certain kind of machine, called a learning network machine, before exporting it, and in fact, the export process actually requires us to do so. Since a composite model type does not yet exist, one constructs the machine using a \"surrogate\" model, whose name indicates the ultimate model supertype (Deterministic, Probabilistic, Unsupervised or Static). This surrogate model has no fields."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "surrogate = Deterministic()\n",
    "mach = machine(surrogate, Xs, ys; predict=ŷ)\n",
    "\n",
    "fit!(mach)\n",
    "predict(mach, X[test[1:5], :])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To form a model out of that network is easy using the `@from_network` macro.\n",
    "\n",
    "Having defined a learning network machine, mach, as above, the following code defines a new model subtype WrappedRegressor <: Supervised with a single field regressor"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@from_network mach begin\n",
    "    mutable struct CompositeModel\n",
    "        regressor=ridge_model\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The macro defines a constructor CompositeModel and attributes a name to the\n",
    "different models; the ordering / connection between the nodes is inferred\n",
    "from `ŷ` via the `<= ŷ`.\n",
    "\n",
    "**Note**: had the model been probabilistic (e.g. `RidgeClassifier`) you would have needed to add `is_probabilistic=true` at the end."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cm = machine(CompositeModel(), X, y)\n",
    "res = evaluate!(cm, resampling=Holdout(fraction_train=0.8, rng=51),\n",
    "                measure=rms)\n",
    "round(res.measurement[1], sigdigits=3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining a model from scratch\n",
    "\n",
    "An alternative to the `@from_network`, is to fully define a new model with its `fit` method:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mutable struct CompositeModel2 <: DeterministicNetwork\n",
    "    std_model::Standardizer\n",
    "    box_model::UnivariateBoxCoxTransformer\n",
    "    ridge_model::RidgeRegressor\n",
    "end\n",
    "\n",
    "function MLJ.fit(m::CompositeModel2, verbosity::Int, X, y)\n",
    "    Xs = source(X)\n",
    "    ys = source(y)\n",
    "    W = MLJ.transform(machine(m.std_model, Xs), Xs)\n",
    "    box = machine(m.box_model, ys)\n",
    "    z = MLJ.transform(box, ys)\n",
    "    ẑ = predict(machine(m.ridge_model, W, z), W)\n",
    "    ŷ = inverse_transform(box, ẑ)\n",
    "    mach = machine(Deterministic(), Xs, ys; predict=ŷ)\n",
    "    fit!(mach, verbosity=verbosity - 1)\n",
    "    return mach()\n",
    "end\n",
    "\n",
    "mdl = CompositeModel2(Standardizer(), UnivariateBoxCoxTransformer(),\n",
    "                      RidgeRegressor(lambda=0.1))\n",
    "cm = machine(mdl, X, y)\n",
    "res = evaluate!(cm, resampling=Holdout(fraction_train=0.8), measure=rms)\n",
    "round(res.measurement[1], sigdigits=3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Either way you now have a constructor to a  model which can be used as a stand-alone object, tuned and composed as you would with any basic model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  },
  "kernelspec": {
   "name": "julia-1.4",
   "display_name": "Julia 1.4.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
