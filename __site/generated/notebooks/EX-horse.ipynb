{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the environment\n",
    "corresponding to [this `Project.toml`](https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/master/Project.toml) and [this `Manifest.toml`](https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/master/Manifest.toml)\n",
    "so that you get an environment which matches the one used to generate the tutorials:\n",
    "\n",
    "```julia\n",
    "cd(\"MLJTutorials\") # cd to folder with the *.toml\n",
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Initial data processing\n",
    "\n",
    "In this example, we consider the [UCI \"horse colic\" dataset](https://archive.ics.uci.edu/ml/datasets/Horse+Colic)\n",
    "\n",
    "This is a reasonably messy classification problem with missing values etc and so some work should be expected in the feature processing.\n",
    "\n",
    "### Getting the data\n",
    "\n",
    "The data is pre-split in training and testing and we will keep it as such"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ, StatsBase\n",
    "MLJ.color_off() # hide\n",
    "using HTTP, CSV, DataFrames\n",
    "req1 = HTTP.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data\")\n",
    "req2 = HTTP.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.test\")\n",
    "header = [\"surgery\", \"age\", \"hospital_number\",\n",
    "    \"rectal_temperature\", \"pulse\",\n",
    "    \"respiratory_rate\", \"temperature_extremities\",\n",
    "    \"peripheral_pulse\", \"mucous_membranes\",\n",
    "    \"capillary_refill_time\", \"pain\",\n",
    "    \"peristalsis\", \"abdominal_distension\",\n",
    "    \"nasogastric_tube\", \"nasogastric_reflux\",\n",
    "    \"nasogastric_reflux_ph\", \"feces\", \"abdomen\",\n",
    "    \"packed_cell_volume\", \"total_protein\",\n",
    "    \"abdomcentesis_appearance\", \"abdomcentesis_total_protein\",\n",
    "    \"outcome\", \"surgical_lesion\", \"lesion_1\", \"lesion_2\", \"lesion_3\",\n",
    "    \"cp_data\"]\n",
    "csv_opts = (header=header, delim=' ', missingstring=\"?\",\n",
    "            ignorerepeated=true)\n",
    "data_train = CSV.read(req1.body; csv_opts...)\n",
    "data_test  = CSV.read(req2.body; csv_opts...)\n",
    "@show size(data_train)\n",
    "@show size(data_test)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Inspecting columns\n",
    "\n",
    "To simplify the analysis, we will drop the columns `Lesion *` as they would need specific re-encoding which would distract us a bit."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "unwanted = [:lesion_1, :lesion_2, :lesion_3]\n",
    "data = vcat(data_train, data_test)\n",
    "select!(data, Not(unwanted));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's also keep track of the initial train-test split"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train = 1:nrows(data_train)\n",
    "test = last(train) .+ (1:nrows(data_test));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We know from reading the description that some of these features represent multiclass data; to facilitate the interpretation, we can use `autotype` from `ScientificTypes`.\n",
    "By default, `autotype` will check all columns and suggest a Finite type assuming there are relatively few distinct values in the column.\n",
    "More sophisticated rules can be passed, see [ScientificTypes.jl](https://alan-turing-institute.github.io/ScientificTypes.jl/dev/):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "datac = coerce(data, autotype(data));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's see column by column whether it looks ok now"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sch = schema(datac)\n",
    "for (name, scitype) in zip(sch.names, sch.scitypes)\n",
    "    println(rpad(\"$name\", 30), scitype)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Most columns are now treated as either Multiclass or Ordered, this\n",
    "corresponds to the [description of the data](https://archive.ics.uci.edu/ml/datasets/Horse+Colic). For instance:\n",
    "\n",
    "- `Surgery` is described as `1=yes / 2=no`\n",
    "- `Age` is described as `1=adult / 2=young`\n",
    "\n",
    "Inspecting the rest of the descriptions and the current scientific type,\n",
    "there are a few more things that can be observed:\n",
    "\n",
    "- hospital number is still a count, this means that there are relatively many hospitals and so  that's  probably not very useful,\n",
    "- pulse and respiratory rate are still as count but the data description suggests that they can be considered as continuous"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "length(unique(datac.hospital_number))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "yeah let's drop that"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "datac = select!(datac, Not(:hospital_number));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "let's also coerce the pulse and respiratory rate, in fact we can do that with\n",
    "`autotype` specifying as rule the `discrete_to_continuous`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "datac = coerce(datac, autotype(datac, rules=(:discrete_to_continuous,)));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Dealing with missing values\n",
    "\n",
    "There's quite a lot of missing values, in this tutorial we'll be a bit rough in how we deal with them applying the following rules of thumb:\n",
    "\n",
    "- drop the rows where the outcome is unknown\n",
    "- drop columns with more than 20% missing values\n",
    "- simple imputation of whatever's left"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "missing_outcome = ismissing.(datac.outcome)\n",
    "idx_missing_outcome = missing_outcome |> findall"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Ok there's only two row which is nice, let's remove them from the train/test indices and drop the rows"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train = setdiff!(train |> collect, idx_missing_outcome)\n",
    "test = setdiff!(test |> collect, idx_missing_outcome)\n",
    "datac = datac[.!missing_outcome, :];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Now let's look at how many missings there are per features"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for name in names(datac)\n",
    "    col = datac[:, name]\n",
    "    ratio_missing = sum(ismissing.(col)) / nrows(datac) * 100\n",
    "    println(rpad(name, 30), round(ratio_missing, sigdigits=3))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's drop the ones with more than 20% (quite a few!)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "unwanted = [:peripheral_pulse, :nasogastric_tube, :nasogastric_reflux,\n",
    "        :nasogastric_reflux_ph, :feces, :abdomen, :abdomcentesis_appearance, :abdomcentesis_total_protein]\n",
    "select!(datac, Not(unwanted));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Note that we could have done this better and investigated the nature of the features for which there's a lot of missing values but don't forget that our goal is to showcase MLJ!\n",
    "\n",
    "Let's conclude by filling all missing values and separating the feature matrix from the  target"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@load FillImputer\n",
    "filler = machine(FillImputer(), datac)\n",
    "fit!(filler)\n",
    "datac = transform(filler, datac)\n",
    "\n",
    "y, X = unpack(datac, ==(:outcome), name->true);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## A baseline model\n",
    "\n",
    "Let's define a first sensible model and get a baseline, basic steps are:\n",
    "- one-hot-encode the categoricals\n",
    "- feed all this into a classifier"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@load OneHotEncoder\n",
    "@load MultinomialClassifier pkg=\"MLJLinearModels\""
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's have convenient handles over the training data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xtrain = X[train,:]\n",
    "ytrain = y[train];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "And let's define a pipeline corresponding to the operations above"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@pipeline SimplePipe(hot = OneHotEncoder(),\n",
    "                     clf = MultinomialClassifier()) is_probabilistic=true\n",
    "mach = machine(SimplePipe(), Xtrain, ytrain)\n",
    "res = evaluate!(mach; resampling=Holdout(fraction_train=0.9),\n",
    "                measure=cross_entropy)\n",
    "round(res.measurement[1], sigdigits=3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "This is the cross entropy on some held-out 10% of the training set.\n",
    "We can also just for the sake of getting a baseline, see the misclassification on the whole training data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ŷ = predict_mode(mach, Xtrain)\n",
    "mcr = misclassification_rate(ŷ, ytrain)\n",
    "println(rpad(\"MNC mcr:\", 10), round(mcr, sigdigits=3))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "That's not bad at all actually.\n",
    "Let's tune it a bit and see if we can get a bit better than that, not much point in going crazy, we might get a few percents but not much more."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = SimplePipe()\n",
    "lambdas = range(model, :(clf.lambda), lower=1e-3, upper=100, scale=:log10)\n",
    "tm = TunedModel(model=SimplePipe(), ranges=lambdas, measure=cross_entropy)\n",
    "mtm = machine(tm, Xtrain, ytrain)\n",
    "fit!(mtm)\n",
    "best_pipe = fitted_params(mtm).best_model"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "So it looks like it's useful to regularise a fair bit to get a lower cross entropy"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ŷ = MLJ.predict(mtm, Xtrain)\n",
    "cross_entropy(ŷ, ytrain) |> mean"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Interestingly this does not improve our missclassification rate"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mcr = misclassification_rate(mode.(ŷ), ytrain)\n",
    "println(rpad(\"MNC mcr:\", 10), round(mcr, sigdigits=3))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We've probably reached the limit of a simple linear model.\n",
    "\n",
    "## Trying another model\n",
    "\n",
    "There are lots of categoricals, so maybe  it's just better to use something that deals well with that like a tree-based classifier."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@load XGBoostClassifier\n",
    "dtc = machine(XGBoostClassifier(), Xtrain, ytrain)\n",
    "fit!(dtc)\n",
    "ŷ = MLJ.predict(dtc, Xtrain)\n",
    "cross_entropy(ŷ, ytrain) |> mean"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "So we get a worse cross entropy but..."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "misclassification_rate(mode.(ŷ), ytrain)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "a significantly better misclassification rate.\n",
    "\n",
    "We could investigate more, do more tuning etc, but the key points of this tutorial was to show how to handle data with missing values."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0-DEV.350"
  },
  "kernelspec": {
   "name": "julia-1.5",
   "display_name": "Julia 1.5.0-DEV.350",
   "language": "julia"
  }
 },
 "nbformat": 4
}
