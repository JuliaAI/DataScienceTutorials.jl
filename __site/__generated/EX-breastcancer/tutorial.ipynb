{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the\n",
    "tutorial-specific package environment, using this\n",
    "[`Project.toml`](https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-breastcancer/Project.toml) and\n",
    "[this `Manifest.toml`](https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-breastcancer/Manifest.toml), or by following\n",
    "[these](https://juliaai.github.io/DataScienceTutorials.jl/#learning_by_doing) detailed instructions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "@@dropdown\n",
    "## Introduction\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial covers programmatic model selection on the popular [\"Breast Cancer\n",
    "Wisconsin (Diagnostic) Data\n",
    "Set\"](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) from\n",
    "the UCI archives. The tutorial also covers basic data preprocessing and usage of MLJ\n",
    "Scientific Types."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Loading the relevant packages\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using UrlDownload\n",
    "using DataFrames\n",
    "using MLJ\n",
    "using StatsBase\n",
    "using StableRNGs # for an RNG stable across julia versions"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Downloading and loading the data\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the package UrlDownload.jl, we can capture the data from the given link using the below commands."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\";\n",
    "feature_names = [\"ID\", \"Class\", \"mean radius\", \"mean texture\", \"mean perimeter\", \"mean area\", \"mean smoothness\", \"mean compactness\", \"mean concavity\", \"mean concave points\", \"mean symmetry\", \"mean fractal dimension\", \"radius error\", \"texture error\", \"perimeter error\", \"area error\", \"smoothness error\", \"compactness error\", \"concavity error\", \"concave points error\", \"symmetry error\", \"fractal dimension error\", \"worst radius\", \"worst texture\", \"worst perimeter\", \"worst area\", \"worst smoothness\", \"worst compactness\", \"worst concavity\", \"worst concave points\", \"worst symmetry\", \"worst fractal dimension\"]\n",
    "data = urldownload(url, true, format = :CSV, header = feature_names);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Exploring the obtained data\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "@@dropdown\n",
    "### Inspecting the class variable\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots\n",
    "\n",
    "Plots.bar(countmap(data.Class), legend=false,)\n",
    "xlabel!(\"Classes\")\n",
    "ylabel!(\"Number of samples\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\figalt{Distribution of target classes}{Target_class.svg}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "### Inspecting the feature set\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df = DataFrame(data)[:, 2:end];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Printing the 1st 10 rows so as to get a visual idea about the type of data we're dealing\n",
    "with"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "first(df,10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For checking the statistical attributes of each inividual feature, we can use the\n",
    "__decsribe()__ method"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "describe(df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see the feature set consists of varying features that have different ranges\n",
    "and quantiles. This can cause trouble for the optimization techniques and might cause\n",
    "convergence issues. We can use a feature scaling technique like __Standardizer()__ to\n",
    "handle this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "But first, let's handle the [scientific\n",
    "types](https://alan-turing-institute.github.io/ScientificTypes.jl/dev/) of all the\n",
    "features. We can use the `schema()` method from MLJ.jl package to do this"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As `Textual` is a sciytype reserved for text data \"with sentiment\", we need to `coerce`\n",
    "the scitype to the more appropriate `OrderedFactor`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(df, :Class => OrderedFactor{2});\n",
    "scitype(df.Class)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Unpacking the values\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that our data is fully processed, we can separate the target variable 'y' from the\n",
    "feature set 'X' using the __unpack()__ method."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rng = StableRNG(123)\n",
    "y, X = unpack(df, ==(:Class); rng);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll be using 80% of data for training, and can perform a train-test split using the\n",
    "`partition` method:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train, test = partition(eachindex(y), 0.8; rng)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Standardizing the \"feature set\"\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that our feature set is separated from the target variable, we can use\n",
    "the`Standardizer()` worklow to obtain to standardize our feature set `X`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "transformer_instance = Standardizer()\n",
    "transformer_model = machine(transformer_instance, X[train,:])\n",
    "fit!(transformer_model)\n",
    "X = MLJ.transform(transformer_model, X);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Train-test split\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With feature scaling complete, we are ready to compare the performance of various\n",
    "machine learning models for classification."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Model compatibility\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have separate training and testing set, let's see the models compatible with our data!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models(matching(X, y))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "## Analyzing the performance of different models\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thats a lot of models for our data! To narrow it down, we'll analyze the performance of\n",
    "probablistic predictors with pure julia implementations:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "@@dropdown\n",
    "### Creating various empty vectors for our analysis\n",
    "@@\n",
    "@@dropdown-content\n",
    "- `model_names`: captures the names of the models being evaluated\n",
    "- `accuracies`: accuracies of the value of the model accuracy on the test set\n",
    "- `log_losses`: values of the log loss (cross entropy) on the test set\n",
    "- `f1_scores`:  captures the values of F1-Score on the test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model_names=Vector{String}();\n",
    "accuracies=[];\n",
    "log_losses=[];\n",
    "f1_scores=[];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "### Collecting data for analysis\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models_to_evaluate = models(matching(X, y)) do m\n",
    "    m.prediction_type==:probabilistic && m.is_pure_julia &&\n",
    "        m.package_name != \"SIRUS\"\n",
    "end\n",
    "\n",
    "p = plot(legendfontsize=7, title=\"ROC Curve\")\n",
    "plot!([0, 1], [0, 1], linewidth=2, linestyle=:dash, color=:black)\n",
    "for m in models_to_evaluate\n",
    "    model=m.name\n",
    "    pkg = m.package_name\n",
    "    model_name = \"$model ($pkg)\"\n",
    "    @info \"Evaluating $model_name. \"\n",
    "    eval(:(clf = @load $model pkg=$pkg verbosity=0))\n",
    "\n",
    "    clf_machine = machine(clf(), X, y)\n",
    "    fit!(clf_machine, rows=train, verbosity=0)\n",
    "\n",
    "    y_pred = MLJ.predict(clf_machine, rows=test);\n",
    "\n",
    "    fprs, tprs, thresholds = roc_curve(y_pred, y[test])\n",
    "    plot!(p, fprs, tprs,label=model_name)\n",
    "    gui()\n",
    "\n",
    "    push!(model_names, model_name)\n",
    "    push!(accuracies, accuracy(mode.(y_pred), y[test]))\n",
    "    push!(log_losses, log_loss(y_pred,y[test]))\n",
    "    push!(f1_scores, f1score(mode.(y_pred), y[test]))\n",
    "end\n",
    "\n",
    "#Adding labels and legend to the ROC-AUC curve\n",
    "xlabel!(\"False Positive Rate (positive=malignant)\")\n",
    "ylabel!(\"True Positive Rate\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\figalt{ROC-AUC Curve}{breastcancer_auc_curve.svg}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@\n",
    "@@dropdown\n",
    "### Inspecting results\n",
    "@@\n",
    "@@dropdown-content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's collect the data in form a dataframe for a more precise analysis"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model_comparison=DataFrame(\n",
    "    ModelName=model_names,\n",
    "    Accuracy=accuracies,\n",
    "    LogLoss=log_losses,\n",
    "    F1Score=f1_scores\n",
    ");"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's sort the data on basis of the log loss:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sort!(model_comparison, [:LogLoss])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "‎\n",
    "@@"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
