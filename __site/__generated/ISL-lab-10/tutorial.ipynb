{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the\n",
    "tutorial-specific package environment, using this\n",
    "[`Project.toml`](https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-10/Project.toml) and\n",
    "[this `Manifest.toml`](https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-10/Manifest.toml), or by following\n",
    "[these](https://juliaai.github.io/DataScienceTutorials.jl/#learning_by_doing) detailed instructions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting started"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "import RDatasets: dataset\n",
    "import DataFrames: DataFrame, select, Not, describe\n",
    "using Random\n",
    "\n",
    "data = dataset(\"datasets\", \"USArrests\")\n",
    "names(data)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's have a look at the mean and standard deviation of each feature:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "describe(data, :mean, :std)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's extract the numerical component and coerce"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = select(data, Not(:State))\n",
    "X = coerce(X, :UrbanPop=>Continuous, :Assault=>Continuous);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA pipeline\n",
    "\n",
    "PCA is usually best done after standardization but we won't do it here:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "PCA = @load PCA pkg=MultivariateStats\n",
    "\n",
    "pca_mdl = PCA(pratio=1)\n",
    "pca = machine(pca_mdl, X)\n",
    "fit!(pca)\n",
    "PCA\n",
    "W = MLJ.transform(pca, X);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "W is the PCA'd data; here we've used default settings for PCA and it has recovered 2 components:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(W).names"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's inspect the fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = report(pca)\n",
    "cumsum(r.principalvars ./ r.tvar)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the second line we look at the explained variance with 1 then 2 PCA features and it seems that with 2 we almost completely recover all of the variance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More interesting data..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instead of just playing with toy data, let's load the orange juice data and extract only the columns corresponding to price data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = dataset(\"ISLR\", \"OJ\")\n",
    "\n",
    "feature_names = [\n",
    "    :PriceCH, :PriceMM, :DiscCH, :DiscMM, :SalePriceMM, :SalePriceCH,\n",
    "    :PriceDiff, :PctDiscMM, :PctDiscCH\n",
    "]\n",
    "\n",
    "X = select(data, feature_names);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PCA pipeline"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Random.seed!(1515)\n",
    "\n",
    "SPCA = Pipeline(\n",
    "    Standardizer(),\n",
    "    PCA(pratio=1-1e-4)\n",
    ")\n",
    "\n",
    "spca = machine(SPCA, X)\n",
    "fit!(spca)\n",
    "W = MLJ.transform(spca, X)\n",
    "names(W)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "What kind of variance can we explain?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rpca = collect(values(report(spca).report_given_machine))[2]\n",
    "cs = cumsum(rpca.principalvars ./ rpca.tvar)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visualise this"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using PyPlot\n",
    "\n",
    "figure(figsize=(8,6))\n",
    "\n",
    "PyPlot.bar(1:length(cs), cs)\n",
    "plot(1:length(cs), cs, color=\"red\", marker=\"o\")\n",
    "\n",
    "xlabel(\"Number of PCA features\", fontsize=14)\n",
    "ylabel(\"Ratio of explained variance\", fontsize=14)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\figalt{PCA explained variance}{ISL-lab-10-g1.svg}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So 4 PCA features are enough to recover most of the variance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clustering"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Random.seed!(1515)\n",
    "\n",
    "KMeans = @load KMeans pkg=Clustering\n",
    "SPCA2 = Pipeline(\n",
    "    Standardizer(),\n",
    "    PCA(),\n",
    "    KMeans(k=3)\n",
    ")\n",
    "\n",
    "spca2 = machine(SPCA2, X)\n",
    "fit!(spca2)\n",
    "\n",
    "assignments = collect(values(report(spca2).report_given_machine))[3].assignments\n",
    "mask1 = assignments .== 1\n",
    "mask2 = assignments .== 2\n",
    "mask3 = assignments .== 3;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can  try visualising this"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using PyPlot\n",
    "\n",
    "figure(figsize=(8, 6))\n",
    "for (m, c) in zip((mask1, mask2, mask3), (\"red\", \"green\", \"blue\"))\n",
    "    plot(W[m, 1], W[m, 2], ls=\"none\", marker=\".\", markersize=10, color=c)\n",
    "end\n",
    "\n",
    "xlabel(\"PCA-1\", fontsize=13)\n",
    "ylabel(\"PCA-2\", fontsize=13)\n",
    "legend([\"Group 1\", \"Group 2\", \"Group 3\"], fontsize=13)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\fig{ISL-lab-10-cluster.svg}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "kernelspec": {
   "name": "julia-1.7",
   "display_name": "Julia 1.7.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
