{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the\n",
    "environment with [this `Project.toml`](https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-ensembles-3/Project.toml) and\n",
    "[this `Manifest.toml`](https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/A-ensembles-3/Manifest.toml).\n",
    "For instance, copy these files to a folder 'A-ensembles-3', `cd` to it and\n",
    "\n",
    "```julia\n",
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [,
    "Pkg.activate(\"_literate/A-ensembles-3/Project.toml\")\n",
    "Pkg.update()\n",
    "macro OUTPUT()\n",
    "    return isdefined(Main, :Franklin) ? Franklin.OUT_PATH[] : \"/tmp/\"\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple example of a homogeneous ensemble using learning networks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this simple example, no bagging is used, so every atomic model\n",
    "gets the same learned parameters, unless the atomic model training\n",
    "algorithm has randomness, eg, DecisionTree with random subsampling\n",
    "of features at nodes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that MLJ has a built in model wrapper called `EnsembleModel`\n",
    "for creating bagged ensembles with a few lines of code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definition of composite model type"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "using PyPlot\n",
    "import Statistics"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the learning network (composite model spec):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xs = source()\n",
    "ys = source()\n",
    "\n",
    "DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\n",
    "atom = DecisionTreeRegressor()\n",
    "\n",
    "machines = (machine(atom, Xs, ys) for i in 1:100)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overloading `mean` for nodes:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Statistics.mean(v...) = mean(v)\n",
    "Statistics.mean(v::AbstractVector{<:AbstractNode}) = node(mean, v...)\n",
    "\n",
    "yhat = mean([predict(m, Xs) for  m in machines]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the new composite model type and instance:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "surrogate = Deterministic()\n",
    "mach = machine(surrogate, Xs, ys; predict=yhat)\n",
    "\n",
    "@from_network mach begin\n",
    "    mutable struct OneHundredModels\n",
    "        atom=atom\n",
    "    end\n",
    "end\n",
    "\n",
    "one_hundred_models = OneHundredModels()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Application to data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X, y = @load_boston;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "tune regularization parameter for a *single* tree:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = range(atom,\n",
    "          :min_samples_split,\n",
    "          lower=2,\n",
    "          upper=100, scale=:log)\n",
    "\n",
    "mach = machine(atom, X, y)\n",
    "\n",
    "curve = learning_curve!(mach,\n",
    "                        range=r,\n",
    "                        measure=mav,\n",
    "                        resampling=CV(nfolds=9),\n",
    "                        verbosity=0)\n",
    "\n",
    "plot(curve.parameter_values, curve.measurements)\n",
    "xlabel(curve.parameter_name)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\fig{e1.svg}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "tune regularization parameter for all trees in ensemble simultaneously:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = range(one_hundred_models,\n",
    "          :(atom.min_samples_split),\n",
    "          lower=2,\n",
    "          upper=100, scale=:log)\n",
    "\n",
    "mach = machine(one_hundred_models, X, y)\n",
    "\n",
    "curve = learning_curve!(mach,\n",
    "                        range=r,\n",
    "                        measure=mav,\n",
    "                        resampling=CV(nfolds=9),\n",
    "                        verbosity=0)\n",
    "\n",
    "plot(curve.parameter_values, curve.measurements)\n",
    "xlabel(curve.parameter_name)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\fig{e2}"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0-DEV.271"
  },
  "kernelspec": {
   "name": "julia-1.8",
   "display_name": "Julia 1.8.0-DEV.271",
   "language": "julia"
  }
 },
 "nbformat": 4
}
