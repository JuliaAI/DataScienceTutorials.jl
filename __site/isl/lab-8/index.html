<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/DataScienceTutorials.jl/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/franklin.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/pure.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/side-menu.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/extra.css">
  <!-- <link rel="icon" href="/DataScienceTutorials.jl/assets/infra/favicon.gif"> -->
   <title>Lab 8 - Tree-based models</title>  
  <!-- LUNR -->
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/DataScienceTutorials.jl/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class="pure-menu-link"><strong>Home</strong></a></li>

    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/processing/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data processing</a></li>
    </ul>

    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Stacking</a></li>
    </ul>

    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>

    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> King County Houses</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Airfoil </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/powergen/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Power Generation </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-flux" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->
<div class="franklin-content"><h1 id="lab_8_-_tree-based_models"><a href="#lab_8_-_tree-based_models">Lab 8 - Tree-based models</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/notebooks/ISL-lab-8.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/ISL-lab-8-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/ISL-lab-8.jl" target="_blank"><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="franklin-toc"><ol><li><a href="#getting_started">Getting started</a><ol><li><a href="#decision_tree_classifier">Decision Tree Classifier</a></li><li><a href="#tuning_a_dtc">Tuning a DTC</a></li><li><a href="#decision_tree_regressor">Decision Tree Regressor</a></li></ol></li><li><a href="#random_forest">Random Forest</a></li><li><a href="#gradient_boosting_machine">Gradient Boosting Machine</a></li></ol></div><h2 id="getting_started"><a href="#getting_started">Getting started</a></h2>
<pre><code class="language-julia">using MLJ
import RDatasets: dataset
using PrettyPrinting
import DataFrames: DataFrame, select, Not
@load DecisionTreeClassifier pkg=DecisionTree

carseats = dataset("ISLR", "Carseats")

first(carseats, 3) |> pretty</code></pre><pre><code class="plaintext">┌────────────┬────────────┬────────────┬─────────────┬────────────┬────────────┬──────────────────────────────────────────────────┬────────────┬────────────┬──────────────────────────────────────────────────┬──────────────────────────────────────────────────┐
│ Sales      │ CompPrice  │ Income     │ Advertising │ Population │ Price      │ ShelveLoc                                        │ Age        │ Education  │ Urban                                            │ US                                               │
│ Float64    │ Float64    │ Float64    │ Float64     │ Float64    │ Float64    │ CategoricalArrays.CategoricalValue{String,UInt8} │ Float64    │ Float64    │ CategoricalArrays.CategoricalValue{String,UInt8} │ CategoricalArrays.CategoricalValue{String,UInt8} │
│ Continuous │ Continuous │ Continuous │ Continuous  │ Continuous │ Continuous │ Multiclass{3}                                    │ Continuous │ Continuous │ Multiclass{2}                                    │ Multiclass{2}                                    │
├────────────┼────────────┼────────────┼─────────────┼────────────┼────────────┼──────────────────────────────────────────────────┼────────────┼────────────┼──────────────────────────────────────────────────┼──────────────────────────────────────────────────┤
│ 9.5        │ 138.0      │ 73.0       │ 11.0        │ 276.0      │ 120.0      │ Bad                                              │ 42.0       │ 17.0       │ Yes                                              │ Yes                                              │
│ 11.22      │ 111.0      │ 48.0       │ 16.0        │ 260.0      │ 83.0       │ Good                                             │ 65.0       │ 10.0       │ Yes                                              │ Yes                                              │
│ 10.06      │ 113.0      │ 35.0       │ 10.0        │ 269.0      │ 80.0       │ Medium                                           │ 59.0       │ 12.0       │ Yes                                              │ Yes                                              │
└────────────┴────────────┴────────────┴─────────────┴────────────┴────────────┴──────────────────────────────────────────────────┴────────────┴────────────┴──────────────────────────────────────────────────┴──────────────────────────────────────────────────┘
</code></pre>
<p>We encode a new variable <code>High</code> based on whether the sales are higher or lower than 8 and add that column to the dataframe:</p>
<pre><code class="language-julia">High = ifelse.(carseats.Sales .<= 8, "No", "Yes") |> categorical;
carseats[!, :High] = High;</code></pre>
<p>Let&#39;s now train a basic decision tree classifier for <code>High</code> given the other features after one-hot-encoding the categorical features:</p>
<pre><code class="language-julia">X = select(carseats, Not([:Sales, :High]))
y = carseats.High;</code></pre>
<h3 id="decision_tree_classifier"><a href="#decision_tree_classifier">Decision Tree Classifier</a></h3>
<pre><code class="language-julia">HotTreeClf = @pipeline(OneHotEncoder(),
                       DecisionTreeClassifier())

mdl = HotTreeClf
mach = machine(mdl, X, y)
fit!(mach);</code></pre>
<p>Note that this is trained on the whole data.</p>
<pre><code class="language-julia">ypred = predict_mode(mach, X)
misclassification_rate(ypred, y)</code></pre><pre><code class="plaintext">0.0</code></pre>
<p>That&#39;s right... it gets it perfectly; this tends to be classic behaviour for a DTC to overfit the data it&#39;s trained on. Let&#39;s see if it generalises:</p>
<pre><code class="language-julia">train, test = partition(eachindex(y), 0.5, shuffle=true, rng=333)
fit!(mach, rows=train)
ypred = predict_mode(mach, rows=test)
misclassification_rate(ypred, y[test])</code></pre><pre><code class="plaintext">0.265</code></pre>
<p>Not really...</p>
<h3 id="tuning_a_dtc"><a href="#tuning_a_dtc">Tuning a DTC</a></h3>
<p>Let&#39;s try to do a bit of tuning</p>
<pre><code class="language-julia">r_mpi = range(mdl, :(decision_tree_classifier.max_depth), lower=1, upper=10)
r_msl = range(mdl, :(decision_tree_classifier.min_samples_leaf), lower=1, upper=50)

tm = TunedModel(model=mdl, ranges=[r_mpi, r_msl], tuning=Grid(resolution=8),
                resampling=CV(nfolds=5, rng=112),
                operation=predict_mode, measure=misclassification_rate)
mtm = machine(tm, X, y)
fit!(mtm, rows=train)

ypred = predict_mode(mtm, rows=test)
misclassification_rate(ypred, y[test])</code></pre><pre><code class="plaintext">0.26</code></pre>
<p>We can inspect the parameters of the best model</p>
<pre><code class="language-julia">fitted_params(mtm).best_model.decision_tree_classifier</code></pre><pre><code class="plaintext">DecisionTreeClassifier(
    max_depth = 10,
    min_samples_leaf = 1,
    min_samples_split = 2,
    min_purity_increase = 0.0,
    n_subfeatures = 0,
    post_prune = false,
    merge_purity_threshold = 1.0,
    pdf_smoothing = 0.0,
    display_depth = 5) @341</code></pre>
<h3 id="decision_tree_regressor"><a href="#decision_tree_regressor">Decision Tree Regressor</a></h3>
<pre><code class="language-julia">@load DecisionTreeRegressor pkg=DecisionTree

boston = dataset("MASS", "Boston")

y, X = unpack(boston, ==(:MedV), col -> true)

train, test = partition(eachindex(y), 0.5, shuffle=true, rng=551);

scitype(X)</code></pre><pre><code class="plaintext">Table{Union{AbstractArray{Continuous,1}, AbstractArray{Count,1}}}</code></pre>
<p>Let&#39;s recode the Count as Continuous and then fit a DTR</p>
<pre><code class="language-julia">X = coerce(X, autotype(X, rules=(:discrete_to_continuous,)))

dtr_model = DecisionTreeRegressor()
dtr = machine(dtr_model, X, y)

fit!(dtr, rows=train)

ypred = predict(dtr, rows=test)
round(rms(ypred, y[test]), sigdigits=3)</code></pre><pre><code class="plaintext">4.98</code></pre>
<p>Again we can try tuning this a bit, since it&#39;s the same idea as before, let&#39;s just try to adjust the depth of the tree:</p>
<pre><code class="language-julia">r_depth = range(dtr_model, :max_depth, lower=2, upper=20)

tm = TunedModel(model=dtr_model, ranges=[r_depth], tuning=Grid(resolution=10),
                resampling=CV(nfolds=5, rng=1254), measure=rms)
mtm = machine(tm, X, y)

fit!(mtm, rows=train)

ypred = predict(mtm, rows=test)
round(rms(ypred, y[test]), sigdigits=3)</code></pre><pre><code class="plaintext">4.98</code></pre>
<h2 id="random_forest"><a href="#random_forest">Random Forest</a></h2>
<p><strong>Note</strong>: the package <a href="https://github.com/bensadeghi/DecisionTree.jl"><code>DecisionTree.jl</code></a> also has a RandomForest model but it is not yet interfaced with in MLJ.</p>
<pre><code class="language-julia">@load RandomForestRegressor pkg=ScikitLearn

rf_mdl = RandomForestRegressor()
rf = machine(rf_mdl, X, y)
fit!(rf, rows=train)

ypred = predict(rf, rows=test)
round(rms(ypred, y[test]), sigdigits=3)</code></pre><pre><code class="plaintext">3.86</code></pre>
<h2 id="gradient_boosting_machine"><a href="#gradient_boosting_machine">Gradient Boosting Machine</a></h2>
<pre><code class="language-julia">@load XGBoostRegressor

xgb_mdl = XGBoostRegressor(num_round=10, max_depth=10)
xgb = machine(xgb_mdl, X, y)
fit!(xgb, rows=train)

ypred = predict(xgb, rows=test)
round(rms(ypred, y[test]), sigdigits=3)</code></pre><pre><code class="plaintext">3.96</code></pre>
<p>Again we could do some tuning for this.<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom, Sebastian Vollmer and collaborators. Last modified: July 14, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>
  
  
      <script src="/DataScienceTutorials.jl/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
