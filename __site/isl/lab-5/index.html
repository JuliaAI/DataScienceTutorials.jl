<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/css/franklin.css">
  <link rel="stylesheet" href="/css/pure.css">
  <link rel="stylesheet" href="/css/side-menu.css">
  <link rel="stylesheet" href="/css/extra.css">
  <!-- <link rel="icon" href="/assets/infra/favicon.gif"> -->
   <title>Lab 5 - Cross validation and the bootstrap</title>  
  <!-- LUNR -->
  <script src="/libs/lunr/lunr.min.js"></script>
  <script src="/libs/lunr/lunr_index.js"></script>
  <script src="/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/" id="menu-logo-link">
          <div class="menu-logo">
            <img id="menu-logo" alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" />
            <p><strong>MLJ Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/search.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/" class="pure-menu-link"><strong>Home</strong></a></li>
    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/data/dataframe/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/data/categorical/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/data/scitype/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
    </ul>
    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/getting-started/choosing-a-model/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/getting-started/fit-and-predict/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/getting-started/model-tuning/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/getting-started/ensembles/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/getting-started/ensembles-2/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/getting-started/composing-models/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/getting-started/learning-networks/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/getting-started/learning-networks-2/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
    </ul>
    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/isl/lab-2/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-3/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-4/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-5/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-6b/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-8/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-9/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-10/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>
    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/end-to-end/AMES/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/wine/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/crabs-xgb/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/horse/index.html" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->

<div class="franklin-content">
<h1 id="lab_5_-_cross_validation_and_the_bootstrap"><a href="/isl/lab-5/index.html#lab_5_-_cross_validation_and_the_bootstrap">Lab 5 - Cross validation and the bootstrap</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/notebooks/ISL-lab-5.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/scripts/ISL-lab-5-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/scripts/ISL-lab-5.jl" target="_blank"><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="franklin-toc"><ol><li><a href="/isl/lab-5/index.html#getting_started">Getting started</a><ol><li><a href="/isl/lab-5/index.html#polynomial_regression">Polynomial regression</a></li></ol></li><li><a href="/isl/lab-5/index.html#k-folds_cross_validation">K-Folds Cross Validation</a></li><li><a href="/isl/lab-5/index.html#the_bootstrap">The Bootstrap</a></li></ol></div><h2 id="getting_started"><a href="/isl/lab-5/index.html#getting_started">Getting started</a></h2>
<pre><code class="language-julia">using MLJ, RDatasets
auto = dataset("ISLR", "Auto")
y, X = unpack(auto, ==(:MPG), col->true)
train, test = partition(eachindex(y), 0.5, shuffle=true, rng=444);</code></pre>
<p>Note the use of <code>rng&#61;</code> to seed the shuffling of indices so that the results are reproducible.</p>
<h3 id="polynomial_regression"><a href="/isl/lab-5/index.html#polynomial_regression">Polynomial regression</a></h3>
<pre><code class="language-julia">@load LinearRegressor pkg=MLJLinearModels</code></pre><pre><code class="plaintext">LinearRegressor(
    fit_intercept = true,
    solver = nothing) @ 6…73</code></pre>
<p>In this part we only build models with the <code>Horsepower</code> feature.</p>
<pre><code class="language-julia">using PyPlot

figure(figsize=(8,6))
plot(X.Horsepower, y, ls="none", marker="o")

xlabel("Horsepower", fontsize=14)
xticks(50:50:250, fontsize=12)
yticks(10:10:50, fontsize=12)
ylabel("MPG", fontsize=14)</code></pre>
<img src="/assets/isl/lab-5/code/output/ISL-lab-5-g1.svg" alt="MPG v Horsepower">
<p>Let&#39;s get a baseline:</p>
<pre><code class="language-julia">lm = LinearRegressor()
mlm = machine(lm, select(X, :Horsepower), y)
fit!(mlm, rows=train)
rms(predict(mlm, rows=test), y[test])^2</code></pre><pre><code class="plaintext">23.493990895007986</code></pre>
<p>Note that we square the measure to  match the results obtained in the ISL labs where the mean squared error &#40;here we use the <code>rms</code> which is the square root of that&#41;.</p>
<pre><code class="language-julia">xx = (Horsepower=range(50, 225, length=100) |> collect, )
yy = predict(mlm, xx)

figure(figsize=(8,6))
plot(X.Horsepower, y, ls="none", marker="o")
plot(xx.Horsepower, yy, lw=3)

xlabel("Horsepower", fontsize=14)
xticks(50:50:250, fontsize=12)
yticks(10:10:50, fontsize=12)
ylabel("MPG", fontsize=14)</code></pre>
<img src="/assets/isl/lab-5/code/output/ISL-lab-5-g2.svg" alt="1st order baseline">
<p>We now want to build three polynomial models of degree 1, 2 and 3 respectively; we start by forming the corresponding feature matrix:</p>
<pre><code class="language-julia">hp = X.Horsepower
Xhp = DataFrame(hp1=hp, hp2=hp.^2, hp3=hp.^3);</code></pre>
<p>Now we  can write a simple pipeline where the first step selects the features we want &#40;and with it the degree of the polynomial&#41; and the second is the linear regressor:</p>
<pre><code class="language-julia">@pipeline LinMod(fs = FeatureSelector(features=[:hp1]),
                 lr = LinearRegressor());</code></pre>
<p>Then we can  instantiate and fit 3 models where we specify the features each time:</p>
<pre><code class="language-julia">lrm = LinMod()
lr1 = machine(lrm, Xhp, y) # poly of degree 1 (line)
fit!(lr1, rows=train)

lrm.fs.features = [:hp1, :hp2] # poly of degree 2
lr2 = machine(lrm, Xhp, y)
fit!(lr2, rows=train)

lrm.fs.features = [:hp1, :hp2, :hp3] # poly of degree 3
lr3 = machine(lrm, Xhp, y)
fit!(lr3, rows=train)</code></pre><pre><code class="plaintext">Machine{LinMod} @ 1…39
</code></pre>
<p>Let&#39;s check the performances on the test set</p>
<pre><code class="language-julia">get_mse(lr) = rms(predict(lr, rows=test), y[test])^2

@show get_mse(lr1)
@show get_mse(lr2)
@show get_mse(lr3)</code></pre><pre><code class="plaintext">get_mse(lr1) = 23.493990895007986
get_mse(lr2) = 19.287175510952146
get_mse(lr3) = 19.381831638657914
</code></pre>
<p>Let&#39;s visualise the models</p>
<pre><code class="language-julia">hpn  = xx.Horsepower
Xnew = DataFrame(hp1=hpn, hp2=hpn.^2, hp3=hpn.^3)

yy1 = predict(lr1, Xnew)
yy2 = predict(lr2, Xnew)
yy3 = predict(lr3, Xnew)

figure(figsize=(8,6))
plot(X.Horsepower, y, ls="none", marker="o")
plot(xx.Horsepower, yy1, lw=3, label="Order 1")
plot(xx.Horsepower, yy2, lw=3, label="Order 2")
plot(xx.Horsepower, yy3, lw=3, label="Order 3")

legend(fontsize=14)

xlabel("Horsepower", fontsize=14)
xticks(50:50:250, fontsize=12)
yticks(10:10:50, fontsize=12)
ylabel("MPG", fontsize=14)</code></pre>
<img src="/assets/isl/lab-5/code/output/ISL-lab-5-g3.svg" alt="1st, 2nd and 3d order fit">
<h2 id="k-folds_cross_validation"><a href="/isl/lab-5/index.html#k-folds_cross_validation">K-Folds Cross Validation</a></h2>
<p>Let&#39;s crossvalidate over the degree of the  polynomial.</p>
<p><strong>Note</strong>: there&#39;s a  bit of gymnastics here because MLJ doesn&#39;t directly support a polynomial regression; see our tutorial on <a href="/pub/getting-started/model-tuning.html">tuning models</a> for a gentler introduction to model tuning. The gist of the following code is to create a dataframe where each column is a power of the <code>Horsepower</code> feature from 1 to 10 and we build a series of regression models using incrementally more of those features &#40;higher degree&#41;:</p>
<pre><code class="language-julia">Xhp = DataFrame([hp.^i for i in 1:10])

cases = [[Symbol("x$j") for j in 1:i] for i in 1:10]
r = range(lrm, :(fs.features), values=cases)

tm = TunedModel(model=lrm, ranges=r, resampling=CV(nfolds=10), measure=rms)</code></pre><pre><code class="plaintext">DeterministicTunedModel(
    model = LinMod(
            fs = FeatureSelector @ 1…10,
            lr = LinearRegressor @ 7…89),
    tuning = Grid(
            goal = nothing,
            resolution = 10,
            shuffle = true,
            rng = Random._GLOBAL_RNG()),
    resampling = CV(
            nfolds = 10,
            shuffle = false,
            rng = Random._GLOBAL_RNG()),
    measure = rms(),
    weights = nothing,
    operation = MLJModelInterface.predict,
    range = NominalRange(
            field = :(fs.features),
            values = ([:x1], [:x1, :x2], [:x1, :x2, :x3], [:x1, :x2, :x3, :x4], [:x1, :x2, :x3, :x4, :x5], [:x1, :x2, :x3, :x4, :x5, :x6], [:x1, :x2, :x3, :x4, :x5, :x6, :x7], [:x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8], [:x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9], [:x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])),
    train_best = true,
    repeats = 1,
    n = nothing,
    acceleration = ComputationalResources.CPU1{Nothing}(nothing),
    acceleration_resampling = ComputationalResources.CPU1{Nothing}(nothing),
    check_measure = true) @ 1…73</code></pre>
<p>Now we&#39;re left with fitting the tuned model</p>
<pre><code class="language-julia">mtm = machine(tm, Xhp, y)
fit!(mtm)
rep = report(mtm)

res = rep.plotting

@show round.(res.measurements.^2, digits=2)
@show argmin(res.measurements)</code></pre><pre><code class="plaintext">round.(res.measurements .^ 2, digits = 2) = [20.83, 25.63, 20.89, 21.27, 223.05, 98.83, 21.24, 27.33, 20.82, 21.11]
argmin(res.measurements) = 9
</code></pre>
<p>So the conclusion here is that the 5th order polynomial does quite well.</p>
<p>In ISL they use a different seed so the results are a bit different but comparable.</p>
<pre><code class="language-julia">Xnew = DataFrame([hpn.^i for i in 1:10])
yy5 = predict(mtm, Xnew)

figure(figsize=(8,6))
plot(X.Horsepower, y, ls="none", marker="o")
plot(xx.Horsepower, yy5, lw=3)

xlabel("Horsepower", fontsize=14)
xticks(50:50:250, fontsize=12)
yticks(10:10:50, fontsize=12)
ylabel("MPG", fontsize=14)</code></pre>
<img src="/assets/isl/lab-5/code/output/ISL-lab-5-g4.svg" alt="5th order fit">
<h2 id="the_bootstrap"><a href="/isl/lab-5/index.html#the_bootstrap">The Bootstrap</a></h2>
<p><em>Bootstrapping is not currently supported in MLJ.</em>
<div class="page-foot">
  <div class="copyright">
    &copy; Anthony Blaom, Thibaut Lienart and collaborators. Last modified: February 19, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>

</div>
<!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/libs/pure/ui.min.js"></script>
  
  
      <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
