<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/DataScienceTutorials.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/franklin.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/pure.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/side-menu.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/extra.css"> <title>House King County</title> <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script> <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script> <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/DataScienceTutorials.jl/" id=menu-logo-link > <div class=menu-logo > <img id=menu-logo  alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> <p><strong>MLJ Tutorials</strong></p> </div> </a> <form id=lunrSearchForm  name=lunrSearchForm > <input class=search-input  name=q  placeholder="Enter search term" type=text > <input type=submit  value=Search  formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden"> </form> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Data basics</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Loading data</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Data Frames</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Scientific Type</a> </ul> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Choosing a model</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Model tuning</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Composing models</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Stacking</a> </ul> <li class=pure-menu-sublist-title ><strong>Intro to Stats Learning</strong> <ul class=pure-menu-sublist  id=isl> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 2</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 3</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 4</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 5</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 6b</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 8</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 9</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 10</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist  id=e2e> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> AMES</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Wine</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Horse</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> King County Houses</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Airfoil </a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a> </ul> </ul> </div> </div> <div id=main > <div class=franklin-content ><h1 id=house_king_county ><a href="#house_king_county">House King County</a></h1> <em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/notebooks/EX-housekingcounty.ipynb" target=_blank ><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/scripts/EX-housekingcounty-raw.jl" target=_blank ><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/gh-pages/generated/scripts/EX-housekingcounty.jl" target=_blank ><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class=franklin-toc ><ol><li><a href="#getting_started">Getting started</a><ol><li><a href="#loading_and_preparing_the_data">Loading and preparing the data</a><li><a href="#basic_data_visualisation">Basic data visualisation</a></ol><li><a href="#fitting_a_first_model">Fitting a first model</a><ol><li><a href="#random_forest_model">Random forest model</a><li><a href="#gbm">GBM</a></ol></ol></div><h2 id=getting_started ><a href="#getting_started">Getting started</a></h2> <p>This tutorial is adapted from <a href="https://mlr3gallery.mlr-org.com/house-prices-in-king-county/">the corresponding MLR tutorial</a>.</p> <h3 id=loading_and_preparing_the_data ><a href="#loading_and_preparing_the_data">Loading and preparing the data</a></h3> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ
<span class=hljs-keyword >using</span> PrettyPrinting
<span class=hljs-keyword >import</span> DataFrames: DataFrame, select!, Not, describe
<span class=hljs-keyword >import</span> Statistics
<span class=hljs-keyword >using</span> Dates
<span class=hljs-keyword >using</span> PyPlot
<span class=hljs-keyword >using</span> UrlDownload


df = DataFrame(urldownload(<span class=hljs-string >"https://raw.githubusercontent.com/tlienart/DataScienceTutorialsData.jl/master/data/kc_housing.csv"</span>, <span class=hljs-literal >true</span>))
describe(df)</code></pre><pre><code class="plaintext hljs">21×8 DataFrame
│ Row │ variable      │ mean       │ min             │ median    │ max             │ nunique │ nmissing │ eltype   │
│     │ Symbol        │ Union…     │ Any             │ Union…    │ Any             │ Union…  │ Nothing  │ DataType │
├─────┼───────────────┼────────────┼─────────────────┼───────────┼─────────────────┼─────────┼──────────┼──────────┤
│ 1   │ id            │ 4.5803e9   │ 1000102         │ 3.90493e9 │ 9900000190      │         │          │ Int64    │
│ 2   │ date          │            │ 20140502T000000 │           │ 20150527T000000 │ 372     │          │ String   │
│ 3   │ price         │ 540088.0   │ 75000.0         │ 450000.0  │ 7.7e6           │         │          │ Float64  │
│ 4   │ bedrooms      │ 3.37084    │ 0               │ 3.0       │ 33              │         │          │ Int64    │
│ 5   │ bathrooms     │ 2.11476    │ 0.0             │ 2.25      │ 8.0             │         │          │ Float64  │
│ 6   │ sqft_living   │ 2079.9     │ 290             │ 1910.0    │ 13540           │         │          │ Int64    │
│ 7   │ sqft_lot      │ 15107.0    │ 520             │ 7618.0    │ 1651359         │         │          │ Int64    │
│ 8   │ floors        │ 1.49431    │ 1.0             │ 1.5       │ 3.5             │         │          │ Float64  │
│ 9   │ waterfront    │ 0.00754176 │ 0               │ 0.0       │ 1               │         │          │ Int64    │
│ 10  │ view          │ 0.234303   │ 0               │ 0.0       │ 4               │         │          │ Int64    │
│ 11  │ condition     │ 3.40943    │ 1               │ 3.0       │ 5               │         │          │ Int64    │
│ 12  │ grade         │ 7.65687    │ 1               │ 7.0       │ 13              │         │          │ Int64    │
│ 13  │ sqft_above    │ 1788.39    │ 290             │ 1560.0    │ 9410            │         │          │ Int64    │
│ 14  │ sqft_basement │ 291.509    │ 0               │ 0.0       │ 4820            │         │          │ Int64    │
│ 15  │ yr_built      │ 1971.01    │ 1900            │ 1975.0    │ 2015            │         │          │ Int64    │
│ 16  │ yr_renovated  │ 84.4023    │ 0               │ 0.0       │ 2015            │         │          │ Int64    │
│ 17  │ zipcode       │ 98077.9    │ 98001           │ 98065.0   │ 98199           │         │          │ Int64    │
│ 18  │ lat           │ 47.5601    │ 47.1559         │ 47.5718   │ 47.7776         │         │          │ Float64  │
│ 19  │ long          │ -122.214   │ -122.519        │ -122.23   │ -121.315        │         │          │ Float64  │
│ 20  │ sqft_living15 │ 1986.55    │ 399             │ 1840.0    │ 6210            │         │          │ Int64    │
│ 21  │ sqft_lot15    │ 12768.5    │ 651             │ 7620.0    │ 871200          │         │          │ Int64    │</code></pre> <p>We drop unrelated columns</p> <pre><code class="julia hljs">select!(df, Not([:id, :date]))
schema(df)</code></pre><pre><code class="plaintext hljs">┌───────────────┬─────────┬────────────┐
│ _.names       │ _.types │ _.scitypes │
├───────────────┼─────────┼────────────┤
│ price         │ Float64 │ Continuous │
│ bedrooms      │ Int64   │ Count      │
│ bathrooms     │ Float64 │ Continuous │
│ sqft_living   │ Int64   │ Count      │
│ sqft_lot      │ Int64   │ Count      │
│ floors        │ Float64 │ Continuous │
│ waterfront    │ Int64   │ Count      │
│ view          │ Int64   │ Count      │
│ condition     │ Int64   │ Count      │
│ grade         │ Int64   │ Count      │
│ sqft_above    │ Int64   │ Count      │
│ sqft_basement │ Int64   │ Count      │
│ yr_built      │ Int64   │ Count      │
│ yr_renovated  │ Int64   │ Count      │
│ zipcode       │ Int64   │ Count      │
│ lat           │ Float64 │ Continuous │
│ long          │ Float64 │ Continuous │
│ sqft_living15 │ Int64   │ Count      │
│ sqft_lot15    │ Int64   │ Count      │
└───────────────┴─────────┴────────────┘
_.nrows = 21613
</code></pre> <p>Afterwards, we convert the zip code to an unordered factor &#40;<code>Multiclass</code>&#41;, we also create two binary features <code>isrenovated</code> and <code>has_basement</code> derived from <code>yr_renovated</code> and <code>sqft_basement</code>:</p> <pre><code class="julia hljs">coerce!(df, :zipcode =&gt; Multiclass)
df.isrenovated  = @. !iszero(df.yr_renovated)
df.has_basement = @. !iszero(df.sqft_basement)
schema(df)</code></pre><pre><code class="plaintext hljs">┌───────────────┬────────────────────────────────┬────────────────┐
│ _.names       │ _.types                        │ _.scitypes     │
├───────────────┼────────────────────────────────┼────────────────┤
│ price         │ Float64                        │ Continuous     │
│ bedrooms      │ Int64                          │ Count          │
│ bathrooms     │ Float64                        │ Continuous     │
│ sqft_living   │ Int64                          │ Count          │
│ sqft_lot      │ Int64                          │ Count          │
│ floors        │ Float64                        │ Continuous     │
│ waterfront    │ Int64                          │ Count          │
│ view          │ Int64                          │ Count          │
│ condition     │ Int64                          │ Count          │
│ grade         │ Int64                          │ Count          │
│ sqft_above    │ Int64                          │ Count          │
│ sqft_basement │ Int64                          │ Count          │
│ yr_built      │ Int64                          │ Count          │
│ yr_renovated  │ Int64                          │ Count          │
│ zipcode       │ CategoricalValue{Int64,UInt32} │ Multiclass{70} │
│ lat           │ Float64                        │ Continuous     │
│ long          │ Float64                        │ Continuous     │
│ sqft_living15 │ Int64                          │ Count          │
│ sqft_lot15    │ Int64                          │ Count          │
│ isrenovated   │ Bool                           │ Count          │
│ has_basement  │ Bool                           │ Count          │
└───────────────┴────────────────────────────────┴────────────────┘
_.nrows = 21613
</code></pre> <p>These created variables should be treated as OrderedFactor,</p> <pre><code class="julia hljs">coerce!(df, :isrenovated =&gt; OrderedFactor, :has_basement =&gt; OrderedFactor);</code></pre>
<p>The feature <code>waterfront</code> is currently encoded as a string, but it&#39;s really just a boolean:</p>
<pre><code class="julia hljs">unique(df.waterfront)</code></pre><pre><code class="plaintext hljs">2-element Array{Int64,1}:
 0
 1</code></pre>
<p>So let&#39;s recode it</p>
<pre><code class="julia hljs">df.waterfront = (df.waterfront .!= <span class=hljs-string >"FALSE"</span>)
coerce!(df, :waterfront =&gt; OrderedFactor);</code></pre>
<p>For a number of the remaining features which are treated as <code>Count</code> there are few unique values in which case it might make more sense to recode them as OrderedFactor, this can be done with <code>autotype</code>:</p>
<pre><code class="julia hljs">coerce!(df, autotype(df, :few_to_finite))
schema(df)</code></pre><pre><code class="plaintext hljs">┌───────────────┬──────────────────────────────────┬───────────────────┐
│ _.names       │ _.types                          │ _.scitypes        │
├───────────────┼──────────────────────────────────┼───────────────────┤
│ price         │ Float64                          │ Continuous        │
│ bedrooms      │ CategoricalValue{Int64,UInt32}   │ OrderedFactor{13} │
│ bathrooms     │ CategoricalValue{Float64,UInt32} │ OrderedFactor{30} │
│ sqft_living   │ Int64                            │ Count             │
│ sqft_lot      │ Int64                            │ Count             │
│ floors        │ CategoricalValue{Float64,UInt32} │ OrderedFactor{6}  │
│ waterfront    │ CategoricalValue{Bool,UInt32}    │ OrderedFactor{1}  │
│ view          │ CategoricalValue{Int64,UInt32}   │ OrderedFactor{5}  │
│ condition     │ CategoricalValue{Int64,UInt32}   │ OrderedFactor{5}  │
│ grade         │ CategoricalValue{Int64,UInt32}   │ OrderedFactor{12} │
│ sqft_above    │ Int64                            │ Count             │
│ sqft_basement │ Int64                            │ Count             │
│ yr_built      │ Int64                            │ Count             │
│ yr_renovated  │ CategoricalValue{Int64,UInt32}   │ OrderedFactor{70} │
│ zipcode       │ CategoricalValue{Int64,UInt32}   │ Multiclass{70}    │
│ lat           │ Float64                          │ Continuous        │
│ long          │ Float64                          │ Continuous        │
│ sqft_living15 │ Int64                            │ Count             │
│ sqft_lot15    │ Int64                            │ Count             │
│ isrenovated   │ CategoricalValue{Bool,UInt32}    │ OrderedFactor{2}  │
│ has_basement  │ CategoricalValue{Bool,UInt32}    │ OrderedFactor{2}  │
└───────────────┴──────────────────────────────────┴───────────────────┘
_.nrows = 21613
</code></pre>
<p>Let&#39;s also rescale the column <code>price</code> to be in 1000s of dollars:</p>
<pre><code class="julia hljs">df.price = df.price ./ <span class=hljs-number >1000</span>;</code></pre>
<p>For simplicity let&#39;s just drop a few additional columns that don&#39;t seem to matter much:</p>
<pre><code class="julia hljs">select!(df, Not([:yr_renovated, :sqft_basement, :zipcode]));</code></pre>
<h3 id=basic_data_visualisation ><a href="#basic_data_visualisation">Basic data visualisation</a></h3>
<p>Let&#39;s plot a basic histogram of the prices to get an idea for the distribution:</p>
<pre><code class="julia hljs">plt.figure(figsize=(<span class=hljs-number >8</span>,<span class=hljs-number >6</span>))
plt.hist(df.price, color = <span class=hljs-string >"blue"</span>, edgecolor = <span class=hljs-string >"white"</span>, bins=<span class=hljs-number >50</span>,
         density=<span class=hljs-literal >true</span>, alpha=<span class=hljs-number >0.5</span>)
plt.xlabel(<span class=hljs-string >"Price"</span>, fontsize=<span class=hljs-number >14</span>)
plt.ylabel(<span class=hljs-string >"Frequency"</span>, fontsize=<span class=hljs-number >14</span>)</code></pre>
<img src="/DataScienceTutorials.jl/assets/end-to-end/HouseKingCounty/code/output/hist_price.svg" alt="Histogram of the prices">
<p>Let&#39;s see if there&#39;s a difference between renovated and unrenovated flats:</p>
<pre><code class="julia hljs">plt.figure(figsize=(<span class=hljs-number >8</span>,<span class=hljs-number >6</span>))
plt.hist(df.price[df.isrenovated .== <span class=hljs-literal >true</span>], color=<span class=hljs-string >"blue"</span>, density=<span class=hljs-literal >true</span>,
        edgecolor=<span class=hljs-string >"white"</span>, bins=<span class=hljs-number >50</span>, label=<span class=hljs-string >"renovated"</span>, alpha=<span class=hljs-number >0.5</span>)
plt.hist(df.price[df.isrenovated .== <span class=hljs-literal >false</span>], color=<span class=hljs-string >"red"</span>, density=<span class=hljs-literal >true</span>,
        edgecolor=<span class=hljs-string >"white"</span>, bins=<span class=hljs-number >50</span>, label=<span class=hljs-string >"unrenovated"</span>, alpha=<span class=hljs-number >0.5</span>)
plt.xlabel(<span class=hljs-string >"Price"</span>, fontsize=<span class=hljs-number >14</span>)
plt.ylabel(<span class=hljs-string >"Frequency"</span>, fontsize=<span class=hljs-number >14</span>)
plt.legend(fontsize=<span class=hljs-number >12</span>)</code></pre>
<img src="/DataScienceTutorials.jl/assets/end-to-end/HouseKingCounty/code/output/hist_price2.svg" alt="Histogram of the prices depending on renovation"> We can observe that renovated flats seem to achieve higher sales values, and this might thus be a relevant feature.</p>
<p>Likewise, this could be done to verify that <code>condition</code>, <code>waterfront</code> etc are important features.</p>
<h2 id=fitting_a_first_model ><a href="#fitting_a_first_model">Fitting a first model</a></h2>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> DecisionTreeRegressor

y, X = unpack(df, ==(:price), col -&gt; <span class=hljs-literal >true</span>)
train, test = partition(eachindex(y), <span class=hljs-number >0.7</span>, shuffle=<span class=hljs-literal >true</span>, rng=<span class=hljs-number >5</span>)

tree = machine(DecisionTreeRegressor(), X, y)

fit!(tree, rows=train);</code></pre>
<p>Let&#39;s see how it does</p>
<pre><code class="julia hljs">rms(y[test], predict(tree, rows=test))</code></pre><pre><code class="plaintext hljs">179.86946971693993</code></pre>
<p>Let&#39;s try to do better.</p>
<h3 id=random_forest_model ><a href="#random_forest_model">Random forest model</a></h3>
<p>We might be able to improve upon the RMSE using more powerful learners.</p>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> RandomForestRegressor pkg=ScikitLearn</code></pre><pre><code class="plaintext hljs">RandomForestRegressor(
    n_estimators = 100,
    criterion = "mse",
    max_depth = nothing,
    min_samples_split = 2,
    min_samples_leaf = 1,
    min_weight_fraction_leaf = 0.0,
    max_features = "auto",
    max_leaf_nodes = nothing,
    min_impurity_decrease = 0.0,
    bootstrap = true,
    oob_score = false,
    n_jobs = nothing,
    random_state = nothing,
    verbose = 0,
    warm_start = false) @ 5…84</code></pre>
<p>That model only accepts input in the form of <code>Count</code> and so we have to coerce all <code>Finite</code> types into <code>Count</code>:</p>
<pre><code class="julia hljs">coerce!(X, Finite =&gt; Count);</code></pre>
<p>Now we can fit</p>
<pre><code class="julia hljs">rf_mdl = RandomForestRegressor()
rf = machine(rf_mdl, X, y)
fit!(rf, rows=train)

rms(y[test], predict(rf, rows=test))</code></pre><pre><code class="plaintext hljs">137.84977785477955</code></pre>
<p>A bit better but it would be best to check this a bit more carefully:</p>
<pre><code class="julia hljs">cv3 = CV(; nfolds=<span class=hljs-number >3</span>)
res = evaluate(rf_mdl, X, y, resampling=CV(shuffle=<span class=hljs-literal >true</span>),
               measure=rms, verbosity=<span class=hljs-number >0</span>)</code></pre><pre><code class="plaintext hljs">┌───────────┬───────────────┬────────────────────────────────────────────┐
│ _.measure │ _.measurement │ _.per_fold                                 │
├───────────┼───────────────┼────────────────────────────────────────────┤
│ rms       │ 132.0         │ [137.0, 134.0, 124.0, 139.0, 135.0, 124.0] │
└───────────┴───────────────┴────────────────────────────────────────────┘
_.per_observation = [missing]
</code></pre>
<h3 id=gbm ><a href="#gbm">GBM</a></h3>
<p>Let&#39;s try a different kind of model: Gradient Boosted Decision Trees from the package xgboost and we&#39;ll try to tune it too.</p>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> XGBoostRegressor</code></pre><pre><code class="plaintext hljs">XGBoostRegressor(
    num_round = 100,
    booster = "gbtree",
    disable_default_eval_metric = 0,
    eta = 0.3,
    gamma = 0.0,
    max_depth = 6,
    min_child_weight = 1.0,
    max_delta_step = 0.0,
    subsample = 1.0,
    colsample_bytree = 1.0,
    colsample_bylevel = 1.0,
    lambda = 1.0,
    alpha = 0.0,
    tree_method = "auto",
    sketch_eps = 0.03,
    scale_pos_weight = 1.0,
    updater = "auto",
    refresh_leaf = 1,
    process_type = "default",
    grow_policy = "depthwise",
    max_leaves = 0,
    max_bin = 256,
    predictor = "cpu_predictor",
    sample_type = "uniform",
    normalize_type = "tree",
    rate_drop = 0.0,
    one_drop = 0,
    skip_drop = 0.0,
    feature_selector = "cyclic",
    top_k = 0,
    tweedie_variance_power = 1.5,
    objective = "reg:linear",
    base_score = 0.5,
    eval_metric = "rmse",
    seed = 0) @ 1…83</code></pre>
<p>It expects a <code>Table&#40;Continuous&#41;</code> input so we need to coerce <code>X</code> again:</p>
<pre><code class="julia hljs">coerce!(X, Count =&gt; Continuous)

xgb  = XGBoostRegressor()
xgbm = machine(xgb, X, y)
fit!(xgbm, rows=train)

rms(y[test], predict(xgbm, rows=test))</code></pre><pre><code class="plaintext hljs">137.35137881292272</code></pre>
<p>Let&#39;s try to tune it, first we define ranges for a number of useful parameters:</p>
<pre><code class="julia hljs">r1 = range(xgb, :max_depth, lower=<span class=hljs-number >3</span>, upper=<span class=hljs-number >10</span>)
r2 = range(xgb, :num_round, lower=<span class=hljs-number >1</span>, upper=<span class=hljs-number >25</span>);</code></pre>
<p>And now we tune, we use a very coarse resolution because we use so many ranges, <code>2^7</code> is already some 128 models...</p>
<pre><code class="julia hljs">tm = TunedModel(model=xgb, tuning=Grid(resolution=<span class=hljs-number >7</span>),
                resampling=CV(rng=<span class=hljs-number >11</span>), ranges=[r1,r2],
                measure=rms)
mtm = machine(tm, X, y)
fit!(mtm, rows=train)

rms(y[test], predict(mtm, rows=test))</code></pre><pre><code class="plaintext hljs">147.35605482348706</code></pre>
<p>Tuning helps a fair bit&#33;</p>
<div class=page-foot >
  <div class=copyright >
    &copy; Thibaut Lienart, Anthony Blaom and collaborators. Last modified: May 24, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div>
      </div> 
  </div> 
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>