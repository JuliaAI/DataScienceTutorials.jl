<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/DataScienceTutorials.jl/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/franklin.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/pure.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/side-menu.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/extra.css">
  <!-- <link rel="icon" href="/DataScienceTutorials.jl/assets/infra/favicon.gif"> -->
   <title>Horse colic data</title>  
  <!-- LUNR -->
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/DataScienceTutorials.jl/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class="pure-menu-link"><strong>Home</strong></a></li>

    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/processing/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data processing</a></li>
    </ul>

    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Stacking</a></li>
    </ul>

    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>

    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> King County Houses</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Airfoil </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/powergen/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Power Generation </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-flux" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->
<div class="franklin-content"><h1 id="horse_colic_data"><a href="#horse_colic_data">Horse colic data</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/notebooks/EX-horse.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-horse-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-horse.jl" target="_blank"><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="franklin-toc"><ol><li><a href="#initial_data_processing">Initial data processing</a><ol><li><a href="#getting_the_data">Getting the data</a></li><li><a href="#inspecting_columns">Inspecting columns</a></li><li><a href="#dealing_with_missing_values">Dealing with missing values</a></li></ol></li><li><a href="#a_baseline_model">A baseline model</a></li><li><a href="#trying_another_model">Trying another model</a></li></ol></div><h2 id="initial_data_processing"><a href="#initial_data_processing">Initial data processing</a></h2>
<p>In this example, we consider the <a href="http://archive.ics.uci.edu/ml/datasets/Horse&#43;Colic">UCI &quot;horse colic&quot; dataset</a></p>
<p>This is a reasonably messy classification problem with missing values etc and so some work should be expected in the feature processing.</p>
<h3 id="getting_the_data"><a href="#getting_the_data">Getting the data</a></h3>
<p>The data is pre-split in training and testing and we will keep it as such</p>
<pre><code class="language-julia">using MLJ
using HTTP
using CSV
import DataFrames: DataFrame, select!, Not
req1 = HTTP.get("http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data")
req2 = HTTP.get("http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.test")
header = ["surgery", "age", "hospital_number",
    "rectal_temperature", "pulse",
    "respiratory_rate", "temperature_extremities",
    "peripheral_pulse", "mucous_membranes",
    "capillary_refill_time", "pain",
    "peristalsis", "abdominal_distension",
    "nasogastric_tube", "nasogastric_reflux",
    "nasogastric_reflux_ph", "feces", "abdomen",
    "packed_cell_volume", "total_protein",
    "abdomcentesis_appearance", "abdomcentesis_total_protein",
    "outcome", "surgical_lesion", "lesion_1", "lesion_2", "lesion_3",
    "cp_data"]
csv_opts = (header=header, delim=' ', missingstring="?",
            ignorerepeated=true)
data_train = CSV.read(req1.body; csv_opts...)
data_test  = CSV.read(req2.body; csv_opts...)
@show size(data_train)
@show size(data_test)</code></pre><pre><code class="plaintext">size(data_train) = (300, 28)
size(data_test) = (68, 28)
</code></pre>
<h3 id="inspecting_columns"><a href="#inspecting_columns">Inspecting columns</a></h3>
<p>To simplify the analysis, we will drop the columns <code>Lesion *</code> as they would need specific re-encoding which would distract us a bit.</p>
<pre><code class="language-julia">unwanted = [:lesion_1, :lesion_2, :lesion_3]
data = vcat(data_train, data_test)
select!(data, Not(unwanted));</code></pre>
<p>Let&#39;s also keep track of the initial train-test split</p>
<pre><code class="language-julia">train = 1:nrows(data_train)
test = last(train) .+ (1:nrows(data_test));</code></pre>
<p>We know from reading the description that some of these features represent multiclass data; to facilitate the interpretation, we can use <code>autotype</code> from <code>ScientificTypes</code>. By default, <code>autotype</code> will check all columns and suggest a Finite type assuming there are relatively few distinct values in the column. More sophisticated rules can be passed, see <a href="https://alan-turing-institute.github.io/ScientificTypes.jl/dev/">ScientificTypes.jl</a>:</p>
<pre><code class="language-julia">datac = coerce(data, autotype(data));</code></pre>
<p>Let&#39;s see column by column whether it looks ok now</p>
<pre><code class="language-julia">sch = schema(datac)
for (name, scitype) in zip(sch.names, sch.scitypes)
    println(rpad("$name", 30), scitype)
end</code></pre><pre><code class="plaintext">surgery                       Union{Missing, OrderedFactor{2}}
age                           OrderedFactor{2}
hospital_number               Count
rectal_temperature            Union{Missing, Continuous}
pulse                         Union{Missing, Count}
respiratory_rate              Union{Missing, Count}
temperature_extremities       Union{Missing, OrderedFactor{4}}
peripheral_pulse              Union{Missing, OrderedFactor{4}}
mucous_membranes              Union{Missing, OrderedFactor{6}}
capillary_refill_time         Union{Missing, OrderedFactor{3}}
pain                          Union{Missing, OrderedFactor{5}}
peristalsis                   Union{Missing, OrderedFactor{4}}
abdominal_distension          Union{Missing, OrderedFactor{4}}
nasogastric_tube              Union{Missing, OrderedFactor{3}}
nasogastric_reflux            Union{Missing, OrderedFactor{3}}
nasogastric_reflux_ph         Union{Missing, OrderedFactor{24}}
feces                         Union{Missing, OrderedFactor{4}}
abdomen                       Union{Missing, OrderedFactor{5}}
packed_cell_volume            Union{Missing, Continuous}
total_protein                 Union{Missing, Continuous}
abdomcentesis_appearance      Union{Missing, OrderedFactor{3}}
abdomcentesis_total_protein   Union{Missing, Continuous}
outcome                       Union{Missing, OrderedFactor{3}}
surgical_lesion               OrderedFactor{2}
cp_data                       OrderedFactor{2}
</code></pre>
<p>Most columns are now treated as either Multiclass or Ordered, this corresponds to the <a href="https://archive.ics.uci.edu/ml/datasets/Horse&#43;Colic">description of the data</a>. For instance:</p>
<ul>
<li><p><code>Surgery</code> is described as <code>1&#61;yes / 2&#61;no</code></p>
</li>
<li><p><code>Age</code> is described as <code>1&#61;adult / 2&#61;young</code></p>
</li>
</ul>
<p>Inspecting the rest of the descriptions and the current scientific type, there are a few more things that can be observed:</p>
<ul>
<li><p>hospital number is still a count, this means that there are relatively many hospitals and so  that&#39;s  probably not very useful,</p>
</li>
<li><p>pulse and respiratory rate are still as count but the data description suggests that they can be considered as continuous</p>
</li>
</ul>
<pre><code class="language-julia">length(unique(datac.hospital_number))</code></pre><pre><code class="plaintext">346</code></pre>
<p>yeah let&#39;s drop that</p>
<pre><code class="language-julia">datac = select!(datac, Not(:hospital_number));</code></pre>
<p>let&#39;s also coerce the pulse and respiratory rate, in fact we can do that with <code>autotype</code> specifying as rule the <code>discrete_to_continuous</code>
<pre><code class="language-julia">datac = coerce(datac, autotype(datac, rules=(:discrete_to_continuous,)));</code></pre>
<h3 id="dealing_with_missing_values"><a href="#dealing_with_missing_values">Dealing with missing values</a></h3>
<p>There&#39;s quite a lot of missing values, in this tutorial we&#39;ll be a bit rough in how we deal with them applying the following rules of thumb:</p>
<ul>
<li><p>drop the rows where the outcome is unknown</p>
</li>
<li><p>drop columns with more than 20&#37; missing values</p>
</li>
<li><p>simple imputation of whatever&#39;s left</p>
</li>
</ul>
<pre><code class="language-julia">missing_outcome = ismissing.(datac.outcome)
idx_missing_outcome = missing_outcome |> findall</code></pre><pre><code class="plaintext">2-element Array{Int64,1}:
 133
 309</code></pre>
<p>Ok there&#39;s only two row which is nice, let&#39;s remove them from the train/test indices and drop the rows</p>
<pre><code class="language-julia">train = setdiff!(train |> collect, idx_missing_outcome)
test = setdiff!(test |> collect, idx_missing_outcome)
datac = datac[.!missing_outcome, :];</code></pre>
<p>Now let&#39;s look at how many missings there are per features</p>
<pre><code class="language-julia">for name in names(datac)
    col = datac[:, name]
    ratio_missing = sum(ismissing.(col)) / nrows(datac) * 100
    println(rpad(name, 30), round(ratio_missing, sigdigits=3))
end</code></pre><pre><code class="plaintext">surgery                       0.0
age                           0.0
rectal_temperature            18.9
pulse                         7.1
respiratory_rate              19.4
temperature_extremities       17.5
peripheral_pulse              22.7
mucous_membranes              13.1
capillary_refill_time         10.4
pain                          17.2
peristalsis                   13.9
abdominal_distension          17.5
nasogastric_tube              35.5
nasogastric_reflux            36.1
nasogastric_reflux_ph         81.1
feces                         34.7
abdomen                       39.1
packed_cell_volume            9.84
total_protein                 11.5
abdomcentesis_appearance      52.7
abdomcentesis_total_protein   63.9
outcome                       0.0
surgical_lesion               0.0
cp_data                       0.0
</code></pre>
<p>Let&#39;s drop the ones with more than 20&#37; &#40;quite a few&#33;&#41;</p>
<pre><code class="language-julia">unwanted = [:peripheral_pulse, :nasogastric_tube, :nasogastric_reflux,
        :nasogastric_reflux_ph, :feces, :abdomen, :abdomcentesis_appearance, :abdomcentesis_total_protein]
select!(datac, Not(unwanted));</code></pre>
<p>Note that we could have done this better and investigated the nature of the features for which there&#39;s a lot of missing values but don&#39;t forget that our goal is to showcase MLJ&#33;</p>
<p>Let&#39;s conclude by filling all missing values and separating the feature matrix from the  target</p>
<pre><code class="language-julia">@load FillImputer
filler = machine(FillImputer(), datac)
fit!(filler)
datac = transform(filler, datac)

y, X = unpack(datac, ==(:outcome), name->true);
X = coerce(X, autotype(X, :discrete_to_continuous));</code></pre>
<h2 id="a_baseline_model"><a href="#a_baseline_model">A baseline model</a></h2>
<p>Let&#39;s define a first sensible model and get a baseline, basic steps are:</p>
<ul>
<li><p>one-hot-encode the categoricals</p>
</li>
<li><p>feed all this into a classifier</p>
</li>
</ul>
<pre><code class="language-julia">@load OneHotEncoder
@load MultinomialClassifier pkg="MLJLinearModels"</code></pre><pre><code class="plaintext">MultinomialClassifier(
    lambda = 1.0,
    gamma = 0.0,
    penalty = :l2,
    fit_intercept = true,
    penalize_intercept = false,
    solver = nothing) @698</code></pre>
<p>Let&#39;s have convenient handles over the training data</p>
<pre><code class="language-julia">Xtrain = X[train,:]
ytrain = y[train];</code></pre>
<p>And let&#39;s define a pipeline corresponding to the operations above</p>
<pre><code class="language-julia">SimplePipe = @pipeline(OneHotEncoder(),
                       MultinomialClassifier(), prediction_type=:probabilistic)
mach = machine(SimplePipe, Xtrain, ytrain)
res = evaluate!(mach; resampling=Holdout(fraction_train=0.9),
                measure=cross_entropy)
round(res.measurement[1], sigdigits=3)</code></pre><pre><code class="plaintext">0.704</code></pre>
<p>This is the cross entropy on some held-out 10&#37; of the training set. We can also just for the sake of getting a baseline, see the misclassification on the whole training data:</p>
<pre><code class="language-julia">ŷ = predict(mach, Xtrain)
ȳ = mode(ŷ)
mcr = misclassification_rate(ŷ, ytrain)
println(rpad("MNC mcr:", 10), round(mcr, sigdigits=3))</code></pre><pre><code class="plaintext">MethodError: no method matching (::MLJBase.MisclassificationRate)(::MLJBase.UnivariateFiniteArray{OrderedFactor{3},Int64,UInt32,Float64,1}, ::CategoricalArrays.CategoricalArray{Int64,1,UInt32,Int64,CategoricalArrays.CategoricalValue{Int64,UInt32},Union{}})
Closest candidates are:
  Any(!Matched::AbstractArray{#s490,1} where #s490<:CategoricalArrays.CategoricalValue, ::AbstractArray{#s489,1} where #s489<:CategoricalArrays.CategoricalValue) at /Users/GD/.julia/packages/MLJBase/CcEkh/src/measures/finite.jl:243
  Any(!Matched::AbstractArray{#s490,1} where #s490<:CategoricalArrays.CategoricalValue, ::AbstractArray{#s489,1} where #s489<:CategoricalArrays.CategoricalValue, !Matched::AbstractArray{#s488,1} where #s488<:Real) at /Users/GD/.julia/packages/MLJBase/CcEkh/src/measures/finite.jl:247
</code></pre>
<p>That&#39;s not bad at all actually. Let&#39;s tune it a bit and see if we can get a bit better than that, not much point in going crazy, we might get a few percents but not much more.</p>
<pre><code class="language-julia">model = SimplePipe
lambdas = range(model, :(multinomial_classifier.lambda), lower=1e-3, upper=100, scale=:log10)
tm = TunedModel(model=SimplePipe, ranges=lambdas, measure=cross_entropy)
mtm = machine(tm, Xtrain, ytrain)
fit!(mtm)
best_pipe = fitted_params(mtm).best_model</code></pre><pre><code class="plaintext">Pipeline462(
    one_hot_encoder = OneHotEncoder(
            features = Symbol[],
            drop_last = false,
            ordered_factor = true,
            ignore = false),
    multinomial_classifier = MultinomialClassifier(
            lambda = 27.825594022071243,
            gamma = 0.0,
            penalty = :l2,
            fit_intercept = true,
            penalize_intercept = false,
            solver = nothing)) @219</code></pre>
<p>So it looks like it&#39;s useful to regularise a fair bit to get a lower cross entropy</p>
<pre><code class="language-julia">ŷ = predict(mtm, Xtrain)
cross_entropy(ŷ, ytrain) |> mean</code></pre><pre><code class="plaintext">0.6129047398190444</code></pre>
<p>Interestingly this does not improve our missclassification rate</p>
<pre><code class="language-julia">mcr = misclassification_rate(mode.(ŷ), ytrain)
println(rpad("MNC mcr:", 10), round(mcr, sigdigits=3))</code></pre><pre><code class="plaintext">MNC mcr:  0.278
</code></pre>
<p>We&#39;ve probably reached the limit of a simple linear model.</p>
<h2 id="trying_another_model"><a href="#trying_another_model">Trying another model</a></h2>
<p>There are lots of categoricals, so maybe  it&#39;s just better to use something that deals well with that like a tree-based classifier.</p>
<pre><code class="language-julia">@load XGBoostClassifier
dtc = machine(XGBoostClassifier(), Xtrain, ytrain)
fit!(dtc)
ŷ = predict(dtc, Xtrain)
cross_entropy(ŷ, ytrain) |> mean</code></pre><pre><code class="plaintext">0.024815097f0</code></pre>
<p>So we get a worse cross entropy but...</p>
<pre><code class="language-julia">misclassification_rate(mode.(ŷ), ytrain)</code></pre><pre><code class="plaintext">0.0033444816053511705</code></pre>
<p>a significantly better misclassification rate.</p>
<p>We could investigate more, do more tuning etc, but the key points of this tutorial was to show how to handle data with missing values.<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom and collaborators. Last modified: July 14, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>
  
  
      <script src="/DataScienceTutorials.jl/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
