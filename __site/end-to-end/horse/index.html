<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/DataScienceTutorials.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/franklin.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/pure.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/side-menu.css"> <link rel=stylesheet  href="/DataScienceTutorials.jl/css/extra.css"> <title>Horse colic data</title> <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script> <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script> <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a href="/DataScienceTutorials.jl/" id=menu-logo-link > <div class=menu-logo > <p><strong>Data Science Tutorials</strong></p> </div> </a> <form id=lunrSearchForm  name=lunrSearchForm > <input class=search-input  name=q  placeholder="Enter search term" type=text > <input type=submit  value=Search  formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden"> </form> <ul class=pure-menu-list > <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class=pure-menu-link ><strong>Home</strong></a> <li class=pure-menu-sublist-title ><strong>Data basics</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Loading data</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Data Frames</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Scientific Type</a> </ul> <li class=pure-menu-sublist-title ><strong>Getting started</strong> <ul class=pure-menu-sublist > <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Choosing a model</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Model tuning</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Composing models</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Stacking</a> </ul> <li class=pure-menu-sublist-title ><strong>Intro to Stats Learning</strong> <ul class=pure-menu-sublist  id=isl> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 2</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 3</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 4</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 5</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 6b</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 8</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 9</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Lab 10</a> </ul> <li class=pure-menu-sublist-title ><strong>End to end examples</strong> <ul class=pure-menu-sublist  id=e2e> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> AMES</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Wine</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Horse</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> King County Houses</a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Airfoil </a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a> <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class=pure-menu-link ><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a> </ul> </ul> </div> </div> <div id=main > <div class=franklin-content ><h1 id=horse_colic_data ><a href="#horse_colic_data">Horse colic data</a></h1> <em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/notebooks/EX-horse.ipynb" target=_blank ><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-horse-raw.jl" target=_blank ><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-horse.jl" target=_blank ><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class=franklin-toc ><ol><li><a href="#initial_data_processing">Initial data processing</a><ol><li><a href="#getting_the_data">Getting the data</a><li><a href="#inspecting_columns">Inspecting columns</a><li><a href="#dealing_with_missing_values">Dealing with missing values</a></ol><li><a href="#a_baseline_model">A baseline model</a><li><a href="#trying_another_model">Trying another model</a></ol></div><h2 id=initial_data_processing ><a href="#initial_data_processing">Initial data processing</a></h2> <p>In this example, we consider the <a href="http://archive.ics.uci.edu/ml/datasets/Horse&#43;Colic">UCI &quot;horse colic&quot; dataset</a></p> <p>This is a reasonably messy classification problem with missing values etc and so some work should be expected in the feature processing.</p> <h3 id=getting_the_data ><a href="#getting_the_data">Getting the data</a></h3> <p>The data is pre-split in training and testing and we will keep it as such</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> MLJ
<span class=hljs-keyword >using</span> HTTP
<span class=hljs-keyword >using</span> CSV
<span class=hljs-keyword >import</span> DataFrames: DataFrame, select!, Not
req1 = HTTP.get(<span class=hljs-string >"http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data"</span>)
req2 = HTTP.get(<span class=hljs-string >"http://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.test"</span>)
header = [<span class=hljs-string >"surgery"</span>, <span class=hljs-string >"age"</span>, <span class=hljs-string >"hospital_number"</span>,
    <span class=hljs-string >"rectal_temperature"</span>, <span class=hljs-string >"pulse"</span>,
    <span class=hljs-string >"respiratory_rate"</span>, <span class=hljs-string >"temperature_extremities"</span>,
    <span class=hljs-string >"peripheral_pulse"</span>, <span class=hljs-string >"mucous_membranes"</span>,
    <span class=hljs-string >"capillary_refill_time"</span>, <span class=hljs-string >"pain"</span>,
    <span class=hljs-string >"peristalsis"</span>, <span class=hljs-string >"abdominal_distension"</span>,
    <span class=hljs-string >"nasogastric_tube"</span>, <span class=hljs-string >"nasogastric_reflux"</span>,
    <span class=hljs-string >"nasogastric_reflux_ph"</span>, <span class=hljs-string >"feces"</span>, <span class=hljs-string >"abdomen"</span>,
    <span class=hljs-string >"packed_cell_volume"</span>, <span class=hljs-string >"total_protein"</span>,
    <span class=hljs-string >"abdomcentesis_appearance"</span>, <span class=hljs-string >"abdomcentesis_total_protein"</span>,
    <span class=hljs-string >"outcome"</span>, <span class=hljs-string >"surgical_lesion"</span>, <span class=hljs-string >"lesion_1"</span>, <span class=hljs-string >"lesion_2"</span>, <span class=hljs-string >"lesion_3"</span>,
    <span class=hljs-string >"cp_data"</span>]
csv_opts = (header=header, delim=<span class=hljs-string >' '</span>, missingstring=<span class=hljs-string >"?"</span>,
            ignorerepeated=<span class=hljs-literal >true</span>)
data_train = CSV.read(req1.body; csv_opts...)
data_test  = CSV.read(req2.body; csv_opts...)
<span class=hljs-meta >@show</span> size(data_train)
<span class=hljs-meta >@show</span> size(data_test)</code></pre><pre><code class="plaintext hljs">size(data_train) = (300, 28)
size(data_test) = (68, 28)
</code></pre> <h3 id=inspecting_columns ><a href="#inspecting_columns">Inspecting columns</a></h3> <p>To simplify the analysis, we will drop the columns <code>Lesion *</code> as they would need specific re-encoding which would distract us a bit.</p> <pre><code class="julia hljs">unwanted = [:lesion_1, :lesion_2, :lesion_3]
data = vcat(data_train, data_test)
select!(data, Not(unwanted));</code></pre> <p>Let&#39;s also keep track of the initial train-test split</p> <pre><code class="julia hljs">train = <span class=hljs-number >1</span>:nrows(data_train)
test = last(train) .+ (<span class=hljs-number >1</span>:nrows(data_test));</code></pre> <p>We know from reading the description that some of these features represent multiclass data; to facilitate the interpretation, we can use <code>autotype</code> from <code>ScientificTypes</code>. By default, <code>autotype</code> will check all columns and suggest a Finite type assuming there are relatively few distinct values in the column. More sophisticated rules can be passed, see <a href="https://alan-turing-institute.github.io/ScientificTypes.jl/dev/">ScientificTypes.jl</a>:</p> <pre><code class="julia hljs">datac = coerce(data, autotype(data));</code></pre>
<p>Let&#39;s see column by column whether it looks ok now</p>
<pre><code class="julia hljs">sch = schema(datac)
<span class=hljs-keyword >for</span> (name, scitype) <span class=hljs-keyword >in</span> zip(sch.names, sch.scitypes)
    println(rpad(<span class=hljs-string >"<span class=hljs-variable >$name</span>"</span>, <span class=hljs-number >30</span>), scitype)
<span class=hljs-keyword >end</span></code></pre><pre><code class="plaintext hljs">surgery                       Union{Missing, OrderedFactor{2}}
age                           OrderedFactor{2}
hospital_number               Count
rectal_temperature            Union{Missing, Continuous}
pulse                         Union{Missing, Count}
respiratory_rate              Union{Missing, Count}
temperature_extremities       Union{Missing, OrderedFactor{4}}
peripheral_pulse              Union{Missing, OrderedFactor{4}}
mucous_membranes              Union{Missing, OrderedFactor{6}}
capillary_refill_time         Union{Missing, OrderedFactor{3}}
pain                          Union{Missing, OrderedFactor{5}}
peristalsis                   Union{Missing, OrderedFactor{4}}
abdominal_distension          Union{Missing, OrderedFactor{4}}
nasogastric_tube              Union{Missing, OrderedFactor{3}}
nasogastric_reflux            Union{Missing, OrderedFactor{3}}
nasogastric_reflux_ph         Union{Missing, OrderedFactor{24}}
feces                         Union{Missing, OrderedFactor{4}}
abdomen                       Union{Missing, OrderedFactor{5}}
packed_cell_volume            Union{Missing, Continuous}
total_protein                 Union{Missing, Continuous}
abdomcentesis_appearance      Union{Missing, OrderedFactor{3}}
abdomcentesis_total_protein   Union{Missing, Continuous}
outcome                       Union{Missing, OrderedFactor{3}}
surgical_lesion               OrderedFactor{2}
cp_data                       OrderedFactor{2}
</code></pre>
<p>Most columns are now treated as either Multiclass or Ordered, this corresponds to the <a href="https://archive.ics.uci.edu/ml/datasets/Horse&#43;Colic">description of the data</a>. For instance:</p>
<ul>
<li><p><code>Surgery</code> is described as <code>1&#61;yes / 2&#61;no</code></p>

<li><p><code>Age</code> is described as <code>1&#61;adult / 2&#61;young</code></p>

</ul>
<p>Inspecting the rest of the descriptions and the current scientific type, there are a few more things that can be observed:</p>
<ul>
<li><p>hospital number is still a count, this means that there are relatively many hospitals and so  that&#39;s  probably not very useful,</p>

<li><p>pulse and respiratory rate are still as count but the data description suggests that they can be considered as continuous</p>

</ul>
<pre><code class="julia hljs">length(unique(datac.hospital_number))</code></pre><pre><code class="plaintext hljs">346</code></pre>
<p>yeah let&#39;s drop that</p>
<pre><code class="julia hljs">datac = select!(datac, Not(:hospital_number));</code></pre>
<p>let&#39;s also coerce the pulse and respiratory rate, in fact we can do that with <code>autotype</code> specifying as rule the <code>discrete_to_continuous</code>
<pre><code class="julia hljs">datac = coerce(datac, autotype(datac, rules=(:discrete_to_continuous,)));</code></pre>
<h3 id=dealing_with_missing_values ><a href="#dealing_with_missing_values">Dealing with missing values</a></h3>
<p>There&#39;s quite a lot of missing values, in this tutorial we&#39;ll be a bit rough in how we deal with them applying the following rules of thumb:</p>
<ul>
<li><p>drop the rows where the outcome is unknown</p>

<li><p>drop columns with more than 20&#37; missing values</p>

<li><p>simple imputation of whatever&#39;s left</p>

</ul>
<pre><code class="julia hljs">missing_outcome = ismissing.(datac.outcome)
idx_missing_outcome = missing_outcome |&gt; findall</code></pre><pre><code class="plaintext hljs">2-element Array{Int64,1}:
 133
 309</code></pre>
<p>Ok there&#39;s only two row which is nice, let&#39;s remove them from the train/test indices and drop the rows</p>
<pre><code class="julia hljs">train = setdiff!(train |&gt; collect, idx_missing_outcome)
test = setdiff!(test |&gt; collect, idx_missing_outcome)
datac = datac[.!missing_outcome, :];</code></pre>
<p>Now let&#39;s look at how many missings there are per features</p>
<pre><code class="julia hljs"><span class=hljs-keyword >for</span> name <span class=hljs-keyword >in</span> names(datac)
    col = datac[:, name]
    ratio_missing = sum(ismissing.(col)) / nrows(datac) * <span class=hljs-number >100</span>
    println(rpad(name, <span class=hljs-number >30</span>), round(ratio_missing, sigdigits=<span class=hljs-number >3</span>))
<span class=hljs-keyword >end</span></code></pre><pre><code class="plaintext hljs">surgery                       0.0
age                           0.0
rectal_temperature            18.9
pulse                         7.1
respiratory_rate              19.4
temperature_extremities       17.5
peripheral_pulse              22.7
mucous_membranes              13.1
capillary_refill_time         10.4
pain                          17.2
peristalsis                   13.9
abdominal_distension          17.5
nasogastric_tube              35.5
nasogastric_reflux            36.1
nasogastric_reflux_ph         81.1
feces                         34.7
abdomen                       39.1
packed_cell_volume            9.84
total_protein                 11.5
abdomcentesis_appearance      52.7
abdomcentesis_total_protein   63.9
outcome                       0.0
surgical_lesion               0.0
cp_data                       0.0
</code></pre>
<p>Let&#39;s drop the ones with more than 20&#37; &#40;quite a few&#33;&#41;</p>
<pre><code class="julia hljs">unwanted = [:peripheral_pulse, :nasogastric_tube, :nasogastric_reflux,
        :nasogastric_reflux_ph, :feces, :abdomen, :abdomcentesis_appearance, :abdomcentesis_total_protein]
select!(datac, Not(unwanted));</code></pre>
<p>Note that we could have done this better and investigated the nature of the features for which there&#39;s a lot of missing values but don&#39;t forget that our goal is to showcase MLJ&#33;</p>
<p>Let&#39;s conclude by filling all missing values and separating the feature matrix from the  target</p>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> FillImputer
filler = machine(FillImputer(), datac)
fit!(filler)
datac = transform(filler, datac)

y, X = unpack(datac, ==(:outcome), name-&gt;<span class=hljs-literal >true</span>);</code></pre>
<h2 id=a_baseline_model ><a href="#a_baseline_model">A baseline model</a></h2>
<p>Let&#39;s define a first sensible model and get a baseline, basic steps are:</p>
<ul>
<li><p>one-hot-encode the categoricals</p>

<li><p>feed all this into a classifier</p>

</ul>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> OneHotEncoder
<span class=hljs-meta >@load</span> MultinomialClassifier pkg=<span class=hljs-string >"MLJLinearModels"</span></code></pre><pre><code class="plaintext hljs">MultinomialClassifier(
    lambda = 1.0,
    gamma = 0.0,
    penalty = :l2,
    fit_intercept = true,
    penalize_intercept = false,
    solver = nothing,
    nclasses = 2) @ 7…84</code></pre>
<p>Let&#39;s have convenient handles over the training data</p>
<pre><code class="julia hljs">Xtrain = X[train,:]
ytrain = y[train];</code></pre>
<p>And let&#39;s define a pipeline corresponding to the operations above</p>
<pre><code class="julia hljs"><span class=hljs-meta >@pipeline</span> SimplePipe(hot = OneHotEncoder(),
                     clf = MultinomialClassifier()) is_probabilistic=<span class=hljs-literal >true</span>
mach = machine(SimplePipe(), Xtrain, ytrain)
res = evaluate!(mach; resampling=Holdout(fraction_train=<span class=hljs-number >0.9</span>),
                measure=cross_entropy)
round(res.measurement[<span class=hljs-number >1</span>], sigdigits=<span class=hljs-number >3</span>)</code></pre><pre><code class="plaintext hljs">0.707</code></pre>
<p>This is the cross entropy on some held-out 10&#37; of the training set. We can also just for the sake of getting a baseline, see the misclassification on the whole training data:</p>
<pre><code class="julia hljs">ŷ = predict_mode(mach, Xtrain)
mcr = misclassification_rate(ŷ, ytrain)
println(rpad(<span class=hljs-string >"MNC mcr:"</span>, <span class=hljs-number >10</span>), round(mcr, sigdigits=<span class=hljs-number >3</span>))</code></pre><pre><code class="plaintext hljs">MNC mcr:  0.234
</code></pre>
<p>That&#39;s not bad at all actually. Let&#39;s tune it a bit and see if we can get a bit better than that, not much point in going crazy, we might get a few percents but not much more.</p>
<pre><code class="julia hljs">model = SimplePipe()
lambdas = range(model, :(clf.lambda), lower=<span class=hljs-number >1e-3</span>, upper=<span class=hljs-number >100</span>, scale=:log10)
tm = TunedModel(model=SimplePipe(), ranges=lambdas, measure=cross_entropy)
mtm = machine(tm, Xtrain, ytrain)
fit!(mtm)
best_pipe = fitted_params(mtm).best_model</code></pre><pre><code class="plaintext hljs">SimplePipe(
    hot = OneHotEncoder(
            features = Symbol[],
            drop_last = false,
            ordered_factor = true,
            ignore = false),
    clf = MultinomialClassifier(
            lambda = 27.825594022071243,
            gamma = 0.0,
            penalty = :l2,
            fit_intercept = true,
            penalize_intercept = false,
            solver = nothing,
            nclasses = 3)) @ 1…87</code></pre>
<p>So it looks like it&#39;s useful to regularise a fair bit to get a lower cross entropy</p>
<pre><code class="julia hljs">ŷ = predict(mtm, Xtrain)
cross_entropy(ŷ, ytrain) |&gt; mean</code></pre><pre><code class="plaintext hljs">0.6129047563355016</code></pre>
<p>Interestingly this does not improve our missclassification rate</p>
<pre><code class="julia hljs">mcr = misclassification_rate(mode.(ŷ), ytrain)
println(rpad(<span class=hljs-string >"MNC mcr:"</span>, <span class=hljs-number >10</span>), round(mcr, sigdigits=<span class=hljs-number >3</span>))</code></pre><pre><code class="plaintext hljs">MNC mcr:  0.278
</code></pre>
<p>We&#39;ve probably reached the limit of a simple linear model.</p>
<h2 id=trying_another_model ><a href="#trying_another_model">Trying another model</a></h2>
<p>There are lots of categoricals, so maybe  it&#39;s just better to use something that deals well with that like a tree-based classifier.</p>
<pre><code class="julia hljs"><span class=hljs-meta >@load</span> XGBoostClassifier
dtc = machine(XGBoostClassifier(), Xtrain, ytrain)
fit!(dtc)
ŷ = predict(dtc, Xtrain)
cross_entropy(ŷ, ytrain) |&gt; mean</code></pre><pre><code class="plaintext hljs">0.024815100238238835</code></pre>
<p>So we get a worse cross entropy but...</p>
<pre><code class="julia hljs">misclassification_rate(mode.(ŷ), ytrain)</code></pre><pre><code class="plaintext hljs">0.0033444816053511705</code></pre>
<p>a significantly better misclassification rate.</p>
<p>We could investigate more, do more tuning etc, but the key points of this tutorial was to show how to handle data with missing values.<div class=page-foot >
  <div class=copyright >
    &copy; Thibaut Lienart, Anthony Blaom and collaborators. Last modified: May 24, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div>
      </div> 
  </div> 
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>