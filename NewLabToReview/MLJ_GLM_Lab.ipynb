{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MLJ with the GLM package\n",
    "\n",
    "This juypter lab showcases MLJ in particular using the popular [GLM](https://github.com/JuliaStats/GLM.jl) Julia package. We are using two datasets.  One dataset was created manually for testing purposes.  The other data set is the CollegeDistance dataset from the [AER](https://cran.r-project.org/web/packages/AER/index.html) package in R.  \n",
    "\n",
    "We can quickly define our models in MLJ and study their results.  It is very easy and consistent.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearBinaryClassifier(\n",
       "    fit_intercept = true,\n",
       "    link = GLM.LogitLink())\u001b[34m @ 8…69\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Queryverse, MLJ, CategoricalArrays, PrettyPrinting\n",
    "@load LinearRegressor pkg = GLM\n",
    "@load LinearBinaryClassifier pkg=GLM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data\n",
    "\n",
    "The the CollegeDistance dataset was stored in a CSV file.  Here, we read the input file.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Y</th></tr><tr><th></th><th>Float64</th></tr></thead><tbody><p>4,000 rows × 1 columns</p><tr><th>1</th><td>-2.04463</td></tr><tr><th>2</th><td>-0.461529</td></tr><tr><th>3</th><td>0.458262</td></tr><tr><th>4</th><td>2.27462</td></tr><tr><th>5</th><td>-0.969887</td></tr><tr><th>6</th><td>0.649164</td></tr><tr><th>7</th><td>-0.371084</td></tr><tr><th>8</th><td>2.06409</td></tr><tr><th>9</th><td>1.74157</td></tr><tr><th>10</th><td>0.347421</td></tr><tr><th>11</th><td>-0.0143199</td></tr><tr><th>12</th><td>-0.681539</td></tr><tr><th>13</th><td>1.02899</td></tr><tr><th>14</th><td>-1.15985</td></tr><tr><th>15</th><td>-0.0252663</td></tr><tr><th>16</th><td>0.219885</td></tr><tr><th>17</th><td>0.200231</td></tr><tr><th>18</th><td>3.20963</td></tr><tr><th>19</th><td>2.85346</td></tr><tr><th>20</th><td>0.11007</td></tr><tr><th>21</th><td>0.899752</td></tr><tr><th>22</th><td>0.0555416</td></tr><tr><th>23</th><td>-1.69663</td></tr><tr><th>24</th><td>-4.06557</td></tr><tr><th>25</th><td>1.07183</td></tr><tr><th>26</th><td>-0.16753</td></tr><tr><th>27</th><td>-0.980374</td></tr><tr><th>28</th><td>0.419088</td></tr><tr><th>29</th><td>-2.52421</td></tr><tr><th>30</th><td>-0.200639</td></tr><tr><th>&vellip;</th><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& Y\\\\\n",
       "\t\\hline\n",
       "\t& Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & -2.04463 \\\\\n",
       "\t2 & -0.461529 \\\\\n",
       "\t3 & 0.458262 \\\\\n",
       "\t4 & 2.27462 \\\\\n",
       "\t5 & -0.969887 \\\\\n",
       "\t6 & 0.649164 \\\\\n",
       "\t7 & -0.371084 \\\\\n",
       "\t8 & 2.06409 \\\\\n",
       "\t9 & 1.74157 \\\\\n",
       "\t10 & 0.347421 \\\\\n",
       "\t11 & -0.0143199 \\\\\n",
       "\t12 & -0.681539 \\\\\n",
       "\t13 & 1.02899 \\\\\n",
       "\t14 & -1.15985 \\\\\n",
       "\t15 & -0.0252663 \\\\\n",
       "\t16 & 0.219885 \\\\\n",
       "\t17 & 0.200231 \\\\\n",
       "\t18 & 3.20963 \\\\\n",
       "\t19 & 2.85346 \\\\\n",
       "\t20 & 0.11007 \\\\\n",
       "\t21 & 0.899752 \\\\\n",
       "\t22 & 0.0555416 \\\\\n",
       "\t23 & -1.69663 \\\\\n",
       "\t24 & -4.06557 \\\\\n",
       "\t25 & 1.07183 \\\\\n",
       "\t26 & -0.16753 \\\\\n",
       "\t27 & -0.980374 \\\\\n",
       "\t28 & 0.419088 \\\\\n",
       "\t29 & -2.52421 \\\\\n",
       "\t30 & -0.200639 \\\\\n",
       "\t$\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "4000×1 DataFrame\n",
       "│ Row  │ Y         │\n",
       "│      │ \u001b[90mFloat64\u001b[39m   │\n",
       "├──────┼───────────┤\n",
       "│ 1    │ -2.04463  │\n",
       "│ 2    │ -0.461529 │\n",
       "│ 3    │ 0.458262  │\n",
       "│ 4    │ 2.27462   │\n",
       "│ 5    │ -0.969887 │\n",
       "│ 6    │ 0.649164  │\n",
       "│ 7    │ -0.371084 │\n",
       "│ 8    │ 2.06409   │\n",
       "│ 9    │ 1.74157   │\n",
       "│ 10   │ 0.347421  │\n",
       "⋮\n",
       "│ 3990 │ 0.164744  │\n",
       "│ 3991 │ 0.147512  │\n",
       "│ 3992 │ -0.7335   │\n",
       "│ 3993 │ 0.512661  │\n",
       "│ 3994 │ 2.18719   │\n",
       "│ 3995 │ 2.0201    │\n",
       "│ 3996 │ -1.86067  │\n",
       "│ 3997 │ 0.428379  │\n",
       "│ 3998 │ -2.49518  │\n",
       "│ 3999 │ -3.77547  │\n",
       "│ 4000 │ -2.74644  │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX = DataFrame(Queryverse.load(\"C:\\\\Users\\\\BCP\\\\github\\\\ICP\\\\Test\\\\X3.csv\"))\n",
    "dfYbinary = DataFrame(Queryverse.load(\"C:\\\\Users\\\\BCP\\\\github\\\\ICP\\\\Test\\\\Y3.csv\"))\n",
    "\n",
    "dfX1 = DataFrame(Queryverse.load(\"C:\\\\Users\\\\BCP\\\\github\\\\ICP\\\\Test\\\\X1.csv\"))\n",
    "dfY1 = DataFrame(Queryverse.load(\"C:\\\\Users\\\\BCP\\\\github\\\\ICP\\\\Test\\\\Y1.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Linear Model\n",
    "\n",
    "Let see how many MLJ models handle our kind of target which is the y variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = EvoTreeCount, package_name = EvoTrees, ... )\n",
       " (name = LinearCountRegressor, package_name = GLM, ... )\n",
       " (name = XGBoostCount, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ms = models() do m AbstractVector{Count}<: m.target_scitype end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53-element Array{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype),T} where T<:Tuple,1}:\n",
       " (name = ARDRegressor, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostRegressor, package_name = ScikitLearn, ... )\n",
       " (name = BaggingRegressor, package_name = ScikitLearn, ... )\n",
       " (name = BayesianRidgeRegressor, package_name = ScikitLearn, ... )\n",
       " (name = ConstantRegressor, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeRegressor, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantRegressor, package_name = MLJModels, ... )\n",
       " (name = DummyRegressor, package_name = ScikitLearn, ... )\n",
       " (name = ElasticNetCVRegressor, package_name = ScikitLearn, ... )\n",
       " (name = ElasticNetRegressor, package_name = MLJLinearModels, ... )\n",
       " (name = ElasticNetRegressor, package_name = ScikitLearn, ... )\n",
       " (name = EpsilonSVR, package_name = LIBSVM, ... )\n",
       " (name = EvoTreeGaussian, package_name = EvoTrees, ... )\n",
       " ⋮\n",
       " (name = RandomForestRegressor, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVRegressor, package_name = ScikitLearn, ... )\n",
       " (name = RidgeRegressor, package_name = MLJLinearModels, ... )\n",
       " (name = RidgeRegressor, package_name = MultivariateStats, ... )\n",
       " (name = RidgeRegressor, package_name = ScikitLearn, ... )\n",
       " (name = RobustRegressor, package_name = MLJLinearModels, ... )\n",
       " (name = SGDRegressor, package_name = ScikitLearn, ... )\n",
       " (name = SVMLRegressor, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuRegressor, package_name = ScikitLearn, ... )\n",
       " (name = SVMRegressor, package_name = ScikitLearn, ... )\n",
       " (name = TheilSenRegressor, package_name = ScikitLearn, ... )\n",
       " (name = XGBoostRegressor, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ms = models() do m Vector{Continuous}<: m.target_scitype end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly define our models in MLJ.  It is very easy and consistent.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{LinearRegressorPipe} @ 3…16\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n",
      "┌ Info: Training \u001b[34mNodalMachine{Standardizer} @ 8…90\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n",
      "┌ Info: Training \u001b[34mNodalMachine{OneHotEncoder} @ 9…62\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n",
      "┌ Info: Training \u001b[34mNodalMachine{LinearRegressor} @ 1…25\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(machines = Any[\u001b[34mNodalMachine{LinearRegressor} @ 1…25\u001b[39m, \u001b[34mNodalMachine{OneHotEncoder} @ 9…62\u001b[39m, \u001b[34mNodalMachine{Standardizer} @ 8…90\u001b[39m],\n",
       " fitted_params_given_machine = OrderedCollections.LittleDict{Any,Any,Array{Any,1},Array{Any,1}}(\u001b[34mNodalMachine{LinearRegressor} @ 1…25\u001b[39m => (coef = [1.0207869497405524, 1.03242891546997, 0.009406292423317655, 0.026633915171207473, 0.29985915636370225], intercept = 0.015893883995789806),\u001b[34mNodalMachine{OneHotEncoder} @ 9…62\u001b[39m => (fitresult = \u001b[34mOneHotEncoderResult @ 5…57\u001b[39m,),\u001b[34mNodalMachine{Standardizer} @ 8…90\u001b[39m => (mean_and_std_given_feature = Dict(:V1 => (0.0024456300706479973, 1.1309193246154066),:V2 => (-0.015561621122145304, 1.1238897897565245),:V5 => (0.0077036209704558975, 1.1421493464876622),:V3 => (0.02442889884313839, 2.332713568319154),:V4 => (0.15168404285157286, 6.806065861835239)),)),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = copy(dfX1)\n",
    "y = copy(dfY1)\n",
    "\n",
    "@pipeline LinearRegressorPipe(\n",
    "            std = Standardizer(),\n",
    "            hot = OneHotEncoder(drop_last = true),\n",
    "            reg = LinearRegressor()\n",
    ")\n",
    "\n",
    "coerce!(X, autotype(X, :string_to_multiclass))\n",
    "yv = Vector(y[:, 1])\n",
    "\n",
    "LinearModel = machine(LinearRegressorPipe(), X, yv)\n",
    "fit!(LinearModel)\n",
    "fp = fitted_params(LinearModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Output of Fitting the Linear Model\n",
    "\n",
    "We can quickly read the results of our models in MLJ.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "(machines = [\u001b[34mNodalMachine{LinearRegressor} @ 1…25\u001b[39m,\n",
      "             \u001b[34mNodalMachine{OneHotEncoder} @ 9…62\u001b[39m,\n",
      "             \u001b[34mNodalMachine{Standardizer} @ 8…90\u001b[39m],\n",
      " report_given_machine =\n",
      "     OrderedCollections.LittleDict{Any,Any,Array{Any,1},Array{Any,1}}(\u001b[34mNodalMachine{LinearRegressor} @ 1…25\u001b[39m => (deviance = 3665.985359058753, dof_residual = 3994.0, stderror = [0.015876403107805682, 0.015862782503144914, 0.01515900587321476, 0.01515667698600387, 0.016546721612329368, 0.015148210698700702], vcov = [0.0002520601756415419 2.2602205615189535e-5 -3.3011444355349533e-7 -2.5960643906454084e-6 -7.850207954537936e-5 -5.751748134914404e-21; 2.2602205615189535e-5 0.00025162786874208037 6.311155185082322e-6 3.956572604670321e-6 -7.734342973144668e-5 6.300052382199008e-21; -3.3011444355349533e-7 6.311155185082322e-6 0.00022979545906415963 -4.596108103995977e-6 -5.750120169106886e-8 8.332417766642423e-22; -2.5960643906454084e-6 3.956572604670321e-6 -4.596108103995977e-6 0.00022972485725805932 7.38611582415167e-7 -2.3961699769500786e-21; -7.850207954537936e-5 -7.734342973144668e-5 -5.750120169106886e-8 7.38611582415167e-7 0.00027379399611592785 -1.7674404938821194e-21; -5.751748134914404e-21 6.300052382199008e-21 8.332417766642423e-22 -2.3961699769500786e-21 -1.7674404938821194e-21 0.0002294682873722304]),\u001b[34mNodalMachine{OneHotEncoder} @ 9…62\u001b[39m => (features_to_be_encoded = Symbol[], new_features = [:V1, :V2, :V3, :V4, :V5]),\u001b[34mNodalMachine{Standardizer} @ 8…90\u001b[39m => (features_fit = [:V1, :V2, :V5, :V3, :V4],)))\n",
      "========================================\n",
      "\n",
      " Coefficients:  [1.0207869497405524, 1.03242891546997, 0.009406292423317655, 0.026633915171207473, 0.29985915636370225]\n",
      "\n",
      " y \n",
      " [-2.0446341129015, -0.461528671336098, 0.458261960749596, 2.2746223981481, -0.969887403007307]\n",
      "\n",
      " ŷ \n",
      " Distributions.Normal{Float64}[Distributions.Normal{Float64}(μ=-1.6915415373374758, σ=0.9580569656804974), Distributions.Normal{Float64}(μ=1.412005563203644, σ=0.9580569656804974), Distributions.Normal{Float64}(μ=0.47362968068623923, σ=0.9580569656804974), Distributions.Normal{Float64}(μ=0.7266938985590492, σ=0.9580569656804974), Distributions.Normal{Float64}(μ=-1.8396459459760566, σ=0.9580569656804974)]\n",
      "\n",
      " yhatResponse \n",
      " [-1.6915415373374758, 1.412005563203644, 0.47362968068623923, 0.7266938985590492, -1.8396459459760566]\n",
      "\n",
      " Residuals \n",
      " [-0.3530925755640242, -1.8735342345397419, -0.01536771993664321, 1.547928499589051, 0.8697585429687495]\n",
      "\n",
      " Standard Error per Coefficient \n",
      "[0.015876403107805682, 0.015862782503144914, 0.01515900587321476, 0.01515667698600387, 0.016546721612329368, 0.015148210698700702]\n"
     ]
    }
   ],
   "source": [
    "ŷ = MLJ.predict(LinearModel, X)\n",
    "yhatResponse = [ŷ[i,1].μ for i in 1:nrow(y)]\n",
    "residuals = y .- yhatResponse\n",
    "r = report(LinearModel)\n",
    "\n",
    "println(\"========================================\")\n",
    "pprint(r)\n",
    "println(\"\\n========================================\")\n",
    "\n",
    "k = collect(keys(fp.fitted_params_given_machine))[1]\n",
    "println(\"\\n Coefficients:  \", fp.fitted_params_given_machine[k].coef)\n",
    "println(\"\\n y \\n \", y[1:5,1])\n",
    "println(\"\\n ŷ \\n \", ŷ[1:5])\n",
    "println(\"\\n yhatResponse \\n \", yhatResponse[1:5])\n",
    "println(\"\\n Residuals \\n \", y[1:5,1] .- yhatResponse[1:5])\n",
    "println(\"\\n Standard Error per Coefficient \\n\", r.report_given_machine[k].stderror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{LinearBinaryClassifierPipe} @ 6…09\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n",
      "┌ Info: Training \u001b[34mNodalMachine{Standardizer} @ 6…33\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n",
      "┌ Info: Training \u001b[34mNodalMachine{OneHotEncoder} @ 4…11\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n",
      "┌ Info: Spawning 1 sub-features to one-hot encode feature :gender.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Spawning 2 sub-features to one-hot encode feature :ethnicity.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Spawning 1 sub-features to one-hot encode feature :fcollege.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Spawning 1 sub-features to one-hot encode feature :mcollege.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Spawning 1 sub-features to one-hot encode feature :home.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Spawning 1 sub-features to one-hot encode feature :urban.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Spawning 1 sub-features to one-hot encode feature :income.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Spawning 1 sub-features to one-hot encode feature :region.\n",
      "└ @ MLJModels C:\\Users\\BCP\\.julia\\packages\\MLJModels\\Hrhbw\\src\\builtins\\Transformers.jl:762\n",
      "┌ Info: Training \u001b[34mNodalMachine{LinearBinaryClassifier{LogitLink}} @ 1…83\u001b[39m.\n",
      "└ @ MLJBase C:\\Users\\BCP\\.julia\\packages\\MLJBase\\LoSOQ\\src\\machines.jl:183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(machines = Any[\u001b[34mNodalMachine{LinearBinaryClassifier{LogitLink}} @ 1…83\u001b[39m, \u001b[34mNodalMachine{OneHotEncoder} @ 4…11\u001b[39m, \u001b[34mNodalMachine{Standardizer} @ 6…33\u001b[39m],\n",
       " fitted_params_given_machine = OrderedCollections.LittleDict{Any,Any,Array{Any,1},Array{Any,1}}(\u001b[34mNodalMachine{LinearBinaryClassifier{LogitLink}} @ 1…83\u001b[39m => (coef = [0.2025072937886874, 0.130752939109129, 0.344951624939835, 0.9977565847160846, -0.5022315102984594, -0.47850056260216534, -0.20440507809955016, -0.06922751403500091, 0.05892864973017097, -0.08344749828203228, -0.0023151433338597475, 0.4617765395578656, 0.3843262958100775], intercept = -1.076633890579365),\u001b[34mNodalMachine{OneHotEncoder} @ 4…11\u001b[39m => (fitresult = \u001b[34mOneHotEncoderResult @ 7…00\u001b[39m,),\u001b[34mNodalMachine{Standardizer} @ 6…33\u001b[39m => (mean_and_std_given_feature = Dict(:wage => (9.500506478338009, 1.3430670761078416),:unemp => (7.597214581091511, 2.763580873344848),:tuition => (0.8146082493518824, 0.33950381985971717),:score => (50.88902933684601, 8.701909614072397)),)),)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = copy(dfX)\n",
    "y = copy(dfYbinary)\n",
    "\n",
    "@pipeline LinearBinaryClassifierPipe(\n",
    "            std = Standardizer(),\n",
    "            hot = OneHotEncoder(drop_last = true),\n",
    "            reg = LinearBinaryClassifier()\n",
    ")\n",
    "\n",
    "coerce!(X, autotype(X, :string_to_multiclass))\n",
    "yc = CategoricalArray(y[:, 1])\n",
    "yc = coerce(yc, OrderedFactor)\n",
    "\n",
    "LogisticModel = machine(LinearBinaryClassifierPipe(), X, yc)\n",
    "fit!(LogisticModel)\n",
    "fp = fitted_params(LogisticModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Output from the Prediction of the Logistic Model\n",
    "\n",
    "The output of the MLJ model basically contain the same information as the R version of the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "(machines = [\u001b[34mNodalMachine{LinearBinaryClassifier{LogitLink}} @ 1…83\u001b[39m,\n",
      "             \u001b[34mNodalMachine{OneHotEncoder} @ 4…11\u001b[39m,\n",
      "             \u001b[34mNodalMachine{Standardizer} @ 6…33\u001b[39m],\n",
      " report_given_machine =\n",
      "     OrderedCollections.LittleDict{Any,Any,Array{Any,1},Array{Any,1}}(\u001b[34mNodalMachine{LinearBinaryClassifier{LogitLink}} @ 1…83\u001b[39m => (deviance = 4455.662325324947, dof_residual = 4726.0, stderror = [0.07542967234030673, 0.1226000420274196, 0.10934317995152515, 0.046614372503729386, 0.0960924372481536, 0.10743620672240188, 0.10642223545563925, 0.09190778860389336, 0.039227245365088655, 0.04118915117919153, 0.05115399636339274, 0.08454431256127863, 0.12281455657940012, 0.17884724866298302], vcov = [0.005689635469366034 0.00017587716108658598 0.00046323946802323416 0.0003795721149201088 -0.00019490704288535566 6.090592126972174e-5 -0.0001803560619668214 -0.00022255973418694745 -5.5862189997762526e-5 0.00011040714633407938 2.4029524302818077e-5 0.00027613185520564365 4.0379492600757386e-5 -0.0032223988058702057; 0.00017587716108658598 0.015030770305125053 0.0030815766051367757 0.0014841047877545731 -0.000614684947435086 0.0006549513738058027 -0.0010367208516729996 0.0017289660442525376 5.419502190930666e-5 0.0003572620683454678 -9.253632237560017e-5 0.0005154995198957178 -0.0007663688201711846 -0.003935402013734099; 0.00046323946802323416 0.0030815766051367757 0.011955931001911613 0.0009371746823744725 -0.00043427954925584646 -0.00039940377767757815 -0.0007274279334656171 0.0010164864830337513 -0.0006462212212366474 0.00033048317626940176 0.0010414408374671508 0.000642149399527746 0.00016984699821089434 -0.003559520126669645; 0.0003795721149201088 0.0014841047877545731 0.0009371746823744725 0.0021728997239164423 0.00029175717742387097 0.00019359914699709904 5.6745908610638524e-5 -3.172535774607292e-5 6.517052028049314e-5 -7.240943054447556e-5 -0.00017243530013535775 0.00010131973081247049 0.00022239872735001275 -0.0019979132731591073; -0.00019490704288535566 -0.000614684947435086 -0.00043427954925584646 0.00029175717742387097 0.009233756496290338 -0.00355184679583402 -9.998364231272937e-5 6.53662870458673e-5 -0.00025202906140676045 2.7692082308077846e-5 6.408973016168575e-5 0.0020967124187260587 -0.0005933040620298645 -0.003956976109893046; 6.090592126972174e-5 0.0006549513738058027 -0.00039940377767757815 0.00019359914699709904 -0.00355184679583402 0.011542538514898672 -8.852341628837407e-5 9.561048832597112e-5 -0.00015103917056737706 -6.179862424903284e-7 -1.4362348323777125e-5 0.0008783123228177975 0.00010414617860737049 -0.0075015300602459456; -0.0001803560619668214 -0.0010367208516729996 -0.0007274279334656171 5.6745908610638524e-5 -9.998364231272937e-5 -8.852341628837407e-5 0.011325692199375521 0.000414490409335989 2.617875654185725e-5 0.00015478742268465408 -0.0001623954929906194 0.0008797785572162364 0.00011812261057960285 -0.0019251049703396632; -0.00022255973418694745 0.0017289660442525376 0.0010164864830337513 -3.172535774607292e-5 6.53662870458673e-5 9.561048832597112e-5 0.000414490409335989 0.00844704160605795 -0.00023036669516896463 2.646944222320686e-5 -0.00013859297972144535 -0.000358934260760554 0.0005502651634978588 -0.007337462423515122; -5.5862189997762526e-5 5.419502190930666e-5 -0.0006462212212366474 6.517052028049314e-5 -0.00025202906140676045 -0.00015103917056737706 2.617875654185725e-5 -0.00023036669516896463 0.001538776778932869 -0.0003833420723206135 -0.00027902748028955015 0.00021283400418763108 0.0002037331659207198 0.00037664302386832915; 0.00011040714633407938 0.0003572620683454678 0.00033048317626940176 -7.240943054447556e-5 2.7692082308077846e-5 -6.179862424903284e-7 0.00015478742268465408 2.646944222320686e-5 -0.0003833420723206135 0.001696546174862295 -0.0005886099417334052 -0.00017035325683361575 0.000592478796325022 -0.0006394243721255306; 2.4029524302818077e-5 -9.253632237560017e-5 0.0010414408374671508 -0.00017243530013535775 6.408973016168575e-5 -1.4362348323777125e-5 -0.0001623954929906194 -0.00013859297972144535 -0.00027902748028955015 -0.0005886099417334052 0.0026167313439459977 -0.00012182163462840968 -0.0037053954907699128 0.0029124288553434683; 0.00027613185520564365 0.0005154995198957178 0.000642149399527746 0.00010131973081247049 0.0020967124187260587 0.0008783123228177975 0.0008797785572162364 -0.000358934260760554 0.00021283400418763108 -0.00017035325683361575 -0.00012182163462840968 0.007147740786459175 0.00035364569693683754 -0.0052692738776326615; 4.0379492600757386e-5 -0.0007663688201711846 0.00016984699821089434 0.00022239872735001275 -0.0005933040620298645 0.00010414617860737049 0.00011812261057960285 0.0005502651634978588 0.0002037331659207198 0.000592478796325022 -0.0037053954907699128 0.00035364569693683754 0.015083415307794673 -0.012411033359895709; -0.0032223988058702057 -0.003935402013734099 -0.003559520126669645 -0.0019979132731591073 -0.003956976109893046 -0.0075015300602459456 -0.0019251049703396632 -0.007337462423515122 0.00037664302386832915 -0.0006394243721255306 0.0029124288553434683 -0.0052692738776326615 -0.012411033359895709 0.03198633835431888]),\u001b[34mNodalMachine{OneHotEncoder} @ 4…11\u001b[39m => (features_to_be_encoded = [:income, :ethnicity, :fcollege, :home, :urban, :region, :mcollege, :gender], new_features = [:gender__female, :ethnicity__afam, :ethnicity__hispanic, :score, :fcollege__no, :mcollege__no, :home__no, :urban__no, :unemp, :wage, :tuition, :income__high, :region__other]),\u001b[34mNodalMachine{Standardizer} @ 6…33\u001b[39m => (features_fit = [:wage, :unemp, :tuition, :score],)))\n",
      "========================================\n",
      "\n",
      " Coefficients:  [0.2025072937886874, 0.130752939109129, 0.344951624939835, 0.9977565847160846, -0.5022315102984594, -0.47850056260216534, -0.20440507809955016, -0.06922751403500091, 0.05892864973017097, -0.08344749828203228, -0.0023151433338597475, 0.4617765395578656, 0.3843262958100775]\n",
      "\n",
      " y \n",
      " [0, 0, 0, 0, 0]\n",
      "\n",
      " ŷ \n",
      " UnivariateFinite{Int64,UInt32,Float64}[UnivariateFinite(0=>0.881, 1=>0.119), UnivariateFinite(0=>0.838, 1=>0.162), UnivariateFinite(0=>0.866, 1=>0.134), UnivariateFinite(0=>0.936, 1=>0.0637), UnivariateFinite(0=>0.944, 1=>0.056)]\n",
      "\n",
      " residuals \n",
      " [0.119446033467422, 0.16182691493524637, 0.13445730373831222, 0.06370799769022906, 0.05604680411361729]\n",
      "\n",
      " Standard Error per Coefficient \n",
      "[0.07542967234030673, 0.1226000420274196, 0.10934317995152515, 0.046614372503729386, 0.0960924372481536, 0.10743620672240188, 0.10642223545563925, 0.09190778860389336, 0.039227245365088655, 0.04118915117919153, 0.05115399636339274, 0.08454431256127863, 0.12281455657940012, 0.17884724866298302]\n"
     ]
    }
   ],
   "source": [
    "ŷ = MLJ.predict(LogisticModel, X)\n",
    "residuals = [1 - pdf(ŷ[i], y[i,1]) for i in 1:nrow(y)]\n",
    "r = report(LogisticModel)\n",
    "\n",
    "println(\"========================================\")\n",
    "pprint(r)\n",
    "println(\"\\n========================================\")\n",
    "k = collect(keys(fp.fitted_params_given_machine))[1]\n",
    "println(\"\\n Coefficients:  \", fp.fitted_params_given_machine[k].coef)\n",
    "println(\"\\n y \\n \", y[1:5,1])\n",
    "println(\"\\n ŷ \\n \", ŷ[1:5])\n",
    "println(\"\\n residuals \\n \", residuals[1:5])\n",
    "println(\"\\n Standard Error per Coefficient \\n\", r.report_given_machine[k].stderror)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
