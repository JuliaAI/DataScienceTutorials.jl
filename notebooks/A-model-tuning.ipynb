{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Before running this, make sure to instantiate the environment corresponding to\n",
    "[this `Project.toml`](https://raw.githubusercontent.com/tlienart/MLJTutorials/master/Project.toml)\n",
    "and [this `Manifest.toml`](https://raw.githubusercontent.com/tlienart/MLJTutorials/master/Manifest.toml)\n",
    "so that you get an environment which matches the one used to generate the tutorials.\n",
    "\n",
    "To do so, copy both files in a folder, start Julia in that folder and\n",
    "\n",
    "```julia\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "[MLJ.jl]: https://github.com/alan-turing-institute/MLJ.jl\n",
    "[RDatasets.jl]: https://github.com/JuliaStats/RDatasets.jl\n",
    "[NearestNeighbors.jl]: https://github.com/KristofferC/NearestNeighbors.jl\n",
    "\n",
    "## Tuning a single hyperparameter\n",
    "\n",
    "In MLJ, tuning is implemented as a model wrapper.\n",
    "After wrapping a model in a _tuning strategy_ (e.g. cross-validation) and binding the wrapped model to data in a _machine_, fitting the machine initiates a search for optimal model hyperparameters.\n",
    "\n",
    "Let's use a decision tree classifier and tune the maximum depth of the tree.\n",
    "As usual, start by loading data and the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "X, y = @load_iris\n",
    "@load DecisionTreeClassifier"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Specifying a range of value\n",
    "\n",
    "To specify a range of value, you can use the `range` function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "r   = range(dtc, :max_depth, lower=1, upper=5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As you can see, the range function takes a model (`dtc`), a symbol for the hyperparameter of interest (`:max_depth`) and indication of how to samples values.\n",
    "You can either manually specify an iterator over values by using the `values=` keyword or, where appropriate, use the `lower` and `upper` keywords which help define such an iterator between bounds.\n",
    "\n",
    "Once a range of value has been defined, you can then wrap the model in a `TunedModel` specifying the tuning strategy:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tm = TunedModel(model=dtc, ranges=[r, ], measure=cross_entropy)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Fitting and inspecting a tuned model\n",
    "\n",
    "To fit a tuned model, you can use the usual syntax:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m = machine(tm, X, y)\n",
    "fit!(m)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "In order to inspect the best model, you can use the function `fitted_params` on the machine and inspect the `best_model` field:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fitted_params(m).best_model.max_depth"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Tuning nested hyperparameters"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's generate simple dummy regression data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = (x1=rand(100), x2=rand(100), x3=rand(100))\n",
    "y = 2X.x1 - X.x2 + 0.05 * randn(100);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's then build a simple ensemble model with decision tree regressors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dtr = @load DecisionTreeRegressor\n",
    "forest = EnsembleModel(atom=dtr)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Such a model has *nested* hyperparameters in that the ensemble has hyperparameters (e.g. the `:bagging_fraction`) and the atom has hyperparameters (e.g. `:n_subfeatures` or `:max_depth`).\n",
    "\n",
    "Range for nested hyperparameters are specified using dot syntax, the rest is done in much the same way as before:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r1 = range(forest, :(atom.n_subfeatures), lower=1, upper=3)\n",
    "r2 = range(forest, :bagging_fraction, lower=0.4, upper=1.0)\n",
    "tm = TunedModel(model=forest, tuning=Grid(resolution=12),\n",
    "                resampling=CV(nfolds=6), ranges=[r1, r2],\n",
    "                measure=rms)\n",
    "m = machine(tm, X, y)\n",
    "fit!(m);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "A useful function to inspect a model after fitting it is the `report` function which collects information on the model and the tuning, for instance you can use it to recover the best measurement:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = report(m)\n",
    "r.best_measurement"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0-rc3.0"
  },
  "kernelspec": {
   "name": "julia-1.3",
   "display_name": "Julia 1.3.0-rc3.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
