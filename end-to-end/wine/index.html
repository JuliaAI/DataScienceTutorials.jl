<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/DataScienceTutorials.jl/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/landing.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/franklin.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/pure.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/side-menu.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/nav.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/extra.css">
  <!-- <link rel="icon" href="/DataScienceTutorials.jl/assets/infra/favicon.gif"> -->
   <title>Wine</title> 
  <!-- LUNR -->
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script>
</head>

<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu" style="display: none;">
      <div class="pure-menu">
        <a href="/DataScienceTutorials.jl/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Search in tutorials..." type="text">
          <input type="submit" value="Search" formaction="/DataScienceTutorials.jl/search/index.html" style="display:none">
        </form>
        <!-- LIST OF MENU ITEMS -->
        <ul class="pure-menu-list">
          <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/"
              class="pure-menu-link"><strong>Home</strong></a></li>

          <!-- DATA BASICS -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Data Basics</strong></li>
          </div>
          <div class="collapse dropdown-content">
            <ul class="pure-menu-sublist">
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading
                  data</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data
                  Frames</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Categorical Arrays</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific
                  Type</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/data/processing/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data
                  processing</a></li>
            </ul>
          </div>

          <!-- GETTING STARTED WITH MLJ -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Getting Started</strong></li>
          </div>
          <div class="collapse dropdown-content">
            <ul class="pure-menu-sublist">
              <li
                class="pure-menu-item ">
                <a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Choosing a model</a>
              </li>
              <li class="pure-menu-item ">
                <a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Fit, predict, transform</a>
              </li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/getting-started/model-tuning/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Model tuning</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Ensembles</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Ensembles 2</a></li>
              <li
                class="pure-menu-item ">
                <a href="/DataScienceTutorials.jl/getting-started/composing-models/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Composing models</a>
              </li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Stacking</a></li>
            </ul>
          </div>
          <!-- INTRO TO STATS LEARNING -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
          </div>
          <div class="collapse dropdown-content">
            <ul class="pure-menu-sublist" id=isl>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/"
                  class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 3</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 4</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 5</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 8</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 9</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Lab 10</a></li>
            </ul>
          </div>
          <!-- End to End -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>End to End</strong></li>
          </div>
          <div class="dropdown-content collapse">
            <ul class="pure-menu-sublist" >
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/end-to-end/telco/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>Telco
                  Churn</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a>
              </li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Wine</a></li>
              <li class="pure-menu-item "><a
                  href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span>
                  Crabs (XGB)</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Horse</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> King County Houses</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Airfoil </a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/powergen/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Power Generation </a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-flux" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/breastcancer" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Breast Cancer</a></li>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/creditfraud" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Credit Fraud</a></li>
            </ul>
          </div>
          <!-- ADVANCED EXAMPLES -->
          <div class="dropdown">
            <li class="pure-menu-sublist-title"><strong>Advanced Examples</strong></li>
          </div>
          <div class="dropdown-content collapse">
            <ul class="pure-menu-sublist" id=adv>
              <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/advanced/ensembles-3/" class="pure-menu-link"><span
                    style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
            </ul>
          </div>
      </div>
      </ul>
      <!-- END OF LIST OF MENU ITEMS -->
    </div>
  </div>
  <div id="nav" class="navigation">
    <div class="nav-container">
      <div class="brand">
        <a href="/DataScienceTutorials.jl/">DataScienceTutorials.jl</a>
      </div>
      <nav>
        <div class="nav-mobile"><a id="nav-toggle" href="#!"><span></span></a></div>
        <ul class="nav-list">
        <!-- horizontal navigation bar gets injected -->
        </ul>
      </nav>
    </div>
  </div>
  <div id="main"> <!-- Closed in foot -->
    

    <!-- Content appended here --><div class="franklin-content"><h1 id="wine"><a href="#wine" class="header-anchor">Wine</a></h1>
<em>To ensure code in this tutorial runs as shown, download the tutorial <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/end-to-end/wine.tar.gz">project folder</a> and follow <a href="/DataScienceTutorials.jl/#learning_by_doing">these instructions</a>.</em></p>
<p><em>If you have questions or suggestions about this tutorial, please open an issue <a href="https://github.com/JuliaAI/DataScienceTutorials.jl/issues/new">here</a>.</em></p>
<p><div class="franklin-toc"><ol><li><a href="#initial_data_processing">Initial data processing</a><ol><li><a href="#getting_the_data">Getting the data</a></li><li><a href="#setting_the_scientific_type">Setting the scientific type</a></li></ol></li><li><a href="#getting_a_baseline">Getting a baseline</a></li><li><a href="#visualising_the_classes">Visualising the classes</a></li></ol></div>
<div class="dropdown"><h2 id="initial_data_processing"><a href="#initial_data_processing" class="header-anchor">Initial data processing</a></h2></div>
<div class="dropdown-content"><p>In this example, we consider the <a href="http://archive.ics.uci.edu/ml/datasets/wine">UCI &quot;wine&quot; dataset</a></p>
<blockquote>
<p>These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.</p>
</blockquote>
<div class="dropdown"><h3 id="getting_the_data"><a href="#getting_the_data" class="header-anchor">Getting the data</a></h3></div>
<div class="dropdown-content"><p>Let&#39;s download the data thanks to the <a href="https://github.com/Arkoniak/UrlDownload.jl">UrlDownload.jl</a> package and load it into a DataFrame:</p>
<pre><code class="language-julia">using HTTP
using MLJ
using StableRNGs # for RNGs, stable over Julia versions
import DataFrames: DataFrame, describe
using UrlDownload

url &#61; &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;
header &#61; &#91;&quot;Class&quot;, &quot;Alcool&quot;, &quot;Malic acid&quot;, &quot;Ash&quot;, &quot;Alcalinity of ash&quot;,
          &quot;Magnesium&quot;, &quot;Total phenols&quot;, &quot;Flavanoids&quot;,
          &quot;Nonflavanoid phenols&quot;, &quot;Proanthcyanins&quot;, &quot;Color intensity&quot;,
          &quot;Hue&quot;, &quot;OD280/OD315 of diluted wines&quot;, &quot;Proline&quot;&#93;
data &#61; urldownload&#40;url, true, format&#61;:CSV, header&#61;header&#41;;</code></pre>
<p>The second argument to <code>urldownload</code> adds a progress meter for the download, the <code>format</code> helps indicate the format of the file and the <code>header</code> helps pass the column names which are not in the file.</p>
<pre><code class="language-julia">df &#61; DataFrame&#40;data&#41;
describe&#40;df&#41;</code></pre><pre><code class="plaintext code-output">14×7 DataFrame
 Row │ variable                      mean        min     median   max      nmissing  eltype
     │ Symbol                        Float64     Real    Float64  Real     Int64     DataType
─────┼────────────────────────────────────────────────────────────────────────────────────────
   1 │ Class                           1.9382      1       2.0       3            0  Int64
   2 │ Alcool                         13.0006     11.03   13.05     14.83         0  Float64
   3 │ Malic acid                      2.33635     0.74    1.865     5.8          0  Float64
   4 │ Ash                             2.36652     1.36    2.36      3.23         0  Float64
   5 │ Alcalinity of ash              19.4949     10.6    19.5      30.0          0  Float64
   6 │ Magnesium                      99.7416     70      98.0     162            0  Int64
   7 │ Total phenols                   2.29511     0.98    2.355     3.88         0  Float64
   8 │ Flavanoids                      2.02927     0.34    2.135     5.08         0  Float64
   9 │ Nonflavanoid phenols            0.361854    0.13    0.34      0.66         0  Float64
  10 │ Proanthcyanins                  1.5909      0.41    1.555     3.58         0  Float64
  11 │ Color intensity                 5.05809     1.28    4.69     13.0          0  Float64
  12 │ Hue                             0.957449    0.48    0.965     1.71         0  Float64
  13 │ OD280/OD315 of diluted wines    2.61169     1.27    2.78      4.0          0  Float64
  14 │ Proline                       746.893     278     673.5    1680            0  Int64</code></pre>
<p>the target is the <code>Class</code> column, everything else is a feature; we can dissociate the two  using the <code>unpack</code> function:</p>
<pre><code class="language-julia">y, X &#61; unpack&#40;df, &#61;&#61;&#40;:Class&#41;&#41;; # a vector and a table</code></pre>
<p>‎</p></div>
<div class="dropdown"><h3 id="setting_the_scientific_type"><a href="#setting_the_scientific_type" class="header-anchor">Setting the scientific type</a></h3></div>
<div class="dropdown-content"><p>Let&#39;s explore the scientific type attributed by default to the target and the features</p>
<pre><code class="language-julia">scitype&#40;y&#41;</code></pre><pre><code class="plaintext code-output">AbstractVector{Count} (alias for AbstractArray{ScientificTypesBase.Count, 1})</code></pre>
<p>this should be changed as it should be considered as an ordered factor. The difference is as follows:</p>
<ul>
<li><p>a <code>Count</code> corresponds to an integer between 0 and infinity</p>
</li>
<li><p>a <code>OrderedFactor</code> however is a categorical object &#40;there are finitely many options&#41; with ordering &#40;<code>1 &lt; 2 &lt; 3</code>&#41;.</p>
</li>
</ul>
<pre><code class="language-julia">yc &#61; coerce&#40;y, OrderedFactor&#41;;</code></pre>
<p>Let&#39;s now consider the features. Since this is a table, will inspect scitypes using <code>schema</code>, which is more user-friendly:</p>
<pre><code class="language-julia">schema&#40;X&#41;</code></pre><pre><code class="plaintext code-output">┌──────────────────────────────┬────────────┬─────────┐
│ names                        │ scitypes   │ types   │
├──────────────────────────────┼────────────┼─────────┤
│ Alcool                       │ Continuous │ Float64 │
│ Malic acid                   │ Continuous │ Float64 │
│ Ash                          │ Continuous │ Float64 │
│ Alcalinity of ash            │ Continuous │ Float64 │
│ Magnesium                    │ Count      │ Int64   │
│ Total phenols                │ Continuous │ Float64 │
│ Flavanoids                   │ Continuous │ Float64 │
│ Nonflavanoid phenols         │ Continuous │ Float64 │
│ Proanthcyanins               │ Continuous │ Float64 │
│ Color intensity              │ Continuous │ Float64 │
│ Hue                          │ Continuous │ Float64 │
│ OD280/OD315 of diluted wines │ Continuous │ Float64 │
│ Proline                      │ Count      │ Int64   │
└──────────────────────────────┴────────────┴─────────┘
</code></pre>
<p>So there are <code>Continuous</code> values &#40;encoded as floating point&#41; and <code>Count</code> values &#40;integer&#41;.  Note also that there are no missing value &#40;otherwise one of the scientific type would have been a <code>Union&#123;Missing,*&#125;</code>&#41;.  Let&#39;s check which column is what: The two variables that are encoded as <code>Count</code> can probably be re-interpreted; let&#39;s have a look at the <code>Proline</code> one to see what it looks like</p>
<pre><code class="language-julia">X&#91;1:5, :Proline&#93;</code></pre><pre><code class="plaintext code-output">5-element Vector{Int64}:
 1065
 1050
 1185
 1480
  735</code></pre>
<p>This is likely representing a <code>Continuous</code> variable as well &#40;it would be better to know precisely what it is but for now let&#39;s just go with the hunch&#41;. We&#39;ll do the same with <code>:Magnesium</code>:</p>
<pre><code class="language-julia">Xc &#61; coerce&#40;X, :Proline&#61;&gt;Continuous, :Magnesium&#61;&gt;Continuous&#41;;</code></pre>
<p>Finally, let&#39;s have a quick look at the mean and standard deviation of each feature to get a feel for their amplitude:</p>
<pre><code class="language-julia">describe&#40;Xc, :mean, :std&#41;</code></pre><pre><code class="plaintext code-output">13×3 DataFrame
 Row │ variable                      mean        std
     │ Symbol                        Float64     Float64
─────┼──────────────────────────────────────────────────────
   1 │ Alcool                         13.0006      0.811827
   2 │ Malic acid                      2.33635     1.11715
   3 │ Ash                             2.36652     0.274344
   4 │ Alcalinity of ash              19.4949      3.33956
   5 │ Magnesium                      99.7416     14.2825
   6 │ Total phenols                   2.29511     0.625851
   7 │ Flavanoids                      2.02927     0.998859
   8 │ Nonflavanoid phenols            0.361854    0.124453
   9 │ Proanthcyanins                  1.5909      0.572359
  10 │ Color intensity                 5.05809     2.31829
  11 │ Hue                             0.957449    0.228572
  12 │ OD280/OD315 of diluted wines    2.61169     0.70999
  13 │ Proline                       746.893     314.907</code></pre>
<p>Right so it varies a fair bit which would invite to standardise the data.</p>
<p><strong>Note</strong>: to complete such a first step, one could explore histograms of the various **features for instance, check that there is enough variation among the continuous **features and that there does not seem to be problems in the encoding, we cut this out **to shorten the tutorial. We could also have checked that the data is balanced.</p>
<p>‎</p></div>
<p>‎</p></div>
<div class="dropdown"><h2 id="getting_a_baseline"><a href="#getting_a_baseline" class="header-anchor">Getting a baseline</a></h2></div>
<div class="dropdown-content"><p>It&#39;s a multiclass classification problem with continuous inputs so a sensible start is to test two very simple classifiers to get a baseline.</p>
<p>We&#39;ll train two simple pipelines:</p>
<ul>
<li><p>a Standardizer &#43; KNN classifier and</p>
</li>
<li><p>a Standardizer &#43; Multinomial classifier &#40;logistic regression&#41;.</p>
</li>
</ul>
<pre><code class="language-julia">KNNClassifier &#61; @load KNNClassifier
MultinomialClassifier &#61; @load MultinomialClassifier pkg&#61;MLJLinearModels;

knn_pipe &#61; Standardizer&#40;&#41; |&gt; KNNClassifier&#40;&#41;
multinom_pipe &#61; Standardizer&#40;&#41; |&gt; MultinomialClassifier&#40;&#41;</code></pre><pre><code class="plaintext code-output">import NearestNeighborModels ✔
import MLJLinearModels ✔
ProbabilisticPipeline(
  standardizer = Standardizer(
        features = Symbol[], 
        ignore = false, 
        ordered_factor = false, 
        count = false), 
  multinomial_classifier = MultinomialClassifier(
        lambda = 2.220446049250313e-16, 
        gamma = 0.0, 
        penalty = :l2, 
        fit_intercept = true, 
        penalize_intercept = false, 
        scale_penalty_with_samples = true, 
        solver = nothing), 
  cache = true)</code></pre>
<p>Note the <code>|&gt;</code> syntax, which is syntactic sugar for creating a linear <code>Pipeline</code>.</p>
<p>We can now fit this on a train split of the data setting aside 20&#37; of the data for eventual testing.</p>
<pre><code class="language-julia">&#40;Xtrain, Xtest&#41;, &#40;ytrain, ytest&#41; &#61;
    partition&#40;&#40;Xc, yc&#41;, 0.8, rng&#61;StableRNG&#40;123&#41;, multi&#61;true&#41;;</code></pre>
<p>Let&#39;s now wrap an instance of these models with data &#40;all hyperparameters are set to default here&#41;:</p>
<pre><code class="language-julia">knn &#61; machine&#40;knn_pipe, Xtrain, ytrain&#41;
multinom &#61; machine&#40;multinom_pipe, Xtrain, ytrain&#41;</code></pre><pre><code class="plaintext code-output">untrained Machine; does not cache data
  model: ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …)
  args: 
    1:	Source @623 ⏎ ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}
    2:	Source @934 ⏎ AbstractVector{ScientificTypesBase.OrderedFactor{3}}
</code></pre>
<p>Let&#39;s train a KNNClassifier with default hyperparameters and get a baseline misclassification rate using 90&#37; of the training data to train the model and the remaining 10&#37; to evaluate it:</p>
<pre><code class="language-julia">opts &#61; &#40;
    resampling&#61;Holdout&#40;fraction_train&#61;0.9&#41;,
    measures&#61;&#91;log_loss, accuracy&#93;,
&#41;
evaluate&#33;&#40;knn; opts...&#41;</code></pre><pre><code class="plaintext code-output">PerformanceEvaluation object with these fields:
  model, measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows, resampling, repeats
Extract:
┌──────────────────────┬──────────────┬─────────────┬──────────┐
│ measure              │ operation    │ measurement │ per_fold │
├──────────────────────┼──────────────┼─────────────┼──────────┤
│ LogLoss(             │ predict      │ 0.0319      │ [0.0319] │
│   tol = 2.22045e-16) │              │             │          │
│ Accuracy()           │ predict_mode │ 1.0         │ [1.0]    │
└──────────────────────┴──────────────┴─────────────┴──────────┘
</code></pre>
<p>Now we do the same with a MultinomialClassifier</p>
<pre><code class="language-julia">evaluate&#33;&#40;multinom; opts...&#41;</code></pre><pre><code class="plaintext code-output">PerformanceEvaluation object with these fields:
  model, measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows, resampling, repeats
Extract:
┌──────────────────────┬──────────────┬─────────────┬──────────┐
│ measure              │ operation    │ measurement │ per_fold │
├──────────────────────┼──────────────┼─────────────┼──────────┤
│ LogLoss(             │ predict      │ 3.3e-6      │ [3.3e-6] │
│   tol = 2.22045e-16) │              │             │          │
│ Accuracy()           │ predict_mode │ 1.0         │ [1.0]    │
└──────────────────────┴──────────────┴─────────────┴──────────┘
</code></pre>
<p>Both methods have perfect out-of-sample accuracy, without any tuning&#33;</p>
<p>Let&#39;s check the accuracy on the test set:</p>
<pre><code class="language-julia">fit&#33;&#40;knn&#41; # train on all train data
yhat &#61; predict_mode&#40;knn, Xtest&#41;
accuracy&#40;yhat, ytest&#41;</code></pre><pre><code class="plaintext code-output">0.8888888888888888</code></pre>
<p>Still pretty good.</p>
<pre><code class="language-julia">fit&#33;&#40;multinom&#41; # train on all train data
yhat &#61; predict_mode&#40;multinom, Xtest&#41;
accuracy&#40;yhat, ytest&#41;</code></pre><pre><code class="plaintext code-output">0.9444444444444444</code></pre>
<p>Even better.</p>
<p>‎</p></div>
<div class="dropdown"><h2 id="visualising_the_classes"><a href="#visualising_the_classes" class="header-anchor">Visualising the classes</a></h2></div>
<div class="dropdown-content"><p>One way to get intuition for why the dataset is so easy to classify is to project it onto a 2D space using the PCA and display the two classes to see if they are well separated; we use the arrow-syntax here &#40;if you&#39;re on Julia &lt;&#61; 1.2, use the commented-out lines as you won&#39;t be able to use the arrow-syntax&#41;</p>
<pre><code class="language-julia">PCA &#61; @load PCA
pca_pipe &#61; Standardizer&#40;&#41; |&gt; PCA&#40;maxoutdim&#61;2&#41;
pca &#61; machine&#40;pca_pipe, Xtrain&#41;
fit&#33;&#40;pca&#41;
W &#61; transform&#40;pca, Xtrain&#41;;</code></pre><pre><code class="plaintext code-output">import MLJMultivariateStatsInterface ✔
</code></pre>
<p>Let&#39;s now display this using different colours for the different classes:</p>
<pre><code class="language-julia">x1 &#61; W.x1
x2 &#61; W.x2

mask_1 &#61; ytrain .&#61;&#61; 1
mask_2 &#61; ytrain .&#61;&#61; 2
mask_3 &#61; ytrain .&#61;&#61; 3

using Plots

scatter&#40;x1&#91;mask_1&#93;, x2&#91;mask_1&#93;, color&#61;&quot;red&quot;, label&#61;&quot;Class 1&quot;&#41;
scatter&#33;&#40;x1&#91;mask_2&#93;, x2&#91;mask_2&#93;, color&#61;&quot;blue&quot;, label&#61;&quot;Class 2&quot;&#41;
scatter&#33;&#40;x1&#91;mask_3&#93;, x2&#91;mask_3&#93;, color&#61;&quot;yellow&quot;, label&#61;&quot;Class 3&quot;&#41;

xlabel&#33;&#40;&quot;PCA dimension 1&quot;&#41;
ylabel&#33;&#40;&quot;PCA dimension 2&quot;&#41;</code></pre>
<img src="/DataScienceTutorials.jl/assets/end-to-end/wine/code/output/EX-wine-pca.svg" alt="PCA">
<p>From the figure it&#39;s clear why we managed to achieve such high scores with very simple classifiers.  At this point it&#39;s a bit pointless to dig much deaper into parameter tuning etc.</p>
<p>‎</p></div>

<div class="bottom-nav-container">
  <a id="prev-tutorial" style="text-decoration: none"><Button class="bottom-nav">
        <div>← Previous Tutorial</div>
        <div id="prev-label" class="button-label"> Home</div>
    </Button></a>
  <a id="next-tutorial" style="text-decoration: none"><Button class="bottom-nav">
        <div>Next Tutorial →</div>
        <div id="next-label" class="button-label">Home</div> 
    </Button></a>
</div>
<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom, Sebastian Vollmer and collaborators. Last modified: April 15, 2024. Website built with <a
      href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div></div><!-- CONTENT ENDS HERE -->
</div> <!-- end of id=main -->
</div> <!-- end of id=layout -->
<!-- for collapse functionality -->
<script src="/DataScienceTutorials.jl/libs/collapse/collapse.js"></script>
<script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>
<!-- head and footer-nav -->
<script src="/DataScienceTutorials.jl/libs/nav/head.js"  type="module"></script>
<!-- landing page -->
<script src="/DataScienceTutorials.jl/libs/landing/landing.js"></script>
<!-- navigation bar -->
<script src="/DataScienceTutorials.jl/libs/nav/nav.js"></script>
<!-- responsive navigation bar -->
<script src="/DataScienceTutorials.jl/libs/nav/responsive.js"></script>


<script src="/DataScienceTutorials.jl/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>


</body>

</html>