<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/DataScienceTutorials.jl/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/franklin.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/pure.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/side-menu.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/extra.css">
  <!-- <link rel="icon" href="/DataScienceTutorials.jl/assets/infra/favicon.gif"> -->
   <title>Using GLM.jl</title>  
  <!-- LUNR -->
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/DataScienceTutorials.jl/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class="pure-menu-link"><strong>Home</strong></a></li>

    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/processing/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data processing</a></li>
    </ul>

    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Stacking</a></li>
    </ul>

    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>

    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> King County Houses</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Airfoil </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
      <!-- <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li> -->
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/powergen/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Power Generation </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-flux" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/breastcancer" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Breast Cancer</a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->
<div class="franklin-content"><h1 id="using_glmjl"><a href="#using_glmjl" class="header-anchor">Using GLM.jl</a></h1>
<em>Download the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-GLM/tutorial.ipynb" target="_blank"><em>notebook</em></a>
  , the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-GLM/tutorial.jl" target="_blank"><em>annotated script</em></a>
   or the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-GLM/tutorial-raw.jl" target="_blank"><em>raw script</em></a>
   for this tutorial &#40;right-click on the relevant link and save-as&#41;. These rely on <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-GLM/Project.toml">this Project.toml</a> and <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-GLM/Manifest.toml">this Manifest.toml</a>.</em> <br/>   <em>You can also download the whole <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/EX-GLM.tar.gz">project folder</a>.</em></p>
<p><em>If you have questions or suggestions about this tutorial, please open an issue <a href="https://github.com/JuliaAI/DataScienceTutorials.jl/issues/new">here</a>.</em></p>
<p><div class="franklin-toc"><ol><li><a href="#reading_the_data">Reading the data</a></li><li><a href="#defining_the_linear_model">Defining the Linear Model</a></li><li><a href="#reading_the_output_of_fitting_the_linear_model">Reading the Output of Fitting the Linear Model</a></li><li><a href="#defining_the_logistic_model">Defining the Logistic Model</a></li><li><a href="#reading_the_output_from_the_prediction_of_the_logistic_model">Reading the Output from the Prediction of the Logistic Model</a></li></ol></div>
<p><strong>Main author</strong>: <a href="https://github.com/drcxcruz">Clarman Cruz</a>.</p>
<p>This juypter lab showcases MLJ in particular using the popular <a href="https://github.com/JuliaStats/GLM.jl">GLM</a> Julia package. We are using two datasets.  One dataset was created manually for testing purposes.  The other data set is the CollegeDistance dataset from the <a href="https://cran.r-project.org/web/packages/AER/index.html">AER</a> package in R.</p>
<p>We can quickly define our models in MLJ and study their results.  It is very easy and consistent.</p>
<pre><code class="language-julia">using MLJ, CategoricalArrays, PrettyPrinting
import DataFrames: DataFrame, nrow
using UrlDownload

LinearRegressor &#61; @load LinearRegressor pkg&#61;GLM
LinearBinaryClassifier &#61; @load LinearBinaryClassifier pkg&#61;GLM</code></pre><pre><code class="plaintext code-output">import MLJGLMInterface ✔
import MLJGLMInterface ✔
MLJGLMInterface.LinearBinaryClassifier</code></pre>
<h2 id="reading_the_data"><a href="#reading_the_data" class="header-anchor">Reading the data</a></h2>
<p>The CollegeDistance dataset was stored in a CSV file.  Here, we read the input file.</p>
<pre><code class="language-julia">baseurl &#61; &quot;https://raw.githubusercontent.com/tlienart/DataScienceTutorialsData.jl/master/data/glm/&quot;

dfX &#61; DataFrame&#40;urldownload&#40;baseurl * &quot;X3.csv&quot;&#41;&#41;
dfYbinary &#61; DataFrame&#40;urldownload&#40;baseurl * &quot;Y3.csv&quot;&#41;&#41;
dfX1 &#61; DataFrame&#40;urldownload&#40;baseurl * &quot;X1.csv&quot;&#41;&#41;
dfY1 &#61; DataFrame&#40;urldownload&#40;baseurl * &quot;Y1.csv&quot;&#41;&#41;;</code></pre>
<p>You can have a look at those using <code>first</code>:</p>
<pre><code class="language-julia">first&#40;dfX, 3&#41;</code></pre><pre><code class="plaintext code-output">3×12 DataFrame
 Row │ gender   ethnicity  score    fcollege  mcollege  home     urban    unemp    wage     tuition  income   region
     │ String7  String15   Float64  String3   String3   String3  String3  Float64  Float64  Float64  String7  String7
─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────
   1 │ male     other        39.15  yes       no        yes      yes          6.2     8.09  0.88915  high     other
   2 │ female   other        48.87  no        no        yes      yes          6.2     8.09  0.88915  low      other
   3 │ male     other        48.74  no        no        yes      yes          6.2     8.09  0.88915  low      other</code></pre>
<p>same for Y:</p>
<pre><code class="language-julia">first&#40;dfY1, 3&#41;</code></pre><pre><code class="plaintext code-output">3×1 DataFrame
 Row │ Y
     │ Float64
─────┼───────────
   1 │ -2.04463
   2 │ -0.461529
   3 │  0.458262</code></pre>
<h2 id="defining_the_linear_model"><a href="#defining_the_linear_model" class="header-anchor">Defining the Linear Model</a></h2>
<p>Let see how many MLJ models handle our kind of target which is the y variable.</p>
<pre><code class="language-julia">ms &#61; models&#40;&#41; do m
    AbstractVector&#123;Count&#125; &lt;: m.target_scitype
end
foreach&#40;m -&gt; println&#40;m.name&#41;, ms&#41;</code></pre><pre><code class="plaintext code-output">EvoTreeCount
LinearCountRegressor
XGBoostCount
</code></pre>
<p>How about if the type was Continuous:</p>
<pre><code class="language-julia">ms &#61; models&#40;&#41; do m
    Vector&#123;Continuous&#125; &lt;: m.target_scitype
end
foreach&#40;m -&gt; println&#40;m.name&#41;, ms&#41;</code></pre><pre><code class="plaintext code-output">ARDRegressor
AdaBoostRegressor
BaggingRegressor
BayesianRidgeRegressor
ConstantRegressor
DecisionTreeRegressor
DecisionTreeRegressor
DeterministicConstantRegressor
DummyRegressor
ElasticNetCVRegressor
ElasticNetRegressor
ElasticNetRegressor
EpsilonSVR
EvoTreeGaussian
EvoTreeRegressor
ExtraTreesRegressor
GaussianProcessRegressor
GradientBoostingRegressor
HuberRegressor
HuberRegressor
KNNRegressor
KNeighborsRegressor
KPLSRegressor
LADRegressor
LGBMRegressor
LarsCVRegressor
LarsRegressor
LassoCVRegressor
LassoLarsCVRegressor
LassoLarsICRegressor
LassoLarsRegressor
LassoRegressor
LassoRegressor
LinearRegressor
LinearRegressor
LinearRegressor
LinearRegressor
NeuralNetworkRegressor
NuSVR
OrthogonalMatchingPursuitCVRegressor
OrthogonalMatchingPursuitRegressor
PLSRegressor
PassiveAggressiveRegressor
QuantileRegressor
RANSACRegressor
RandomForestRegressor
RandomForestRegressor
RandomForestRegressor
RidgeCVRegressor
RidgeRegressor
RidgeRegressor
RidgeRegressor
RobustRegressor
SGDRegressor
SVMLinearRegressor
SVMNuRegressor
SVMRegressor
TheilSenRegressor
XGBoostRegressor
</code></pre>
<p>We can quickly define our models in MLJ.  It is very easy and consistent.</p>
<pre><code class="language-julia">X &#61; copy&#40;dfX1&#41;
y &#61; copy&#40;dfY1&#41;

coerce&#33;&#40;X, autotype&#40;X, :string_to_multiclass&#41;&#41;
yv &#61; Vector&#40;y&#91;:, 1&#93;&#41;

LinearRegressorPipe &#61; @pipeline&#40;Standardizer&#40;&#41;,
                                OneHotEncoder&#40;drop_last &#61; true&#41;,
                                LinearRegressor&#40;&#41;&#41;

LinearModel &#61; machine&#40;LinearRegressorPipe, X, yv&#41;
fit&#33;&#40;LinearModel&#41;
fp &#61; fitted_params&#40;LinearModel&#41;</code></pre><pre><code class="plaintext code-output">TaskFailedException

    nested task error: MethodError: no method matching keys(::DataFrame)
    Closest candidates are:
      keys(!Matched::Union{Tables.AbstractColumns, Tables.AbstractRow}) at ~/.julia/packages/Tables/M26tI/src/Tables.jl:184
      keys(!Matched::DataStructures.MultiDict, !Matched::Any...) at ~/.julia/packages/DataStructures/vSp4s/src/delegate.jl:21
      keys(!Matched::Test.GenericArray) at /Applications/Julia-1.7.app/Contents/Resources/julia/share/julia/stdlib/v1.7/Test/src/Test.jl:1823
      ...
    Stacktrace:
     [1] fit_only!(mach::Machine{MLJGLMInterface.LinearRegressor, true}, wait_on_downstream::Bool; kwargs::Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}})
       @ MLJBase ~/.julia/packages/MLJBase/MuLnJ/src/machines.jl:685
     [2] (::MLJBase.var"#80#82"{Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}}, Machine{MLJGLMInterface.LinearRegressor, true}})()
       @ MLJBase ./task.jl:423
    
    caused by: MethodError: no method matching keys(::DataFrame)
    Closest candidates are:
      keys(!Matched::Union{Tables.AbstractColumns, Tables.AbstractRow}) at ~/.julia/packages/Tables/M26tI/src/Tables.jl:184
      keys(!Matched::DataStructures.MultiDict, !Matched::Any...) at ~/.julia/packages/DataStructures/vSp4s/src/delegate.jl:21
      keys(!Matched::Test.GenericArray) at /Applications/Julia-1.7.app/Contents/Resources/julia/share/julia/stdlib/v1.7/Test/src/Test.jl:1823
      ...
    Stacktrace:
     [1] glm_data(model::MLJGLMInterface.LinearRegressor, Xmatrix::Matrix{Float64}, X::DataFrame, y::Vector{Float64})
       @ MLJGLMInterface ~/.julia/packages/MLJGLMInterface/jM45W/src/MLJGLMInterface.jl:158
     [2] fit(model::MLJGLMInterface.LinearRegressor, verbosity::Int64, X::DataFrame, y::Vector{Float64})
       @ MLJGLMInterface ~/.julia/packages/MLJGLMInterface/jM45W/src/MLJGLMInterface.jl:170
     [3] fit_only!(mach::Machine{MLJGLMInterface.LinearRegressor, true}; rows::Nothing, verbosity::Int64, force::Bool)
       @ MLJBase ~/.julia/packages/MLJBase/MuLnJ/src/machines.jl:592
     [4] fit_only!(mach::Machine{MLJGLMInterface.LinearRegressor, true}, wait_on_downstream::Bool; kwargs::Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}})
       @ MLJBase ~/.julia/packages/MLJBase/MuLnJ/src/machines.jl:681
     [5] (::MLJBase.var"#80#82"{Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}}, Machine{MLJGLMInterface.LinearRegressor, true}})()
       @ MLJBase ./task.jl:423
</code></pre>
<h2 id="reading_the_output_of_fitting_the_linear_model"><a href="#reading_the_output_of_fitting_the_linear_model" class="header-anchor">Reading the Output of Fitting the Linear Model</a></h2>
<p>We can quickly read the results of our models in MLJ.  Remember to compute the accuracy of the linear model.</p>
<pre><code class="language-julia">ŷ &#61; MLJ.predict&#40;LinearModel, Xm&#41;
yhatResponse &#61; &#91;ŷ&#91;i,1&#93;.μ for i in 1:nrow&#40;y&#41;&#93;
residuals &#61; y .- yhatResponse
r &#61; report&#40;LinearModel&#41;

k &#61; collect&#40;keys&#40;fp.fitted_params_given_machine&#41;&#41;&#91;3&#93;
println&#40;&quot;\n Coefficients:  &quot;, fp.fitted_params_given_machine&#91;k&#93;.coef&#41;
println&#40;&quot;\n y \n &quot;, y&#91;1:5,1&#93;&#41;
println&#40;&quot;\n ŷ \n &quot;, ŷ&#91;1:5&#93;&#41;
println&#40;&quot;\n yhatResponse \n &quot;, yhatResponse&#91;1:5&#93;&#41;
println&#40;&quot;\n Residuals \n &quot;, y&#91;1:5,1&#93; .- yhatResponse&#91;1:5&#93;&#41;
println&#40;&quot;\n Standard Error per Coefficient \n&quot;, r.linear_regressor.stderror&#91;2:end&#93;&#41;</code></pre><pre><code class="plaintext code-output">UndefVarError: Xm not defined
</code></pre>
<p>and get the accuracy</p>
<pre><code class="language-julia">round&#40;rms&#40;yhatResponse, y&#91;:,1&#93;&#41;, sigdigits&#61;4&#41;</code></pre><pre><code class="plaintext code-output">UndefVarError: yhatResponse not defined
</code></pre>
<h2 id="defining_the_logistic_model"><a href="#defining_the_logistic_model" class="header-anchor">Defining the Logistic Model</a></h2>
<pre><code class="language-julia">X &#61; copy&#40;dfX&#41;
y &#61; copy&#40;dfYbinary&#41;

coerce&#33;&#40;X, autotype&#40;X, :string_to_multiclass&#41;&#41;
yc &#61; CategoricalArray&#40;y&#91;:, 1&#93;&#41;
yc &#61; coerce&#40;yc, OrderedFactor&#41;

LinearBinaryClassifierPipe &#61; @pipeline&#40;Standardizer&#40;&#41;,
                                       OneHotEncoder&#40;drop_last &#61; true&#41;,
                                       LinearBinaryClassifier&#40;&#41;&#41;

LogisticModel &#61; machine&#40;LinearBinaryClassifierPipe, X, yc&#41;
fit&#33;&#40;LogisticModel&#41;
fp &#61; fitted_params&#40;LogisticModel&#41;</code></pre><pre><code class="plaintext code-output">TaskFailedException

    nested task error: MethodError: no method matching keys(::DataFrame)
    Closest candidates are:
      keys(!Matched::Union{Tables.AbstractColumns, Tables.AbstractRow}) at ~/.julia/packages/Tables/M26tI/src/Tables.jl:184
      keys(!Matched::DataStructures.MultiDict, !Matched::Any...) at ~/.julia/packages/DataStructures/vSp4s/src/delegate.jl:21
      keys(!Matched::Test.GenericArray) at /Applications/Julia-1.7.app/Contents/Resources/julia/share/julia/stdlib/v1.7/Test/src/Test.jl:1823
      ...
    Stacktrace:
     [1] fit_only!(mach::Machine{MLJGLMInterface.LinearBinaryClassifier{GLM.LogitLink}, true}, wait_on_downstream::Bool; kwargs::Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}})
       @ MLJBase ~/.julia/packages/MLJBase/MuLnJ/src/machines.jl:685
     [2] (::MLJBase.var"#80#82"{Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}}, Machine{MLJGLMInterface.LinearBinaryClassifier{GLM.LogitLink}, true}})()
       @ MLJBase ./task.jl:423
    
    caused by: MethodError: no method matching keys(::DataFrame)
    Closest candidates are:
      keys(!Matched::Union{Tables.AbstractColumns, Tables.AbstractRow}) at ~/.julia/packages/Tables/M26tI/src/Tables.jl:184
      keys(!Matched::DataStructures.MultiDict, !Matched::Any...) at ~/.julia/packages/DataStructures/vSp4s/src/delegate.jl:21
      keys(!Matched::Test.GenericArray) at /Applications/Julia-1.7.app/Contents/Resources/julia/share/julia/stdlib/v1.7/Test/src/Test.jl:1823
      ...
    Stacktrace:
     [1] glm_data(model::MLJGLMInterface.LinearBinaryClassifier{GLM.LogitLink}, Xmatrix::Matrix{Float64}, X::DataFrame, y::Vector{Int64})
       @ MLJGLMInterface ~/.julia/packages/MLJGLMInterface/jM45W/src/MLJGLMInterface.jl:158
     [2] fit(model::MLJGLMInterface.LinearBinaryClassifier{GLM.LogitLink}, verbosity::Int64, X::DataFrame, y::CategoricalVector{Int64, UInt32, Int64, CategoricalValue{Int64, UInt32}, Union{}})
       @ MLJGLMInterface ~/.julia/packages/MLJGLMInterface/jM45W/src/MLJGLMInterface.jl:198
     [3] fit_only!(mach::Machine{MLJGLMInterface.LinearBinaryClassifier{GLM.LogitLink}, true}; rows::Nothing, verbosity::Int64, force::Bool)
       @ MLJBase ~/.julia/packages/MLJBase/MuLnJ/src/machines.jl:592
     [4] fit_only!(mach::Machine{MLJGLMInterface.LinearBinaryClassifier{GLM.LogitLink}, true}, wait_on_downstream::Bool; kwargs::Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}})
       @ MLJBase ~/.julia/packages/MLJBase/MuLnJ/src/machines.jl:681
     [5] (::MLJBase.var"#80#82"{Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:verbosity,), Tuple{Int64}}}, Machine{MLJGLMInterface.LinearBinaryClassifier{GLM.LogitLink}, true}})()
       @ MLJBase ./task.jl:423
</code></pre>
<h2 id="reading_the_output_from_the_prediction_of_the_logistic_model"><a href="#reading_the_output_from_the_prediction_of_the_logistic_model" class="header-anchor">Reading the Output from the Prediction of the Logistic Model</a></h2>
<p>The output of the MLJ model basically contain the same information as the R version of the model.</p>
<pre><code class="language-julia">ŷ &#61; MLJ.predict&#40;LogisticModel, X&#41;
residuals &#61; &#91;1 - pdf&#40;ŷ&#91;i&#93;, y&#91;i,1&#93;&#41; for i in 1:nrow&#40;y&#41;&#93;
r &#61; report&#40;LogisticModel&#41;

k &#61; collect&#40;keys&#40;fp.fitted_params_given_machine&#41;&#41;&#91;3&#93;
println&#40;&quot;\n Coefficients:  &quot;, fp.fitted_params_given_machine&#91;k&#93;.coef&#41;
println&#40;&quot;\n y \n &quot;, y&#91;1:5,1&#93;&#41;
println&#40;&quot;\n ŷ \n &quot;, ŷ&#91;1:5&#93;&#41;
println&#40;&quot;\n residuals \n &quot;, residuals&#91;1:5&#93;&#41;
println&#40;&quot;\n Standard Error per Coefficient \n&quot;, r.linear_binary_classifier.stderror&#91;2:end&#93;&#41;</code></pre><pre><code class="plaintext code-output">Machine{Pipeline536,…} has not been trained.
</code></pre>
<p>No logistic analysis is complete without the confusion matrix:</p>
<pre><code class="language-julia">yMode &#61; &#91;mode&#40;ŷ&#91;i&#93;&#41; for i in 1:length&#40;ŷ&#41;&#93;
y &#61; coerce&#40;y&#91;:,1&#93;, OrderedFactor&#41;
yMode &#61; coerce&#40;yMode, OrderedFactor&#41;
confusion_matrix&#40;yMode, y&#41;</code></pre><pre><code class="plaintext code-output">UndefVarError: ŷ not defined
</code></pre>

<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom, Sebastian Vollmer and collaborators. Last modified: January 13, 2022. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>
  
  
      <script src="/DataScienceTutorials.jl/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
