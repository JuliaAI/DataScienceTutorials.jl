<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/DataScienceTutorials.jl/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/franklin.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/pure.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/side-menu.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/extra.css">
  <!-- <link rel="icon" href="/DataScienceTutorials.jl/assets/infra/favicon.gif"> -->
   <title>Using GLM.jl</title>  
  <!-- LUNR -->
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/DataScienceTutorials.jl/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class="pure-menu-link"><strong>Home</strong></a></li>

    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
    </ul>

    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Stacking</a></li>
    </ul>

    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>

    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> King County Houses</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Airfoil </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/powergen/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Power Generation </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-flux" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->
<div class="franklin-content"><h1 id="using_glmjl"><a href="#using_glmjl">Using GLM.jl</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/notebooks/EX-GLM.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-GLM-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-GLM.jl" target="_blank"><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="franklin-toc"><ol><li><a href="#reading_the_data">Reading the data</a></li><li><a href="#defining_the_linear_model">Defining the Linear Model</a></li><li><a href="#reading_the_output_of_fitting_the_linear_model">Reading the Output of Fitting the Linear Model</a></li><li><a href="#defining_the_logistic_model">Defining the Logistic Model</a></li><li><a href="#reading_the_output_from_the_prediction_of_the_logistic_model">Reading the Output from the Prediction of the Logistic Model</a></li></ol></div><strong>Main author</strong>: <a href="https://github.com/drcxcruz">Clarman Cruz</a>.</p>
<p>This juypter lab showcases MLJ in particular using the popular <a href="https://github.com/JuliaStats/GLM.jl">GLM</a> Julia package. We are using two datasets.  One dataset was created manually for testing purposes.  The other data set is the CollegeDistance dataset from the <a href="https://cran.r-project.org/web/packages/AER/index.html">AER</a> package in R.</p>
<p>We can quickly define our models in MLJ and study their results.  It is very easy and consistent.</p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> MLJ, CategoricalArrays, PrettyPrinting
<span class="hljs-keyword">import</span> DataFrames: DataFrame, nrow
<span class="hljs-keyword">using</span> UrlDownload
<span class="hljs-meta">@load</span> LinearRegressor pkg = GLM
<span class="hljs-meta">@load</span> LinearBinaryClassifier pkg=GLM</code></pre><pre><code class="plaintext hljs">LinearBinaryClassifier(
    fit_intercept = true,
    link = GLM.LogitLink()) @718</code></pre>
<h2 id="reading_the_data"><a href="#reading_the_data">Reading the data</a></h2>
<p>The CollegeDistance dataset was stored in a CSV file.  Here, we read the input file.</p>
<pre><code class="julia hljs">baseurl = <span class="hljs-string">&quot;https://raw.githubusercontent.com/tlienart/DataScienceTutorialsData.jl/master/data/glm/&quot;</span>

dfX = DataFrame(urldownload(baseurl * <span class="hljs-string">&quot;X3.csv&quot;</span>))
dfYbinary = DataFrame(urldownload(baseurl * <span class="hljs-string">&quot;Y3.csv&quot;</span>))
dfX1 = DataFrame(urldownload(baseurl * <span class="hljs-string">&quot;X1.csv&quot;</span>))
dfY1 = DataFrame(urldownload(baseurl * <span class="hljs-string">&quot;Y1.csv&quot;</span>));</code></pre>
<p>You can have a look at those using <code>first</code>:</p>
<pre><code class="julia hljs">first(dfX, <span class="hljs-number">3</span>)</code></pre><pre><code class="plaintext hljs">3×12 DataFrame
│ Row │ gender │ ethnicity │ score   │ fcollege │ mcollege │ home   │ urban  │ unemp   │ wage    │ tuition │ income │ region │
│     │ String │ String    │ Float64 │ String   │ String   │ String │ String │ Float64 │ Float64 │ Float64 │ String │ String │
├─────┼────────┼───────────┼─────────┼──────────┼──────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼────────┤
│ 1   │ male   │ other     │ 39.15   │ yes      │ no       │ yes    │ yes    │ 6.2     │ 8.09    │ 0.88915 │ high   │ other  │
│ 2   │ female │ other     │ 48.87   │ no       │ no       │ yes    │ yes    │ 6.2     │ 8.09    │ 0.88915 │ low    │ other  │
│ 3   │ male   │ other     │ 48.74   │ no       │ no       │ yes    │ yes    │ 6.2     │ 8.09    │ 0.88915 │ low    │ other  │</code></pre>
<p>same for Y:</p>
<pre><code class="julia hljs">first(dfY1, <span class="hljs-number">3</span>)</code></pre><pre><code class="plaintext hljs">3×1 DataFrame
│ Row │ Y         │
│     │ Float64   │
├─────┼───────────┤
│ 1   │ -2.04463  │
│ 2   │ -0.461529 │
│ 3   │ 0.458262  │</code></pre>
<h2 id="defining_the_linear_model"><a href="#defining_the_linear_model">Defining the Linear Model</a></h2>
<p>Let see how many MLJ models handle our kind of target which is the y variable.</p>
<pre><code class="julia hljs">ms = models() <span class="hljs-keyword">do</span> m
    <span class="hljs-built_in">AbstractVector</span>{Count} &lt;: m.target_scitype
<span class="hljs-keyword">end</span>
foreach(m -&gt; println(m.name), ms)</code></pre><pre><code class="plaintext hljs">EvoTreeCount
LinearCountRegressor
XGBoostCount
</code></pre>
<p>How about if the type was Continuous:</p>
<pre><code class="julia hljs">ms = models() <span class="hljs-keyword">do</span> m
    <span class="hljs-built_in">Vector</span>{Continuous} &lt;: m.target_scitype
<span class="hljs-keyword">end</span>
foreach(m -&gt; println(m.name), ms)</code></pre><pre><code class="plaintext hljs">ARDRegressor
AdaBoostRegressor
BaggingRegressor
BayesianRidgeRegressor
ConstantRegressor
DecisionTreeRegressor
DeterministicConstantRegressor
DummyRegressor
ElasticNetCVRegressor
ElasticNetRegressor
ElasticNetRegressor
EpsilonSVR
EvoTreeGaussian
EvoTreeRegressor
ExtraTreesRegressor
GaussianProcessRegressor
GradientBoostingRegressor
HuberRegressor
HuberRegressor
KNNRegressor
KNeighborsRegressor
LADRegressor
LGBMRegressor
LarsCVRegressor
LarsRegressor
LassoCVRegressor
LassoLarsCVRegressor
LassoLarsICRegressor
LassoLarsRegressor
LassoRegressor
LassoRegressor
LinearRegressor
LinearRegressor
LinearRegressor
NeuralNetworkRegressor
NuSVR
OrthogonalMatchingPursuitCVRegressor
OrthogonalMatchingPursuitRegressor
PassiveAggressiveRegressor
QuantileRegressor
RANSACRegressor
RandomForestRegressor
RandomForestRegressor
RidgeCVRegressor
RidgeRegressor
RidgeRegressor
RidgeRegressor
RobustRegressor
SGDRegressor
SVMLinearRegressor
SVMNuRegressor
SVMRegressor
TheilSenRegressor
XGBoostRegressor
</code></pre>
<p>We can quickly define our models in MLJ.  It is very easy and consistent.</p>
<pre><code class="julia hljs">X = copy(dfX1)
y = copy(dfY1)

coerce!(X, autotype(X, :string_to_multiclass))
yv = <span class="hljs-built_in">Vector</span>(y[:, <span class="hljs-number">1</span>])

LinearRegressorPipe = <span class="hljs-meta">@pipeline</span>(Standardizer(),
                                OneHotEncoder(drop_last = <span class="hljs-literal">true</span>),
                                LinearRegressor())

LinearModel = machine(LinearRegressorPipe, X, yv)
fit!(LinearModel)
fp = fitted_params(LinearModel)</code></pre><pre><code class="plaintext hljs">(standardizer = (mean_and_std_given_feature = Dict(:V1 =&gt; (0.0024456300706479973, 1.1309193246154066),:V2 =&gt; (-0.015561621122145304, 1.1238897897565245),:V5 =&gt; (0.0077036209704558975, 1.1421493464876622),:V3 =&gt; (0.02442889884313839, 2.332713568319154),:V4 =&gt; (0.15168404285157286, 6.806065861835239)),),
 one_hot_encoder = (fitresult = OneHotEncoderResult @252,),
 linear_regressor = (coef = [1.0207869497405524, 1.03242891546997, 0.009406292423317668, 0.026633915171207462, 0.29985915636370225],
                     intercept = 0.015893883995789806,),
 machines = Machine[Machine{Standardizer} @418, Machine{OneHotEncoder} @090, Machine{LinearRegressor} @332],
 fitted_params_given_machine = OrderedCollections.LittleDict{Any,Any,Array{Any,1},Array{Any,1}}(Machine{Standardizer} @418 =&gt; (mean_and_std_given_feature = Dict(:V1 =&gt; (0.0024456300706479973, 1.1309193246154066),:V2 =&gt; (-0.015561621122145304, 1.1238897897565245),:V5 =&gt; (0.0077036209704558975, 1.1421493464876622),:V3 =&gt; (0.02442889884313839, 2.332713568319154),:V4 =&gt; (0.15168404285157286, 6.806065861835239)),),Machine{OneHotEncoder} @090 =&gt; (fitresult = OneHotEncoderResult @252,),Machine{LinearRegressor} @332 =&gt; (coef = [1.0207869497405524, 1.03242891546997, 0.009406292423317668, 0.026633915171207462, 0.29985915636370225], intercept = 0.015893883995789806)),)</code></pre>
<h2 id="reading_the_output_of_fitting_the_linear_model"><a href="#reading_the_output_of_fitting_the_linear_model">Reading the Output of Fitting the Linear Model</a></h2>
<p>We can quickly read the results of our models in MLJ.  Remember to compute the accuracy of the linear model.</p>
<pre><code class="julia hljs">ŷ = MLJ.predict(LinearModel, X)
yhatResponse = [ŷ[i,<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:nrow(y)]
residuals = y .- yhatResponse
r = report(LinearModel)

k = collect(keys(fp.fitted_params_given_machine))[<span class="hljs-number">3</span>]
println(<span class="hljs-string">&quot;\n Coefficients:  &quot;</span>, fp.fitted_params_given_machine[k].coefs)
println(<span class="hljs-string">&quot;\n y \n &quot;</span>, y[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>,<span class="hljs-number">1</span>])
println(<span class="hljs-string">&quot;\n ŷ \n &quot;</span>, ŷ[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>])
println(<span class="hljs-string">&quot;\n yhatResponse \n &quot;</span>, yhatResponse[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>])
println(<span class="hljs-string">&quot;\n Residuals \n &quot;</span>, y[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>,<span class="hljs-number">1</span>] .- yhatResponse[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>])</code></pre><pre><code class="plaintext hljs">MethodError: no method matching -(::Float64, ::Distributions.Normal{Float64})
Closest candidates are:
  -(::Float64, !Matched::Float64) at float.jl:403
  -(::Float64) at float.jl:393
  -(!Matched::PyCall.PyObject, ::Any) at /Users/tlienart/.julia/packages/PyCall/zqDXB/src/pyoperators.jl:13
  ...
</code></pre>
<p>and get the accuracy</p>
<pre><code class="julia hljs">round(rms(yhatResponse, y[:,<span class="hljs-number">1</span>]), sigdigits=<span class="hljs-number">4</span>)</code></pre><pre><code class="plaintext hljs">MethodError: no method matching (::MLJBase.RMS)(::Array{Distributions.Normal{Float64},1}, ::Array{Float64,1})
Closest candidates are:
  Any(!Matched::AbstractArray{#s490,1} where #s490&lt;:Real, ::AbstractArray{#s489,1} where #s489&lt;:Real) at /Users/tlienart/.julia/packages/MLJBase/b1egR/src/measures/continuous.jl:75
  Any(!Matched::AbstractArray{#s490,1} where #s490&lt;:Real, ::AbstractArray{#s489,1} where #s489&lt;:Real, !Matched::AbstractArray{#s488,1} where #s488&lt;:Real) at /Users/tlienart/.julia/packages/MLJBase/b1egR/src/measures/continuous.jl:86
</code></pre>
<h2 id="defining_the_logistic_model"><a href="#defining_the_logistic_model">Defining the Logistic Model</a></h2>
<pre><code class="julia hljs">X = copy(dfX)
y = copy(dfYbinary)

coerce!(X, autotype(X, :string_to_multiclass))
yc = CategoricalArray(y[:, <span class="hljs-number">1</span>])
yc = coerce(yc, OrderedFactor)

LinearBinaryClassifierPipe = <span class="hljs-meta">@pipeline</span>(Standardizer(),
                                       OneHotEncoder(drop_last = <span class="hljs-literal">true</span>),
                                       LinearBinaryClassifier())

LogisticModel = machine(LinearBinaryClassifierPipe, X, yc)
fit!(LogisticModel)
fp = fitted_params(LogisticModel)</code></pre><pre><code class="plaintext hljs">(standardizer = (mean_and_std_given_feature = Dict(:wage =&gt; (9.500506478338009, 1.3430670761078416),:unemp =&gt; (7.597214581091511, 2.763580873344848),:tuition =&gt; (0.8146082493518824, 0.33950381985971717),:score =&gt; (50.88902933684601, 8.701909614072397)),),
 one_hot_encoder = (fitresult = OneHotEncoderResult @441,),
 linear_binary_classifier = Any[],
 machines = Machine[Machine{Standardizer} @169, Machine{OneHotEncoder} @402, Machine{LinearBinaryClassifier{LogitLink}} @499],
 fitted_params_given_machine = OrderedCollections.LittleDict{Any,Any,Array{Any,1},Array{Any,1}}(Machine{Standardizer} @169 =&gt; (mean_and_std_given_feature = Dict(:wage =&gt; (9.500506478338009, 1.3430670761078416),:unemp =&gt; (7.597214581091511, 2.763580873344848),:tuition =&gt; (0.8146082493518824, 0.33950381985971717),:score =&gt; (50.88902933684601, 8.701909614072397)),),Machine{OneHotEncoder} @402 =&gt; (fitresult = OneHotEncoderResult @441,),Machine{LinearBinaryClassifier{LogitLink}} @499 =&gt; (coef = [0.2025072937886873, 0.1307529391091288, 0.34495162493983483, 0.9977565847160845, -0.5022315102984596, -0.4785005626021655, -0.20440507809955027, -0.06922751403500114, 0.058928649730170986, -0.0834474982820323, -0.002315143333859671, 0.46177653955786546, 0.3843262958100772], intercept = -1.076633890579364)),)</code></pre>
<h2 id="reading_the_output_from_the_prediction_of_the_logistic_model"><a href="#reading_the_output_from_the_prediction_of_the_logistic_model">Reading the Output from the Prediction of the Logistic Model</a></h2>
<p>The output of the MLJ model basically contain the same information as the R version of the model.</p>
<pre><code class="julia hljs">ŷ = MLJ.predict(LogisticModel, X)
residuals = [<span class="hljs-number">1</span> - pdf(ŷ[i], y[i,<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:nrow(y)]
r = report(LogisticModel)

k = collect(keys(fp.fitted_params_given_machine))[<span class="hljs-number">3</span>]
println(<span class="hljs-string">&quot;\n Coefficients:  &quot;</span>, fp.fitted_params_given_machine[k].coef)
println(<span class="hljs-string">&quot;\n y \n &quot;</span>, y[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>,<span class="hljs-number">1</span>])
println(<span class="hljs-string">&quot;\n ŷ \n &quot;</span>, ŷ[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>])
println(<span class="hljs-string">&quot;\n residuals \n &quot;</span>, residuals[<span class="hljs-number">1</span>:<span class="hljs-number">5</span>])
println(<span class="hljs-string">&quot;\n Standard Error per Coefficient \n&quot;</span>, r.report_given_machine[k].stderror)</code></pre><pre><code class="plaintext hljs">
 Coefficients:  [0.2025072937886873, 0.1307529391091288, 0.34495162493983483, 0.9977565847160845, -0.5022315102984596, -0.4785005626021655, -0.20440507809955027, -0.06922751403500114, 0.058928649730170986, -0.0834474982820323, -0.002315143333859671, 0.46177653955786546, 0.3843262958100772]

 y 
 [0, 0, 0, 0, 0]

 ŷ 
 UnivariateFinite{OrderedFactor{2},Int64,UInt32,Float64}[UnivariateFinite{OrderedFactor{2}}(0=&gt;0.881, 1=&gt;0.119), UnivariateFinite{OrderedFactor{2}}(0=&gt;0.838, 1=&gt;0.162), UnivariateFinite{OrderedFactor{2}}(0=&gt;0.866, 1=&gt;0.134), UnivariateFinite{OrderedFactor{2}}(0=&gt;0.936, 1=&gt;0.0637), UnivariateFinite{OrderedFactor{2}}(0=&gt;0.944, 1=&gt;0.056)]

 residuals 
 [0.11944603346742211, 0.16182691493524637, 0.13445730373831233, 0.06370799769022917, 0.05604680411361729]

 Standard Error per Coefficient 
[0.07542967234030673, 0.1226000420274196, 0.10934317995152515, 0.04661437250372939, 0.09609243724815351, 0.10743620672240187, 0.10642223545563924, 0.09190778860389329, 0.03922724536508866, 0.04118915117919154, 0.05115399636339276, 0.08454431256127862, 0.1228145565794003, 0.17884724866298302]
</code></pre>
<p>No logistic analysis is complete without the confusion matrix:</p>
<pre><code class="julia hljs">yMode = [mode(ŷ[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:length(ŷ)]
y = coerce(y[:,<span class="hljs-number">1</span>], OrderedFactor)
yMode = coerce(yMode, OrderedFactor)
confusion_matrix(yMode, y)</code></pre><pre><code class="plaintext hljs">              ┌───────────────────────────┐
              │       Ground Truth        │
┌─────────────┼─────────────┬─────────────┤
│  Predicted  │      0      │      1      │
├─────────────┼─────────────┼─────────────┤
│      0      │    3283     │     831     │
├─────────────┼─────────────┼─────────────┤
│      1      │     236     │     389     │
└─────────────┴─────────────┴─────────────┘
</code></pre><div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom and collaborators. Last modified: June 22, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>
  
  
      


  
</body>
</html>
