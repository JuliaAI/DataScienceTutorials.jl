<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/css/franklin.css">
  <link rel="stylesheet" href="/css/pure.css">
  <link rel="stylesheet" href="/css/side-menu.css">
  <link rel="stylesheet" href="/css/extra.css">
  <!-- <link rel="icon" href="/assets/infra/favicon.gif"> -->
   <title>Boston with LightGBM</title>  
  <!-- LUNR -->
  <script src="/libs/lunr/lunr.min.js"></script>
  <script src="/libs/lunr/lunr_index.js"></script>
  <script src="/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/search/index.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/" class="pure-menu-link"><strong>Home</strong></a></li>
    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
    </ul>
    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/getting-started/choosing-a-model/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/getting-started/fit-and-predict/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/getting-started/model-tuning/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/getting-started/ensembles-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/getting-started/ensembles-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
      <li class="pure-menu-item "><a href="/getting-started/composing-models/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/getting-started/learning-networks/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/getting-started/learning-networks-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
      <li class="pure-menu-item "><a href="/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Stacking</a></li>
    </ul>
    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/isl/lab-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-4/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-5/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-6b/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-8/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-9/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/isl/lab-10/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>
    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/wine/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/horse/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/HouseKingCounty/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> King County Houses</a></li>
      <li class="pure-menu-item "><a href="/end-to-end/airfoil" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Airfoil </a></li>
      <li class="pure-menu-item "><a href="/end-to-end/boston-lgbm" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
      <li class="pure-menu-item "><a href="/end-to-end/glm/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->
<div class="franklin-content"><h1 id="boston_with_lightgbm"><a href="#boston_with_lightgbm">Boston with LightGBM</a></h1>
<em>Download the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/notebooks/EX-boston-lgbm.ipynb" target="_blank"><em>notebook</em></a>, <em>the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-boston-lgbm-raw.jl" target="_blank"><em>raw script</em></a>, <em>or the</em> <a href="https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/gh-pages/generated/scripts/EX-boston-lgbm.jl" target="_blank"><em>annotated script</em></a> <em>for this tutorial &#40;right-click on the link and save&#41;.</em> <div class="franklin-toc"><ol><li><a href="#getting_started">Getting started</a></li></ol></div><strong>Main author</strong>: Yaqub Alwan &#40;IQVIA&#41;.</p>
<h2 id="getting_started"><a href="#getting_started">Getting started</a></h2>
<pre><code class="language-julia">using MLJ
using PrettyPrinting
import DataFrames
import Statistics
using PyPlot
using StableRNGs

@load LGBMRegressor</code></pre><pre><code class="plaintext">LightGBM.MLJInterface.LGBMRegressor(10, 0.1, 31, -1, "serial", -1.0, 20, 0.001, 0.0, 0.0, 0.0, 1.0, 2, 1.0, 0, 3, 0, 255, "", "regression", Int64[], 1, true, false, ["l2"], 1, false, [1, 2, 3, 4, 5], 1, 0, 12400, 120, "", false, "cpu")</code></pre>
<p>Let us try LightGBM out by doing a regression task on the Boston house prices dataset. This is a commonly used dataset so there is a loader built into MLJ.</p>
<p>Here, the objective is to show how LightGBM can do better than a Linear Regressor with minimal effort.</p>
<p>We start out by taking a quick peek at the data itself and its statistical properties.</p>
<pre><code class="language-julia">features, targets = @load_boston
features = DataFrames.DataFrame(features)
@show size(features)
@show targets[1:3]
first(features, 3) |> pretty</code></pre><pre><code class="plaintext">size(features) = (506, 12)
targets[1:3] = [24.0, 21.6, 34.7]
┌────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┬────────────────────────────┐
│ Crim                       │ Zn                         │ Indus                      │ NOx                        │ Rm                         │ Age                        │ Dis                        │ Rad                        │ Tax                        │ PTRatio                    │ Black                      │ LStat                      │
│ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │ Float64                    │
│ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │ ScientificTypes.Continuous │
├────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┼────────────────────────────┤
│ 0.00632                    │ 18.0                       │ 2.31                       │ 0.538                      │ 6.575                      │ 65.2                       │ 4.09                       │ 1.0                        │ 296.0                      │ 15.3                       │ 396.9                      │ 4.98                       │
│ 0.02731                    │ 0.0                        │ 7.07                       │ 0.469                      │ 6.421                      │ 78.9                       │ 4.9671                     │ 2.0                        │ 242.0                      │ 17.8                       │ 396.9                      │ 9.14                       │
│ 0.02729                    │ 0.0                        │ 7.07                       │ 0.469                      │ 7.185                      │ 61.1                       │ 4.9671                     │ 2.0                        │ 242.0                      │ 17.8                       │ 392.83                     │ 4.03                       │
└────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┴────────────────────────────┘
</code></pre>
<p>We can also describe the dataframe</p>
<pre><code class="language-julia">DataFrames.describe(features)</code></pre><pre><code class="plaintext">DataFrames.DataFrame(AbstractArray{T,1} where T[[:Crim, :Zn, :Indus, :NOx, :Rm, :Age, :Dis, :Rad, :Tax, :PTRatio, :Black, :LStat], [3.6135235573122535, 11.363636363636363, 11.136778656126504, 0.5546950592885372, 6.284634387351787, 68.57490118577078, 3.795042687747034, 9.549407114624506, 408.2371541501976, 18.455533596837967, 356.67403162055257, 12.653063241106723], [0.00632, 0.0, 0.46, 0.385, 3.561, 2.9, 1.1296, 1.0, 187.0, 12.6, 0.32, 1.73], [0.25651, 0.0, 9.69, 0.538, 6.2085, 77.5, 3.2074499999999997, 5.0, 330.0, 19.05, 391.44, 11.36], [88.9762, 100.0, 27.74, 0.871, 8.78, 100.0, 12.1265, 24.0, 711.0, 22.0, 396.9, 37.97], [nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing], [nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing], DataType[Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64]], DataFrames.Index(Dict(:median => 4,:max => 5,:variable => 1,:mean => 2,:nunique => 6,:nmissing => 7,:eltype => 8,:min => 3), [:variable, :mean, :min, :median, :max, :nunique, :nmissing, :eltype]))</code></pre>
<p>Do the usual train/test partitioning. This is important so we can estimate generalisation.</p>
<pre><code class="language-julia">train, test = partition(eachindex(targets), 0.70, shuffle=true,
                        rng=StableRNG(52))</code></pre><pre><code class="plaintext">([52, 17, 330, 191, 265, 172, 19, 481, 94, 493, 490, 463, 430, 282, 169, 408, 437, 89, 234, 72, 130, 461, 135, 398, 287, 351, 50, 363, 182, 346, 99, 80, 203, 255, 60, 366, 459, 87, 71, 359, 390, 200, 21, 142, 483, 369, 304, 505, 377, 121, 29, 37, 20, 65, 258, 281, 133, 362, 116, 426, 27, 211, 489, 165, 55, 420, 256, 149, 98, 495, 6, 69, 53, 260, 434, 318, 128, 168, 160, 70, 131, 90, 181, 331, 187, 321, 157, 223, 343, 110, 427, 198, 144, 348, 44, 176, 350, 113, 31, 482, 36, 303, 190, 396, 189, 380, 152, 251, 415, 245, 45, 114, 237, 141, 132, 136, 78, 283, 353, 16, 117, 263, 344, 63, 262, 424, 306, 11, 312, 372, 277, 43, 123, 86, 308, 416, 57, 289, 497, 405, 284, 272, 103, 236, 32, 502, 356, 75, 414, 28, 302, 208, 407, 143, 423, 59, 368, 466, 115, 197, 334, 473, 174, 242, 428, 462, 317, 111, 469, 84, 1, 153, 393, 498, 127, 231, 247, 79, 421, 381, 222, 455, 374, 9, 66, 395, 224, 18, 345, 139, 300, 202, 34, 192, 339, 24, 432, 352, 299, 354, 243, 328, 313, 292, 218, 269, 503, 4, 285, 394, 35, 389, 47, 291, 41, 436, 413, 442, 148, 496, 384, 173, 166, 48, 409, 288, 367, 81, 225, 338, 42, 112, 323, 324, 171, 446, 315, 464, 229, 319, 364, 491, 73, 137, 422, 365, 227, 38, 105, 271, 207, 74, 92, 298, 209, 278, 453, 275, 379, 470, 204, 444, 22, 332, 39, 458, 457, 163, 250, 178, 460, 201, 196, 314, 186, 268, 106, 316, 228, 468, 164, 124, 270, 406, 297, 118, 307, 341, 97, 7, 376, 474, 257, 467, 371, 62, 274, 412, 438, 439, 445, 311, 327, 241, 399, 403, 215, 125, 375, 180, 183, 146, 122, 388, 161, 488, 431, 238, 401, 476, 235, 433, 177, 452, 220, 296, 101, 383, 61, 456, 261, 46, 440, 342, 309, 167, 232, 23, 417, 347, 109, 355, 322, 253, 216, 120, 244, 26, 397, 170, 162, 67, 230, 154], [233, 385, 30, 91, 140, 335, 25, 358, 254, 226, 279, 156, 301, 214, 492, 96, 76, 249, 259, 400, 280, 83, 449, 159, 305, 88, 337, 3, 477, 199, 185, 494, 184, 402, 425, 392, 360, 378, 295, 479, 104, 441, 108, 290, 58, 273, 56, 294, 193, 10, 325, 478, 386, 49, 326, 82, 54, 206, 349, 129, 194, 107, 480, 475, 472, 195, 77, 252, 485, 248, 499, 155, 15, 219, 188, 382, 100, 504, 239, 387, 221, 443, 447, 179, 210, 418, 64, 150, 410, 465, 404, 12, 102, 276, 5, 212, 119, 486, 8, 501, 51, 310, 320, 340, 429, 95, 240, 451, 213, 175, 500, 293, 138, 333, 448, 145, 357, 134, 471, 205, 68, 126, 329, 391, 14, 33, 336, 370, 264, 217, 411, 13, 266, 454, 435, 267, 147, 286, 40, 2, 158, 373, 419, 85, 487, 450, 506, 151, 246, 484, 93, 361])</code></pre>
<p>Let us investigation some of the commonly tweaked LightGBM parameters. We start with looking at a learning curve for number of boostings.</p>
<pre><code class="language-julia">lgb = LGBMRegressor() #initialised a model with default params
lgbm = machine(lgb, features[train, :], targets[train, 1])
boostrange = range(lgb, :num_iterations, lower=2, upper=500)
curve = learning_curve!(lgbm, resampling=CV(nfolds=5),
                        range=boostrange, resolution=100,
                        measure=rms)


figure(figsize=(8,6))
plot(curve.parameter_values, curve.measurements)
xlabel("Number of rounds", fontsize=14)
ylabel("RMSE", fontsize=14)</code></pre>
<img src="/assets/end-to-end/boston-lgbm/code/output/lgbm_hp1.svg" alt="">
<p>It looks like that we don&#39;t need to go much past 100 boosts</p>
<p>Since LightGBM is a gradient based learning method, we also have a learning rate parameter which controls the size of gradient updates. Let us look at a learning curve for this parameter too</p>
<pre><code class="language-julia">lgb = LGBMRegressor() #initialised a model with default params
lgbm = machine(lgb, features[train, :], targets[train, 1])
learning_range = range(lgb, :learning_rate, lower=1e-3, upper=1, scale=:log)
curve = learning_curve!(lgbm, resampling=CV(nfolds=5),
                        range=learning_range, resolution=100,
                        measure=rms)


figure(figsize=(8,6))
plot(curve.parameter_values, curve.measurements)
xscale("log")
xlabel("Learning rate (log scale)", fontsize=14)
ylabel("RMSE", fontsize=14)</code></pre>
<img src="/assets/end-to-end/boston-lgbm/code/output/lgbm_hp2.svg" alt="">
<p>It seems like near 0.5 is a reasonable place. Bearing in mind that for lower values of learning rate we possibly require more boosting in order to converge, so the default value of 100 might not be sufficient for convergence. We leave this as an exercise to the reader. We can still try to tune this parameter, however.</p>
<p>Finally let us check number of datapoints required to produce a leaf in an individual tree. This parameter controls the complexity of individual learner trees, and too low a value might lead to overfitting.</p>
<pre><code class="language-julia">lgb = LGBMRegressor() #initialised a model with default params
lgbm = machine(lgb, features[train, :], targets[train, 1])</code></pre><pre><code class="plaintext">MLJBase.Machine{LightGBM.MLJInterface.LGBMRegressor}(LightGBM.MLJInterface.LGBMRegressor(10, 0.1, 31, -1, "serial", -1.0, 20, 0.001, 0.0, 0.0, 0.0, 1.0, 2, 1.0, 0, 3, 0, 255, "", "regression", Int64[], 1, true, false, ["l2"], 1, false, [1, 2, 3, 4, 5], 1, 0, 12400, 120, "", false, "cpu"), #undef, #undef, #undef, (DataFrames.DataFrame(AbstractArray{T,1} where T[[0.04337, 1.05393, 0.06724, 0.09068, 0.55007, 2.3139, 0.80271, 5.82401, 0.02875, 0.11132, 0.18337, 6.65492, 9.33889, 0.03705, 2.3004, 11.9511, 14.4208, 0.0566, 0.33147, 0.15876, 0.88125, 4.81213, 0.97617, 7.67202, 0.01965, 0.06211, 0.21977, 3.67822, 0.06888, 0.03113, 0.08187, 0.08387, 0.02177, 0.04819, 0.10328, 4.55587, 7.75223, 0.05188, 0.08826, 5.20177, 8.15174, 0.0315, 1.25179, 1.62864, 5.73116, 4.89822, 0.1, 0.10959, 15.288, 0.06899, 0.77299, 0.09744, 0.7258, 0.01951, 0.61154, 0.03578, 0.59005, 3.83684, 0.17134, 15.8603, 0.67191, 0.17446, 0.15086, 2.24236, 0.0136, 11.8123, 0.03548, 2.33099, 0.12083, 0.27957, 0.02985, 0.13554, 0.0536, 0.65665, 5.58107, 0.24522, 0.25915, 1.80028, 1.42502, 0.12816, 0.34006, 0.05302, 0.06588, 0.04544, 0.05602, 0.1676, 2.44668, 0.62356, 0.02498, 0.26363, 12.2472, 0.04666, 4.0974, 0.0187, 0.15936, 0.06664, 0.02899, 0.12329, 1.13081, 5.70818, 0.06417, 0.09266, 0.0837, 8.71675, 0.12579, 17.8667, 1.49632, 0.1403, 45.7461, 0.20608, 0.12269, 0.22212, 0.52058, 0.2909, 1.19294, 0.55778, 0.08707, 0.06129, 0.07244, 0.62739, 0.13158, 0.52014, 0.02543, 0.11027, 0.53412, 7.05042, 0.05479, 0.22489, 0.79041, 9.2323, 0.10469, 0.1415, 0.09299, 0.05735, 0.04932, 18.0846, 0.02055, 0.0459, 0.2896, 41.5292, 0.01501, 0.16211, 0.22876, 0.33045, 1.35472, 0.06263, 0.10659, 0.07896, 28.6558, 0.95577, 0.03537, 0.25199, 20.7162, 3.32105, 12.0482, 0.15445, 13.5222, 3.1636, 0.14231, 0.04011, 0.05083, 3.56868, 0.09178, 0.10612, 37.6619, 3.69311, 0.31827, 0.10793, 15.5757, 0.03551, 0.00632, 1.12658, 11.5779, 0.26838, 0.38735, 0.537, 0.33983, 0.05646, 11.0874, 88.9762, 0.40771, 9.51363, 11.1081, 0.21124, 0.03584, 13.3598, 0.6147, 0.7842, 0.03049, 0.2498, 0.05561, 0.03445, 1.15172, 0.06911, 0.03306, 0.98843, 10.0623, 0.0795, 0.06466, 0.01709, 0.1029, 0.24103, 0.26169, 0.07886, 0.07013, 0.5405, 0.04527, 0.03237, 0.00906, 8.64476, 1.61282, 14.3337, 0.18836, 0.03502, 0.03359, 11.1604, 18.811, 9.72418, 2.36862, 0.17899, 7.99248, 0.13914, 2.924, 0.22927, 7.40389, 0.03871, 3.69695, 0.04113, 0.31533, 0.03041, 0.12744, 0.10084, 0.35114, 0.28392, 1.20742, 10.6718, 0.3692, 5.82115, 0.29819, 0.40202, 4.22239, 0.20746, 0.09164, 0.32264, 7.02259, 3.47428, 0.38214, 0.08014, 0.1396, 0.29916, 0.22969, 0.19539, 0.03932, 0.14103, 0.13587, 0.06127, 5.09017, 0.05644, 23.6482, 13.0751, 0.0351, 9.96654, 0.85204, 0.05023, 0.17505, 8.20058, 4.66883, 1.83377, 0.19073, 0.05425, 6.80117, 0.01778, 0.01381, 0.26938, 0.06047, 0.57834, 0.13262, 0.25356, 0.41238, 4.42228, 1.51902, 0.15038, 0.09065, 67.9208, 0.05372, 0.15098, 0.07503, 0.06151, 0.11504, 0.08829, 19.6091, 4.64689, 0.01538, 3.77498, 6.53876, 0.17171, 0.22188, 14.0507, 15.1772, 13.6781, 12.8023, 2.63548, 0.30347, 0.11329, 38.3518, 9.59571, 0.28955, 0.09849, 18.4982, 0.0578, 0.09103, 2.37934, 0.07165, 22.5971, 1.27346, 4.83567, 8.49213, 0.51183, 25.0461, 6.39312, 0.44791, 6.44405, 0.07022, 5.44114, 0.11425, 0.12932, 0.14866, 9.18702, 0.14932, 4.75237, 0.54011, 0.17142, 9.39063, 0.01301, 0.49298, 2.01019, 0.46296, 1.23247, 10.8342, 0.06162, 0.12802, 0.04301, 0.18159, 0.08221, 0.19802, 0.14476, 0.12757, 0.84054, 5.87205, 2.44953, 1.46336, 0.04379, 0.44178, 2.14918], [21.0, 0.0, 0.0, 45.0, 20.0, 0.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 82.5, 80.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 95.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.5, 20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 75.0, 0.0, 80.0, 0.0, 0.0, 0.0, 0.0, 12.5, 21.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 0.0, 85.0, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, 34.0, 45.0, 0.0, 45.0, 0.0, 0.0, 22.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 60.0, 0.0, 0.0, 20.0, 55.0, 25.0, 20.0, 0.0, 33.0, 12.5, 0.0, 0.0, 40.0, 0.0, 0.0, 0.0, 33.0, 0.0, 85.0, 52.5, 0.0, 0.0, 90.0, 20.0, 0.0, 0.0, 0.0, 0.0, 80.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 80.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 80.0, 0.0, 0.0, 0.0, 55.0, 0.0, 70.0, 82.5, 0.0, 45.0, 0.0, 0.0, 0.0, 60.0, 70.0, 90.0, 30.0, 0.0, 0.0, 80.0, 0.0, 20.0, 0.0, 0.0, 90.0, 0.0, 0.0, 0.0, 0.0, 80.0, 75.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 52.5, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 40.0, 0.0, 40.0, 0.0, 0.0, 95.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 95.0, 80.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 12.5, 0.0, 0.0, 90.0, 0.0, 0.0, 25.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 20.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 80.0, 0.0, 22.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 80.0, 0.0, 0.0], [5.64, 8.14, 3.24, 3.44, 3.97, 19.58, 8.14, 18.1, 15.04, 27.74, 27.74, 18.1, 18.1, 3.33, 19.58, 18.1, 18.1, 3.41, 6.2, 10.81, 21.89, 18.1, 21.89, 18.1, 1.76, 1.25, 6.91, 18.1, 2.46, 4.39, 2.89, 12.83, 2.03, 3.64, 5.13, 18.1, 18.1, 4.49, 10.81, 18.1, 18.1, 1.47, 8.14, 21.89, 18.1, 18.1, 6.09, 11.93, 18.1, 25.65, 8.14, 5.96, 8.14, 1.38, 3.97, 3.33, 21.89, 18.1, 10.01, 18.1, 8.14, 10.59, 27.74, 19.58, 4.0, 18.1, 3.64, 19.58, 2.89, 9.69, 2.18, 6.07, 5.64, 3.97, 18.1, 9.9, 21.89, 19.58, 19.58, 6.07, 21.89, 3.41, 2.46, 3.24, 2.46, 7.38, 19.58, 6.2, 1.89, 8.56, 18.1, 1.52, 19.58, 4.15, 6.91, 4.05, 1.25, 10.01, 8.14, 18.1, 5.96, 6.09, 3.44, 18.1, 3.44, 18.1, 19.58, 5.86, 18.1, 5.86, 6.91, 10.01, 6.2, 21.89, 21.89, 21.89, 12.83, 3.33, 1.69, 8.14, 10.01, 3.97, 3.78, 5.13, 3.97, 18.1, 2.18, 7.87, 9.9, 18.1, 6.41, 6.91, 25.65, 4.49, 2.18, 18.1, 0.74, 5.32, 9.69, 18.1, 1.21, 6.96, 8.56, 6.2, 8.14, 11.93, 1.91, 12.83, 18.1, 8.14, 6.09, 10.59, 18.1, 19.58, 18.1, 5.13, 18.1, 18.1, 10.01, 1.52, 5.19, 18.1, 4.05, 4.93, 18.1, 18.1, 9.9, 8.56, 18.1, 4.86, 2.31, 19.58, 18.1, 9.69, 25.65, 6.2, 5.86, 12.83, 18.1, 18.1, 6.2, 18.1, 18.1, 7.87, 3.37, 18.1, 6.2, 8.14, 3.78, 21.89, 2.24, 2.03, 8.14, 3.44, 5.19, 8.14, 18.1, 1.69, 2.24, 2.02, 4.93, 7.38, 9.9, 4.95, 13.89, 3.97, 11.93, 2.18, 2.97, 18.1, 8.14, 18.1, 6.91, 4.95, 2.95, 18.1, 18.1, 18.1, 19.58, 9.69, 18.1, 4.05, 19.58, 6.91, 18.1, 5.32, 18.1, 4.86, 6.2, 5.19, 6.91, 10.01, 7.38, 7.38, 19.58, 18.1, 9.9, 18.1, 6.2, 9.9, 18.1, 27.74, 10.81, 21.89, 18.1, 18.1, 6.2, 5.96, 8.56, 6.96, 10.59, 10.81, 3.41, 13.92, 10.59, 6.41, 18.1, 6.41, 18.1, 18.1, 2.68, 18.1, 8.14, 6.06, 5.96, 18.1, 18.1, 19.58, 5.86, 4.05, 18.1, 1.47, 0.46, 9.9, 2.46, 3.97, 8.56, 9.9, 6.2, 18.1, 19.58, 25.65, 6.96, 18.1, 13.92, 10.01, 2.18, 5.19, 2.89, 7.87, 18.1, 18.1, 3.75, 18.1, 18.1, 5.13, 6.96, 18.1, 18.1, 18.1, 18.1, 9.9, 7.38, 4.93, 18.1, 18.1, 10.59, 25.65, 18.1, 2.46, 2.46, 19.58, 25.65, 18.1, 19.58, 18.1, 18.1, 6.2, 18.1, 18.1, 6.2, 18.1, 4.05, 18.1, 13.89, 13.92, 8.56, 18.1, 5.13, 18.1, 3.97, 6.91, 18.1, 1.52, 9.9, 19.58, 6.2, 8.14, 18.1, 4.39, 8.56, 1.91, 7.38, 5.86, 10.59, 10.01, 4.93, 8.14, 18.1, 19.58, 19.58, 3.37, 6.2, 19.58], [0.439, 0.538, 0.46, 0.437, 0.647, 0.605, 0.538, 0.532, 0.464, 0.609, 0.609, 0.713, 0.679, 0.4429, 0.605, 0.659, 0.74, 0.489, 0.507, 0.413, 0.624, 0.713, 0.624, 0.693, 0.385, 0.429, 0.448, 0.77, 0.488, 0.442, 0.445, 0.437, 0.415, 0.392, 0.453, 0.718, 0.713, 0.449, 0.413, 0.77, 0.7, 0.403, 0.538, 0.624, 0.532, 0.631, 0.433, 0.573, 0.671, 0.581, 0.538, 0.499, 0.538, 0.4161, 0.647, 0.4429, 0.624, 0.77, 0.547, 0.679, 0.538, 0.489, 0.609, 0.605, 0.41, 0.718, 0.392, 0.871, 0.445, 0.585, 0.458, 0.409, 0.439, 0.647, 0.713, 0.544, 0.624, 0.605, 0.871, 0.409, 0.624, 0.489, 0.488, 0.46, 0.488, 0.493, 0.871, 0.507, 0.518, 0.52, 0.584, 0.404, 0.871, 0.429, 0.448, 0.51, 0.429, 0.547, 0.538, 0.532, 0.499, 0.433, 0.437, 0.693, 0.437, 0.671, 0.871, 0.431, 0.693, 0.431, 0.448, 0.547, 0.507, 0.624, 0.624, 0.624, 0.437, 0.4429, 0.411, 0.538, 0.547, 0.647, 0.484, 0.453, 0.647, 0.614, 0.472, 0.524, 0.544, 0.631, 0.447, 0.448, 0.581, 0.449, 0.472, 0.679, 0.41, 0.405, 0.585, 0.693, 0.401, 0.464, 0.52, 0.507, 0.538, 0.573, 0.413, 0.437, 0.597, 0.538, 0.433, 0.489, 0.659, 0.871, 0.614, 0.453, 0.631, 0.655, 0.547, 0.404, 0.515, 0.58, 0.51, 0.428, 0.679, 0.713, 0.544, 0.52, 0.58, 0.426, 0.538, 0.871, 0.7, 0.585, 0.581, 0.504, 0.431, 0.437, 0.718, 0.671, 0.507, 0.713, 0.668, 0.524, 0.398, 0.693, 0.507, 0.538, 0.484, 0.624, 0.4, 0.415, 0.538, 0.437, 0.515, 0.538, 0.584, 0.411, 0.4, 0.41, 0.428, 0.493, 0.544, 0.411, 0.55, 0.575, 0.573, 0.458, 0.4, 0.693, 0.538, 0.7, 0.448, 0.411, 0.428, 0.74, 0.597, 0.74, 0.871, 0.585, 0.7, 0.51, 0.605, 0.448, 0.597, 0.405, 0.718, 0.426, 0.504, 0.515, 0.448, 0.547, 0.493, 0.493, 0.605, 0.74, 0.544, 0.713, 0.504, 0.544, 0.77, 0.609, 0.413, 0.624, 0.718, 0.718, 0.504, 0.499, 0.52, 0.464, 0.489, 0.413, 0.489, 0.437, 0.489, 0.447, 0.713, 0.447, 0.671, 0.58, 0.4161, 0.74, 0.538, 0.4379, 0.499, 0.713, 0.713, 0.605, 0.431, 0.51, 0.713, 0.403, 0.422, 0.544, 0.488, 0.575, 0.52, 0.544, 0.504, 0.584, 0.605, 0.581, 0.464, 0.693, 0.437, 0.547, 0.472, 0.515, 0.445, 0.524, 0.671, 0.614, 0.394, 0.655, 0.631, 0.453, 0.464, 0.597, 0.74, 0.74, 0.74, 0.544, 0.493, 0.428, 0.693, 0.693, 0.489, 0.581, 0.668, 0.488, 0.488, 0.871, 0.581, 0.7, 0.605, 0.583, 0.584, 0.507, 0.693, 0.584, 0.507, 0.584, 0.51, 0.713, 0.55, 0.437, 0.52, 0.7, 0.453, 0.713, 0.647, 0.448, 0.74, 0.442, 0.544, 0.605, 0.504, 0.538, 0.679, 0.442, 0.52, 0.413, 0.493, 0.431, 0.489, 0.547, 0.428, 0.538, 0.693, 0.605, 0.605, 0.398, 0.504, 0.871], [6.115, 5.935, 6.333, 6.951, 7.206, 5.88, 5.456, 6.242, 6.211, 5.983, 5.414, 6.317, 6.38, 6.968, 6.319, 5.608, 6.461, 7.007, 8.247, 5.961, 5.637, 6.701, 5.757, 5.747, 6.23, 6.49, 5.602, 5.362, 6.144, 6.014, 7.82, 5.874, 7.61, 6.108, 5.927, 3.561, 6.301, 6.015, 6.417, 6.127, 5.39, 6.975, 5.57, 5.019, 7.061, 4.97, 6.982, 6.794, 6.649, 5.87, 6.495, 5.841, 5.727, 7.104, 8.704, 7.82, 6.372, 6.251, 5.928, 5.896, 5.813, 5.96, 5.454, 5.854, 5.888, 6.824, 5.876, 5.186, 8.069, 5.926, 6.43, 5.594, 6.511, 6.842, 6.436, 5.782, 5.693, 5.877, 6.51, 5.885, 6.458, 7.079, 7.765, 6.144, 7.831, 6.426, 5.272, 6.879, 6.54, 6.229, 5.837, 7.107, 5.468, 6.516, 6.211, 6.546, 6.939, 5.913, 5.713, 6.75, 5.933, 6.495, 7.185, 6.471, 6.556, 6.223, 5.404, 6.487, 4.519, 5.593, 6.069, 6.092, 6.631, 6.174, 6.326, 6.335, 6.14, 7.645, 5.884, 5.834, 6.176, 8.398, 6.696, 6.456, 7.52, 6.103, 6.616, 6.377, 6.122, 6.216, 7.267, 6.169, 5.961, 6.63, 6.849, 6.434, 6.383, 6.315, 5.39, 5.531, 7.923, 6.24, 6.405, 6.086, 6.072, 6.593, 5.936, 6.273, 5.155, 6.047, 6.59, 5.783, 4.138, 5.403, 5.648, 6.145, 3.863, 5.759, 6.254, 7.287, 6.316, 6.437, 6.416, 6.095, 6.202, 6.376, 5.914, 6.195, 5.926, 6.167, 6.575, 5.012, 5.036, 5.794, 5.613, 5.981, 6.108, 6.232, 6.411, 6.968, 6.164, 6.728, 4.906, 5.631, 6.29, 5.887, 6.618, 5.99, 6.874, 5.857, 7.041, 6.162, 5.701, 6.739, 6.059, 5.813, 6.833, 6.579, 6.345, 6.728, 6.358, 6.083, 6.023, 7.148, 6.642, 7.47, 6.12, 6.998, 7.088, 6.193, 6.096, 4.88, 5.786, 6.861, 7.024, 6.629, 4.628, 6.406, 4.926, 5.67, 5.52, 5.572, 6.101, 6.03, 5.617, 6.209, 4.963, 6.727, 8.266, 5.895, 6.77, 6.715, 6.041, 5.708, 5.875, 6.459, 6.567, 6.513, 7.686, 6.382, 5.803, 5.093, 6.065, 5.942, 6.006, 8.78, 8.04, 5.85, 6.167, 5.856, 6.326, 6.245, 6.405, 5.79, 6.064, 6.826, 6.297, 6.758, 6.38, 5.713, 7.853, 6.485, 5.965, 5.706, 5.966, 5.936, 5.976, 7.802, 6.718, 6.315, 6.081, 7.135, 7.875, 6.266, 6.153, 8.297, 5.851, 5.705, 7.163, 6.003, 8.375, 5.856, 5.92, 5.683, 6.549, 6.021, 7.42, 5.968, 6.163, 6.012, 7.313, 6.98, 7.454, 5.952, 7.016, 5.966, 7.691, 6.657, 6.152, 5.935, 5.854, 4.973, 6.312, 6.897, 5.453, 6.404, 5.412, 5.879, 4.138, 6.98, 7.155, 6.13, 6.004, 5.0, 6.25, 5.905, 6.348, 7.358, 5.987, 6.162, 6.726, 6.425, 6.02, 6.655, 6.373, 6.678, 6.727, 5.536, 5.741, 6.525, 7.203, 5.682, 5.627, 7.241, 6.635, 7.929, 7.412, 6.142, 6.782, 5.898, 6.474, 5.663, 6.376, 6.957, 6.182, 5.731, 6.393, 5.599, 6.405, 6.402, 7.489, 5.787, 6.552, 5.709], [63.0, 29.3, 17.2, 21.5, 91.6, 97.3, 36.6, 64.7, 28.9, 83.5, 98.3, 83.0, 95.6, 37.2, 96.1, 100.0, 93.3, 86.3, 70.4, 17.5, 94.7, 90.0, 98.4, 98.9, 31.5, 44.4, 62.0, 96.2, 62.2, 48.5, 36.9, 36.6, 15.7, 32.0, 47.2, 87.9, 83.7, 45.1, 6.6, 83.4, 98.9, 15.3, 98.1, 100.0, 77.0, 100.0, 17.7, 89.3, 93.3, 69.7, 94.4, 61.4, 69.5, 59.5, 86.9, 64.5, 97.9, 91.1, 88.2, 95.4, 90.3, 92.1, 92.7, 91.8, 47.6, 76.5, 19.1, 93.8, 76.0, 42.6, 58.7, 36.8, 21.1, 100.0, 87.9, 71.7, 96.0, 79.2, 100.0, 33.0, 98.9, 63.1, 83.3, 32.2, 53.6, 52.3, 94.0, 77.7, 59.7, 91.2, 59.7, 36.6, 100.0, 27.7, 6.5, 33.1, 34.5, 92.9, 94.1, 74.9, 68.2, 18.4, 38.9, 98.8, 29.1, 100.0, 100.0, 13.0, 100.0, 76.5, 40.0, 95.4, 76.5, 93.6, 97.7, 98.2, 45.8, 49.7, 18.5, 56.5, 72.5, 91.5, 56.4, 67.8, 89.4, 85.1, 58.1, 94.3, 52.8, 100.0, 49.0, 6.6, 92.9, 56.1, 70.3, 100.0, 35.7, 45.6, 72.9, 85.4, 24.8, 16.3, 85.4, 61.5, 100.0, 69.1, 19.5, 6.0, 100.0, 88.8, 40.4, 72.7, 100.0, 100.0, 87.6, 29.2, 100.0, 48.2, 84.2, 34.1, 38.1, 75.0, 84.1, 65.1, 78.7, 88.4, 83.2, 54.4, 71.0, 46.7, 65.2, 88.0, 97.0, 70.6, 95.6, 68.1, 34.9, 53.7, 100.0, 91.9, 91.3, 94.1, 100.0, 100.0, 17.8, 94.7, 80.8, 81.7, 28.1, 98.2, 10.0, 38.4, 95.0, 30.8, 37.3, 100.0, 94.3, 35.9, 20.1, 36.1, 52.9, 43.7, 90.4, 27.7, 85.1, 52.6, 76.7, 45.8, 20.8, 92.6, 96.9, 100.0, 33.3, 27.9, 15.8, 94.6, 100.0, 97.2, 95.7, 28.8, 100.0, 88.5, 93.0, 85.5, 97.9, 31.3, 91.4, 33.5, 78.3, 59.6, 2.9, 81.6, 49.9, 74.3, 94.6, 94.8, 87.3, 89.9, 17.0, 67.2, 89.0, 98.0, 7.8, 93.5, 95.3, 82.9, 86.5, 41.5, 90.0, 42.1, 52.5, 6.2, 73.9, 58.0, 59.1, 27.6, 91.8, 32.9, 96.2, 56.7, 33.2, 100.0, 89.2, 28.4, 30.2, 80.3, 87.9, 98.2, 17.5, 73.4, 84.4, 13.9, 32.0, 82.8, 68.8, 67.0, 96.7, 77.7, 79.9, 94.5, 93.9, 97.0, 61.5, 100.0, 51.0, 82.6, 71.9, 58.5, 69.6, 66.6, 97.9, 67.6, 34.2, 84.7, 97.5, 93.4, 51.8, 100.0, 100.0, 87.9, 96.6, 37.8, 28.9, 54.3, 100.0, 100.0, 9.8, 95.8, 100.0, 58.4, 92.2, 100.0, 84.1, 89.5, 92.6, 53.2, 86.1, 71.6, 100.0, 97.4, 66.5, 74.8, 47.2, 98.2, 92.4, 31.1, 79.9, 100.0, 66.2, 86.5, 81.8, 33.8, 93.9, 49.3, 82.5, 96.2, 76.9, 91.7, 90.8, 52.3, 97.1, 21.9, 54.3, 6.8, 42.4, 65.2, 7.8, 85.7, 96.0, 95.2, 90.8, 31.1, 21.4, 98.5], [6.8147, 4.4986, 5.2146, 6.4798, 1.9301, 2.3887, 3.7965, 3.4242, 3.6659, 2.1099, 1.7554, 2.7344, 1.9682, 5.2447, 2.1, 1.2852, 2.0026, 3.4217, 3.6519, 5.2873, 1.9799, 2.5975, 2.346, 1.6334, 9.0892, 8.7921, 6.0877, 2.1036, 2.5979, 8.0136, 3.4952, 4.5026, 6.27, 9.2203, 6.932, 1.6132, 2.7831, 4.4272, 5.2873, 2.7227, 1.7281, 7.6534, 3.7979, 1.4394, 3.4106, 1.3325, 5.4917, 2.3889, 1.3449, 2.2577, 4.4547, 3.3779, 3.7965, 9.2229, 1.801, 4.6947, 2.3274, 2.2955, 2.4631, 1.9096, 4.682, 3.8771, 1.8209, 2.422, 7.3197, 1.794, 9.2203, 1.5296, 3.4952, 2.3817, 6.0622, 6.498, 6.8147, 2.0107, 2.3158, 4.0317, 1.7883, 2.4259, 1.7659, 6.498, 2.1185, 3.4145, 2.741, 5.8736, 3.1992, 4.5404, 1.7364, 3.2721, 6.2669, 2.5451, 1.9976, 7.309, 1.4118, 8.5353, 5.7209, 3.1323, 8.7921, 2.3534, 4.233, 3.3317, 3.3603, 5.4917, 4.5667, 1.7257, 4.5667, 1.3861, 1.5916, 7.3967, 1.6582, 7.9549, 5.7209, 2.548, 4.148, 1.6119, 2.271, 2.1107, 4.0905, 5.2119, 10.7103, 4.4986, 2.7301, 2.2885, 5.7321, 7.2255, 2.1398, 2.0218, 3.37, 6.3467, 2.6403, 1.1691, 4.7872, 5.7209, 2.0869, 4.4377, 3.1827, 1.8347, 9.1876, 7.3172, 2.7986, 1.6074, 5.885, 4.429, 2.7147, 3.6519, 4.175, 2.4786, 10.5857, 4.2515, 1.5894, 4.4534, 5.4917, 4.3549, 1.1781, 1.3216, 1.9512, 7.8148, 1.5106, 3.0665, 2.2565, 7.309, 6.4584, 2.8965, 2.6463, 6.3361, 1.8629, 2.5671, 3.9986, 2.7778, 2.9084, 5.4007, 4.09, 1.6102, 1.77, 2.8927, 1.7572, 3.6715, 8.0555, 5.0141, 1.8589, 1.4165, 3.048, 2.4961, 1.1742, 6.0821, 6.6115, 1.7821, 3.2721, 4.2579, 6.4654, 1.6686, 7.8278, 6.27, 3.7872, 6.4798, 4.8122, 4.0952, 2.0882, 10.7103, 7.8278, 12.1265, 7.0355, 5.4159, 2.834, 5.1167, 3.4211, 2.872, 2.2875, 6.0622, 7.3073, 1.7912, 3.7598, 1.5895, 5.1004, 5.1167, 5.4011, 2.1247, 1.5539, 2.0651, 1.4608, 2.7986, 1.5331, 2.5961, 2.2834, 5.6894, 1.4547, 7.3172, 1.7523, 5.4007, 2.8944, 5.615, 5.7209, 2.6775, 4.7211, 4.7211, 2.4259, 1.9879, 3.6023, 2.8016, 3.3751, 3.5325, 1.9047, 1.8226, 5.2873, 1.9669, 1.8746, 1.9047, 3.2157, 3.9342, 2.421, 4.429, 4.3549, 5.2873, 3.0921, 6.32, 4.2392, 4.8628, 2.3682, 4.0776, 1.3861, 2.8237, 5.118, 1.9784, 4.0123, 6.6407, 3.8473, 2.7792, 2.5806, 2.0407, 7.8265, 3.3175, 2.7175, 7.6534, 5.6484, 3.2628, 3.2797, 2.4216, 2.1069, 3.945, 3.2157, 2.5403, 2.162, 1.9444, 3.9175, 1.4254, 5.9604, 2.7474, 3.0992, 4.8122, 3.4952, 5.5605, 1.3163, 2.5329, 6.3361, 2.8715, 1.2024, 6.8185, 4.3665, 1.5275, 1.9142, 1.8206, 1.8956, 2.5194, 5.4159, 6.3361, 1.4896, 1.639, 3.5875, 2.0063, 1.137, 2.829, 2.7006, 1.4191, 2.1974, 1.5184, 1.7984, 3.1523, 2.0527, 4.148, 1.5888, 2.206, 3.6519, 2.2004, 3.5549, 2.3552, 3.3633, 5.9604, 2.7778, 1.5804, 7.2254, 2.4358, 2.1121, 5.1004, 1.8172, 7.0379, 3.3175, 2.0459, 3.6715, 3.9769, 1.8195, 8.0136, 2.4329, 10.5857, 4.5404, 8.9067, 3.9454, 2.7592, 7.0355, 4.4546, 1.6768, 2.2625, 1.9709, 6.6115, 3.3751, 1.6232], [4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 24.0, 4.0, 4.0, 4.0, 24.0, 24.0, 5.0, 5.0, 24.0, 24.0, 2.0, 8.0, 4.0, 4.0, 24.0, 4.0, 24.0, 1.0, 1.0, 3.0, 24.0, 3.0, 3.0, 2.0, 5.0, 2.0, 1.0, 8.0, 24.0, 24.0, 3.0, 4.0, 24.0, 24.0, 3.0, 4.0, 4.0, 24.0, 24.0, 7.0, 1.0, 24.0, 2.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0, 4.0, 24.0, 6.0, 24.0, 4.0, 4.0, 4.0, 5.0, 3.0, 24.0, 1.0, 5.0, 2.0, 6.0, 3.0, 4.0, 4.0, 5.0, 24.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 2.0, 3.0, 4.0, 3.0, 5.0, 5.0, 8.0, 1.0, 5.0, 24.0, 2.0, 5.0, 4.0, 3.0, 5.0, 1.0, 6.0, 4.0, 24.0, 5.0, 7.0, 5.0, 24.0, 5.0, 24.0, 5.0, 7.0, 24.0, 7.0, 3.0, 6.0, 8.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 6.0, 5.0, 5.0, 8.0, 5.0, 24.0, 7.0, 5.0, 4.0, 24.0, 4.0, 3.0, 2.0, 3.0, 7.0, 24.0, 2.0, 6.0, 6.0, 24.0, 1.0, 3.0, 5.0, 8.0, 4.0, 1.0, 4.0, 5.0, 24.0, 4.0, 7.0, 4.0, 24.0, 5.0, 24.0, 8.0, 24.0, 24.0, 6.0, 2.0, 5.0, 24.0, 5.0, 6.0, 24.0, 24.0, 4.0, 5.0, 24.0, 4.0, 1.0, 5.0, 24.0, 6.0, 2.0, 8.0, 7.0, 5.0, 24.0, 24.0, 8.0, 24.0, 24.0, 5.0, 4.0, 24.0, 8.0, 4.0, 5.0, 4.0, 5.0, 2.0, 4.0, 5.0, 5.0, 4.0, 24.0, 4.0, 5.0, 5.0, 6.0, 5.0, 4.0, 4.0, 5.0, 5.0, 1.0, 3.0, 1.0, 24.0, 4.0, 24.0, 3.0, 4.0, 3.0, 24.0, 24.0, 24.0, 5.0, 6.0, 24.0, 5.0, 5.0, 3.0, 24.0, 6.0, 24.0, 4.0, 8.0, 5.0, 3.0, 6.0, 5.0, 5.0, 5.0, 24.0, 4.0, 24.0, 8.0, 4.0, 24.0, 4.0, 4.0, 4.0, 24.0, 24.0, 8.0, 5.0, 5.0, 3.0, 4.0, 4.0, 2.0, 4.0, 4.0, 4.0, 24.0, 4.0, 24.0, 24.0, 4.0, 24.0, 4.0, 1.0, 5.0, 24.0, 24.0, 5.0, 7.0, 5.0, 24.0, 3.0, 4.0, 4.0, 3.0, 5.0, 5.0, 4.0, 8.0, 24.0, 5.0, 2.0, 3.0, 24.0, 4.0, 6.0, 7.0, 5.0, 2.0, 5.0, 24.0, 24.0, 3.0, 24.0, 24.0, 8.0, 3.0, 24.0, 24.0, 24.0, 24.0, 4.0, 5.0, 6.0, 24.0, 24.0, 4.0, 2.0, 24.0, 3.0, 3.0, 5.0, 2.0, 24.0, 5.0, 24.0, 24.0, 8.0, 24.0, 24.0, 8.0, 24.0, 5.0, 24.0, 5.0, 4.0, 5.0, 24.0, 8.0, 24.0, 5.0, 3.0, 24.0, 1.0, 4.0, 5.0, 8.0, 4.0, 24.0, 3.0, 5.0, 4.0, 5.0, 7.0, 4.0, 6.0, 6.0, 4.0, 24.0, 5.0, 5.0, 4.0, 8.0, 5.0], [243.0, 307.0, 430.0, 398.0, 264.0, 403.0, 307.0, 666.0, 270.0, 711.0, 711.0, 666.0, 666.0, 216.0, 403.0, 666.0, 666.0, 270.0, 307.0, 305.0, 437.0, 666.0, 437.0, 666.0, 241.0, 335.0, 233.0, 666.0, 193.0, 352.0, 276.0, 398.0, 348.0, 315.0, 284.0, 666.0, 666.0, 247.0, 305.0, 666.0, 666.0, 402.0, 307.0, 437.0, 666.0, 666.0, 329.0, 273.0, 666.0, 188.0, 307.0, 279.0, 307.0, 216.0, 264.0, 216.0, 437.0, 666.0, 432.0, 666.0, 307.0, 277.0, 711.0, 403.0, 469.0, 666.0, 315.0, 403.0, 276.0, 391.0, 222.0, 345.0, 243.0, 264.0, 666.0, 304.0, 437.0, 403.0, 403.0, 345.0, 437.0, 270.0, 193.0, 430.0, 193.0, 287.0, 403.0, 307.0, 422.0, 384.0, 666.0, 329.0, 403.0, 351.0, 233.0, 296.0, 335.0, 432.0, 307.0, 666.0, 279.0, 329.0, 398.0, 666.0, 398.0, 666.0, 403.0, 330.0, 666.0, 330.0, 233.0, 432.0, 307.0, 437.0, 437.0, 437.0, 398.0, 216.0, 411.0, 307.0, 432.0, 264.0, 370.0, 284.0, 264.0, 666.0, 222.0, 311.0, 304.0, 666.0, 254.0, 233.0, 188.0, 247.0, 222.0, 666.0, 313.0, 293.0, 391.0, 666.0, 198.0, 223.0, 384.0, 307.0, 307.0, 273.0, 334.0, 398.0, 666.0, 307.0, 329.0, 277.0, 666.0, 403.0, 666.0, 284.0, 666.0, 666.0, 432.0, 329.0, 224.0, 666.0, 296.0, 300.0, 666.0, 666.0, 304.0, 384.0, 666.0, 281.0, 296.0, 403.0, 666.0, 391.0, 188.0, 307.0, 330.0, 398.0, 666.0, 666.0, 307.0, 666.0, 666.0, 311.0, 337.0, 666.0, 307.0, 307.0, 370.0, 437.0, 358.0, 348.0, 307.0, 398.0, 224.0, 307.0, 666.0, 411.0, 358.0, 187.0, 300.0, 287.0, 304.0, 245.0, 276.0, 264.0, 273.0, 222.0, 285.0, 666.0, 307.0, 666.0, 233.0, 245.0, 252.0, 666.0, 666.0, 666.0, 403.0, 391.0, 666.0, 296.0, 403.0, 233.0, 666.0, 293.0, 666.0, 281.0, 307.0, 224.0, 233.0, 432.0, 287.0, 287.0, 403.0, 666.0, 304.0, 666.0, 307.0, 304.0, 666.0, 711.0, 305.0, 437.0, 666.0, 666.0, 307.0, 279.0, 384.0, 223.0, 277.0, 305.0, 270.0, 289.0, 277.0, 254.0, 666.0, 254.0, 666.0, 666.0, 224.0, 666.0, 307.0, 304.0, 279.0, 666.0, 666.0, 403.0, 330.0, 296.0, 666.0, 402.0, 255.0, 304.0, 193.0, 264.0, 384.0, 304.0, 307.0, 666.0, 403.0, 188.0, 223.0, 666.0, 289.0, 432.0, 222.0, 224.0, 276.0, 311.0, 666.0, 666.0, 244.0, 666.0, 666.0, 284.0, 223.0, 666.0, 666.0, 666.0, 666.0, 304.0, 287.0, 300.0, 666.0, 666.0, 277.0, 188.0, 666.0, 193.0, 193.0, 403.0, 188.0, 666.0, 403.0, 666.0, 666.0, 307.0, 666.0, 666.0, 307.0, 666.0, 296.0, 666.0, 276.0, 289.0, 384.0, 666.0, 284.0, 666.0, 264.0, 233.0, 666.0, 284.0, 304.0, 403.0, 307.0, 307.0, 666.0, 352.0, 384.0, 334.0, 287.0, 330.0, 277.0, 432.0, 300.0, 307.0, 666.0, 403.0, 403.0, 337.0, 307.0, 403.0], [16.8, 21.0, 16.9, 15.2, 13.0, 14.7, 21.0, 20.2, 18.2, 20.1, 20.1, 20.2, 20.2, 14.9, 14.7, 20.2, 20.2, 17.8, 17.4, 19.2, 21.2, 20.2, 21.2, 20.2, 18.2, 19.7, 17.9, 20.2, 17.8, 18.8, 18.0, 18.7, 14.7, 16.4, 19.7, 20.2, 20.2, 18.5, 19.2, 20.2, 20.2, 17.0, 21.0, 21.2, 20.2, 20.2, 16.1, 21.0, 20.2, 19.1, 21.0, 19.2, 21.0, 18.6, 13.0, 14.9, 21.2, 20.2, 17.8, 20.2, 21.0, 18.6, 20.1, 14.7, 21.1, 20.2, 16.4, 14.7, 18.0, 19.2, 18.7, 18.9, 16.8, 13.0, 20.2, 18.4, 21.2, 14.7, 14.7, 18.9, 21.2, 17.8, 17.8, 16.9, 17.8, 19.6, 14.7, 17.4, 15.9, 20.9, 20.2, 12.6, 14.7, 17.9, 17.9, 16.6, 19.7, 17.8, 21.0, 20.2, 19.2, 16.1, 15.2, 20.2, 15.2, 20.2, 14.7, 19.1, 20.2, 19.1, 17.9, 17.8, 17.4, 21.2, 21.2, 21.2, 18.7, 14.9, 18.3, 21.0, 17.8, 13.0, 17.6, 19.7, 13.0, 20.2, 18.4, 15.2, 18.4, 20.2, 17.6, 17.9, 19.1, 18.5, 18.4, 20.2, 17.3, 16.6, 19.2, 20.2, 13.6, 18.6, 20.9, 17.4, 21.0, 21.0, 22.0, 18.7, 20.2, 21.0, 16.1, 18.6, 20.2, 14.7, 20.2, 19.7, 20.2, 20.2, 17.8, 12.6, 20.2, 20.2, 16.6, 16.6, 20.2, 20.2, 18.4, 20.9, 20.2, 19.0, 15.3, 14.7, 20.2, 19.2, 19.1, 17.4, 19.1, 18.7, 20.2, 20.2, 17.4, 20.2, 20.2, 15.2, 16.1, 20.2, 17.4, 21.0, 17.6, 21.2, 14.8, 14.7, 21.0, 15.2, 20.2, 21.0, 20.2, 18.3, 14.8, 17.0, 16.6, 19.6, 18.4, 19.2, 16.4, 13.0, 21.0, 18.7, 15.3, 20.2, 21.0, 20.2, 17.9, 19.2, 18.3, 20.2, 20.2, 20.2, 14.7, 19.2, 20.2, 16.6, 14.7, 17.9, 20.2, 16.6, 20.2, 19.0, 17.4, 20.2, 17.9, 17.8, 19.6, 19.6, 14.7, 20.2, 18.4, 20.2, 17.4, 18.4, 20.2, 20.1, 19.2, 21.2, 20.2, 20.2, 17.4, 19.2, 20.9, 18.6, 18.6, 19.2, 17.8, 16.0, 18.6, 17.6, 20.2, 17.6, 20.2, 20.2, 14.7, 20.2, 21.0, 16.9, 19.2, 20.2, 20.2, 14.7, 19.1, 16.6, 20.2, 17.0, 14.4, 18.4, 17.8, 13.0, 20.9, 18.4, 17.4, 20.2, 14.7, 19.1, 18.6, 20.2, 16.0, 17.8, 18.4, 20.2, 18.0, 15.2, 20.2, 20.2, 15.9, 20.2, 20.2, 19.7, 18.6, 20.2, 20.2, 20.2, 20.2, 18.4, 19.6, 16.6, 20.2, 20.2, 18.6, 19.1, 20.2, 17.8, 17.8, 14.7, 19.1, 20.2, 14.7, 20.2, 20.2, 17.4, 20.2, 20.2, 17.4, 20.2, 16.6, 20.2, 16.4, 16.0, 20.9, 20.2, 19.7, 20.2, 13.0, 17.9, 20.2, 15.5, 18.4, 14.7, 17.4, 21.0, 20.2, 18.8, 20.9, 22.0, 19.6, 19.1, 18.6, 17.8, 16.6, 21.0, 20.2, 14.7, 14.7, 16.1, 17.4, 14.7], [393.97, 386.85, 375.21, 377.68, 387.89, 348.13, 288.99, 396.9, 396.33, 396.9, 344.05, 396.9, 60.72, 392.23, 297.09, 332.09, 27.49, 396.9, 378.95, 376.94, 396.9, 255.23, 262.76, 393.1, 341.6, 396.9, 396.9, 380.79, 396.9, 385.64, 393.53, 396.06, 395.38, 392.89, 396.9, 354.7, 272.21, 395.99, 383.73, 395.43, 396.9, 396.9, 376.57, 396.9, 395.28, 375.52, 390.43, 393.45, 363.02, 389.15, 387.94, 377.56, 390.95, 393.24, 389.7, 387.31, 385.76, 350.65, 344.91, 7.68, 376.88, 393.25, 395.09, 395.11, 396.9, 48.45, 395.18, 356.99, 396.9, 396.9, 394.12, 396.9, 396.9, 391.93, 100.19, 396.9, 392.11, 227.61, 364.31, 396.9, 395.04, 396.06, 395.56, 368.57, 392.63, 396.9, 88.63, 390.39, 389.96, 391.23, 24.65, 354.31, 396.9, 392.43, 394.46, 390.96, 389.85, 394.95, 360.17, 393.07, 396.9, 383.61, 396.9, 391.98, 382.84, 393.74, 341.6, 396.28, 88.27, 372.49, 389.39, 396.9, 388.45, 388.08, 396.9, 394.67, 386.96, 377.07, 392.33, 395.62, 393.3, 386.86, 396.9, 396.9, 388.37, 2.52, 393.36, 392.52, 396.9, 366.15, 389.25, 383.37, 378.09, 392.3, 396.9, 27.25, 396.9, 396.9, 396.9, 329.46, 395.52, 396.9, 70.8, 376.75, 376.73, 391.99, 376.04, 394.92, 210.97, 306.38, 395.75, 389.43, 370.22, 396.9, 291.55, 390.68, 131.42, 334.4, 388.74, 396.9, 389.71, 393.37, 395.5, 394.62, 18.82, 391.43, 390.7, 393.49, 368.74, 390.64, 396.9, 343.28, 396.9, 396.9, 359.29, 378.35, 390.18, 386.4, 318.75, 396.9, 395.24, 6.68, 396.9, 386.63, 396.9, 396.9, 396.9, 386.75, 387.97, 392.04, 371.58, 393.77, 358.77, 389.71, 396.14, 394.54, 81.33, 370.78, 368.24, 384.46, 372.75, 396.9, 396.3, 396.9, 392.78, 390.3, 396.9, 394.63, 394.72, 396.9, 248.31, 372.92, 396.9, 396.9, 395.62, 109.85, 28.79, 385.96, 391.71, 393.29, 396.9, 396.9, 240.16, 392.74, 314.64, 396.9, 316.03, 396.9, 385.05, 394.81, 385.41, 395.59, 396.9, 391.13, 292.29, 43.06, 395.69, 393.82, 377.51, 395.21, 353.04, 318.43, 390.91, 378.25, 319.98, 354.55, 387.38, 396.9, 392.69, 388.65, 394.87, 377.17, 393.55, 396.9, 381.32, 393.45, 385.09, 396.9, 396.9, 396.9, 392.78, 386.73, 392.53, 394.02, 393.43, 3.5, 10.48, 389.61, 393.74, 395.6, 396.9, 384.3, 394.23, 393.39, 387.11, 384.54, 394.05, 396.42, 372.08, 331.29, 388.45, 370.31, 391.34, 384.97, 392.85, 394.51, 396.9, 396.9, 391.83, 395.6, 396.9, 374.68, 386.34, 22.01, 392.05, 378.08, 390.77, 35.05, 9.32, 68.95, 240.52, 350.45, 396.9, 391.25, 396.9, 376.11, 348.93, 379.38, 396.9, 396.9, 394.12, 172.91, 377.67, 396.9, 338.92, 388.22, 83.45, 390.07, 396.9, 302.76, 360.2, 97.95, 393.23, 355.29, 393.74, 396.9, 394.76, 396.9, 395.11, 50.92, 392.8, 396.9, 396.9, 394.74, 396.9, 369.3, 376.14, 396.9, 21.57, 364.61, 395.24, 382.8, 396.9, 386.09, 393.63, 391.5, 374.71, 303.42, 396.9, 330.04, 374.43, 396.9, 380.34, 261.95], [9.43, 6.58, 7.34, 5.1, 8.1, 12.03, 11.69, 10.74, 6.21, 13.35, 23.97, 13.99, 24.08, 4.59, 11.1, 12.13, 18.05, 5.5, 3.95, 9.88, 18.34, 16.42, 17.31, 19.92, 12.93, 5.98, 16.2, 10.19, 9.45, 10.53, 3.57, 9.1, 3.11, 6.57, 9.22, 7.12, 16.23, 12.86, 6.72, 11.48, 20.85, 4.56, 21.02, 34.41, 7.01, 3.26, 4.86, 6.48, 23.24, 14.37, 12.8, 11.41, 11.28, 8.05, 5.12, 3.76, 11.12, 14.19, 15.76, 24.39, 14.81, 17.27, 18.06, 11.64, 14.8, 22.74, 9.25, 28.32, 4.21, 13.59, 5.21, 13.09, 5.28, 6.9, 16.22, 15.94, 17.19, 12.14, 7.39, 8.79, 12.6, 5.7, 7.56, 9.09, 4.45, 7.2, 16.14, 9.93, 8.65, 15.55, 15.69, 8.61, 26.42, 6.36, 7.44, 5.33, 5.89, 16.21, 22.6, 7.74, 9.68, 8.67, 5.39, 17.12, 4.56, 21.78, 13.28, 5.9, 36.98, 12.5, 9.55, 17.09, 9.54, 24.16, 12.26, 16.96, 10.27, 3.01, 7.79, 8.47, 12.04, 5.91, 7.18, 6.73, 7.26, 23.29, 8.93, 20.45, 5.98, 9.53, 6.05, 5.81, 17.93, 6.53, 7.53, 29.05, 5.77, 7.6, 21.14, 27.38, 3.16, 6.59, 10.63, 10.88, 13.04, 9.67, 5.57, 6.78, 20.08, 17.28, 9.5, 18.06, 23.34, 26.82, 14.1, 6.86, 13.33, 14.13, 10.45, 4.08, 5.68, 14.36, 9.04, 12.4, 14.52, 14.65, 18.33, 13.0, 18.13, 7.51, 4.98, 12.12, 25.68, 14.1, 27.26, 11.65, 9.16, 12.34, 15.02, 17.21, 21.46, 18.71, 34.77, 29.93, 4.67, 16.35, 7.6, 14.67, 4.61, 21.32, 4.74, 7.43, 18.35, 4.69, 8.51, 19.88, 19.69, 5.49, 4.97, 4.5, 11.22, 12.79, 11.72, 3.56, 9.69, 3.16, 9.08, 2.94, 7.85, 15.17, 20.34, 30.62, 14.15, 3.33, 1.98, 23.27, 34.37, 19.52, 29.53, 17.6, 24.56, 14.69, 9.81, 18.8, 26.4, 7.14, 14.0, 5.29, 4.14, 10.56, 4.84, 10.16, 7.7, 11.74, 14.43, 23.98, 9.28, 10.29, 3.92, 10.36, 14.64, 29.68, 5.52, 16.9, 15.7, 5.29, 3.13, 8.77, 12.33, 13.0, 10.97, 7.54, 8.2, 15.84, 14.66, 4.16, 17.27, 3.53, 23.69, 14.76, 3.81, 18.85, 13.83, 12.43, 10.13, 16.94, 19.01, 1.92, 6.56, 6.29, 14.7, 4.45, 2.97, 7.9, 13.15, 7.44, 16.47, 11.5, 6.36, 21.32, 3.32, 25.41, 13.65, 22.98, 7.39, 10.3, 6.47, 9.29, 11.34, 12.43, 13.44, 11.66, 3.11, 17.15, 2.96, 14.44, 6.58, 21.22, 26.45, 34.02, 23.79, 12.64, 6.15, 11.38, 30.59, 20.31, 29.55, 17.58, 37.97, 5.04, 4.82, 27.8, 14.27, 31.99, 5.5, 11.45, 17.64, 4.73, 26.77, 24.1, 8.05, 12.03, 10.11, 17.73, 10.5, 6.27, 9.42, 23.6, 13.15, 18.13, 9.59, 10.21, 22.88, 5.49, 4.54, 3.7, 5.25, 18.72, 25.79, 12.67, 12.27, 8.05, 6.87, 3.53, 9.47, 13.61, 5.19, 16.51, 19.37, 11.32, 1.73, 10.24, 3.76, 15.79]], DataFrames.Index(Dict(:Zn => 2,:Rad => 8,:Tax => 9,:LStat => 12,:Rm => 5,:Age => 6,:NOx => 4,:Indus => 3,:Dis => 7,:PTRatio => 10,:Crim => 1,:Black => 11), [:Crim, :Zn, :Indus, :NOx, :Rm, :Age, :Dis, :Rad, :Tax, :PTRatio, :Black, :LStat])), [20.5, 23.1, 22.6, 37.0, 36.5, 19.1, 20.2, 23.0, 25.0, 20.1, 7.0, 19.5, 9.5, 35.4, 23.8, 27.9, 9.6, 23.6, 48.3, 21.7, 14.3, 16.4, 15.6, 8.5, 20.1, 22.9, 19.4, 20.8, 36.2, 17.5, 43.8, 20.3, 42.3, 21.9, 19.6, 27.5, 14.9, 22.5, 24.2, 22.7, 11.5, 34.9, 13.6, 14.4, 25.0, 50.0, 33.1, 22.0, 13.9, 22.0, 18.4, 20.0, 18.2, 33.0, 50.0, 45.4, 23.0, 19.9, 18.3, 8.3, 16.6, 21.7, 15.2, 22.7, 18.9, 8.4, 20.9, 17.8, 38.7, 24.5, 28.7, 17.4, 25.0, 30.1, 14.3, 19.8, 16.2, 23.8, 23.3, 20.9, 19.2, 28.7, 39.8, 19.8, 50.0, 23.8, 13.1, 27.5, 16.5, 19.4, 10.2, 30.3, 15.6, 23.1, 24.7, 29.4, 26.6, 18.8, 12.7, 23.7, 18.9, 26.4, 34.9, 13.1, 29.8, 10.2, 19.6, 24.4, 7.0, 17.6, 21.2, 18.7, 25.1, 14.0, 19.6, 18.1, 20.8, 46.0, 18.6, 19.9, 21.2, 48.8, 23.9, 22.2, 43.1, 13.4, 28.4, 15.0, 22.1, 50.0, 33.2, 25.3, 20.5, 26.6, 28.2, 7.2, 24.7, 22.3, 19.7, 8.5, 50.0, 25.2, 18.6, 24.0, 14.5, 22.4, 20.6, 24.1, 16.3, 14.8, 22.0, 22.5, 11.9, 13.4, 20.8, 23.3, 23.1, 19.9, 18.5, 33.3, 22.2, 23.2, 23.6, 20.1, 10.9, 17.7, 17.8, 21.7, 19.1, 22.9, 24.0, 15.3, 9.7, 18.3, 15.7, 24.3, 24.3, 21.2, 16.7, 10.4, 21.7, 14.9, 13.8, 16.5, 23.5, 12.7, 30.1, 17.5, 31.2, 13.3, 29.0, 24.1, 13.1, 30.5, 20.6, 14.5, 14.1, 24.1, 22.5, 30.1, 22.2, 22.2, 19.4, 37.3, 28.7, 43.5, 20.6, 33.4, 32.2, 13.8, 13.5, 10.2, 20.0, 28.5, 34.9, 13.4, 17.9, 17.1, 14.6, 23.1, 12.3, 23.1, 25.0, 16.6, 17.2, 23.2, 21.9, 28.0, 44.8, 18.5, 26.6, 22.8, 20.4, 18.5, 17.4, 11.8, 23.8, 20.2, 46.7, 23.1, 16.8, 8.1, 22.8, 17.4, 14.2, 21.9, 37.6, 21.0, 20.1, 21.1, 24.4, 23.4, 22.0, 20.3, 24.4, 33.1, 16.1, 32.4, 13.1, 20.1, 48.5, 15.4, 19.6, 17.1, 24.7, 13.5, 12.7, 50.0, 26.2, 24.6, 20.0, 32.9, 50.0, 21.6, 29.6, 50.0, 19.5, 16.2, 31.6, 19.1, 50.0, 17.3, 20.7, 5.0, 27.1, 19.2, 33.4, 18.7, 21.4, 22.9, 15.0, 29.8, 44.0, 19.0, 50.0, 16.0, 35.2, 17.2, 8.7, 8.4, 10.8, 16.1, 23.0, 22.0, 5.0, 12.1, 23.7, 18.8, 13.8, 37.2, 37.9, 13.8, 20.3, 7.4, 27.0, 20.6, 14.5, 31.5, 5.6, 13.3, 29.0, 16.1, 23.2, 15.2, 23.0, 28.6, 27.5, 11.3, 18.7, 14.1, 33.8, 19.3, 12.8, 32.7, 22.8, 50.0, 31.7, 15.2, 7.5, 17.2, 19.8, 18.2, 23.1, 29.6, 25.0, 19.3, 23.7, 13.9, 12.5, 22.3, 50.0, 19.4, 31.5, 19.4]), #undef, #undef)</code></pre>
<p>dataset is small enough and the lower and upper sets the tree to have certain number of leaves</p>
<pre><code class="language-julia">leaf_range = range(lgb, :min_data_in_leaf, lower=1, upper=50)


curve = learning_curve!(lgbm, resampling=CV(nfolds=5),
                        range=leaf_range, resolution=50,
                        measure=rms)

figure(figsize=(8,6))
plot(curve.parameter_values, curve.measurements)
xlabel("Min data in leaf", fontsize=14)
ylabel("RMSE", fontsize=14)</code></pre>
<img src="/assets/end-to-end/boston-lgbm/code/output/lgbm_hp3.svg" alt="">
<p>It does not seem like there is a huge risk for overfitting, and lower is better for this parameter.</p>
<p>Using the learning curves above we can select some small-ish ranges to jointly search for the best combinations of these parameters via cross validation.</p>
<pre><code class="language-julia">r1 = range(lgb, :num_iterations, lower=50, upper=100)
r2 = range(lgb, :min_data_in_leaf, lower=2, upper=10)
r3 = range(lgb, :learning_rate, lower=1e-1, upper=1e0)
tm = TunedModel(model=lgb, tuning=Grid(resolution=5),
                resampling=CV(rng=StableRNG(123)), ranges=[r1,r2,r3],
                measure=rms)
mtm = machine(tm, features, targets)
fit!(mtm, rows=train);</code></pre>
<p>Lets see what the cross validation best model parameters turned out to be?</p>
<pre><code class="language-julia">best_model = fitted_params(mtm).best_model
@show best_model.learning_rate
@show best_model.min_data_in_leaf
@show best_model.num_iterations</code></pre><pre><code class="plaintext">best_model.learning_rate = 0.1
best_model.min_data_in_leaf = 4
best_model.num_iterations = 100
</code></pre>
<p>Great, and now let&#39;s predict using the held out data.</p>
<pre><code class="language-julia">predictions = predict(mtm, rows=test)
rms_score = round(rms(predictions, targets[test, 1]), sigdigits=4)

@show rms_score</code></pre><pre><code class="plaintext">rms_score = 3.456
</code></pre><div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom and collaborators. Last modified: May 24, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/libs/pure/ui.min.js"></script>
  
  
      <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
