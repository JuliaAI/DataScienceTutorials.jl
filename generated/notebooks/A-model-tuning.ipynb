{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the environment\n",
    "corresponding to [this `Project.toml`](https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/master/Project.toml) and [this `Manifest.toml`](https://raw.githubusercontent.com/alan-turing-institute/MLJTutorials/master/Manifest.toml)\n",
    "so that you get an environment which matches the one used to generate the tutorials:\n",
    "\n",
    "```julia\n",
    "cd(\"MLJTutorials\") # cd to folder with the *.toml\n",
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "[MLJ.jl]: https://github.com/alan-turing-institute/MLJ.jl\n",
    "[RDatasets.jl]: https://github.com/JuliaStats/RDatasets.jl\n",
    "[NearestNeighbors.jl]: https://github.com/KristofferC/NearestNeighbors.jl\n",
    "\n",
    "## Tuning a single hyperparameter\n",
    "\n",
    "In MLJ, tuning is implemented as a model wrapper.\n",
    "After wrapping a model in a _tuning strategy_ (e.g. cross-validation) and binding the wrapped model to data in a _machine_, fitting the machine initiates a search for optimal model hyperparameters.\n",
    "\n",
    "Let's use a decision tree classifier and tune the maximum depth of the tree.\n",
    "As usual, start by loading data and the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ, PrettyPrinting\n",
    "MLJ.color_off() # hide\n",
    "X, y = @load_iris\n",
    "@load DecisionTreeClassifier"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Specifying a range of value\n",
    "\n",
    "To specify a range of value, you can use the `range` function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "r   = range(dtc, :max_depth, lower=1, upper=5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "As you can see, the range function takes a model (`dtc`), a symbol for the hyperparameter of interest (`:max_depth`) and indication of how to samples values.\n",
    "For hyperparameters of type `<:Real`, you should specify a range of values as done above.\n",
    "For hyperparameters of other type (e.g. `Symbol`), you should use the `values=...` keyword.\n",
    "\n",
    "Once a range of values has been defined, you can then wrap the model in a `TunedModel` specifying the tuning strategy:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tm = TunedModel(model=dtc, ranges=[r, ], measure=cross_entropy)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Fitting and inspecting a tuned model\n",
    "\n",
    "To fit a tuned model, you can use the usual syntax:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m = machine(tm, X, y)\n",
    "fit!(m)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "In order to inspect the best model, you can use the function `fitted_params` on the machine and inspect the `best_model` field:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fitted_params(m).best_model.max_depth"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Note that here we have tuned a probabilistic model and consequently used a probabilistic measure for the tuning.\n",
    "We could also have decided we only cared about the mode and the misclassification rate, to do this, just use `operation=predict_mode` in the tuned model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tm = TunedModel(model=dtc, ranges=r, operation=predict_mode,\n",
    "                measure=misclassification_rate)\n",
    "m = machine(tm, X, y)\n",
    "fit!(m)\n",
    "fitted_params(m).best_model.max_depth"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's check the misclassification rate for the best model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = report(m)\n",
    "r.best_result"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Anyone wants plots? of course:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using PyPlot\n",
    "figure(figsize=(8,6))\n",
    "res = r.plotting # contains all you need for plotting\n",
    "plot(res.parameter_values, res.measurements, ls=\"none\", marker=\"o\")\n",
    "\n",
    "xticks(1:5, fontsize=12)\n",
    "yticks(fontsize=12)\n",
    "xlabel(\"Maximum depth\", fontsize=14)\n",
    "ylabel(\"Misclassification rate\", fontsize=14)\n",
    "ylim([0, 1])\n",
    "\n",
    "savefig(joinpath(@OUTPUT, \"A-model-tuning-hpt.svg\")) # hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "\\figalt{hyperparameter heatmap}{A-model-tuning-hpt}"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Tuning nested hyperparameters"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's generate simple dummy regression data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = (x1=rand(100), x2=rand(100), x3=rand(100))\n",
    "y = 2X.x1 - X.x2 + 0.05 * randn(100);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's then build a simple ensemble model with decision tree regressors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dtr = @load DecisionTreeRegressor\n",
    "forest = EnsembleModel(atom=dtr)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Such a model has *nested* hyperparameters in that the ensemble has hyperparameters (e.g. the `:bagging_fraction`) and the atom has hyperparameters (e.g. `:n_subfeatures` or `:max_depth`).\n",
    "You can see this by inspecting the parameters using `params`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "params(forest) |> pprint"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Range for nested hyperparameters are specified using dot syntax, the rest is done in much the same way as before:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r1 = range(forest, :(atom.n_subfeatures), lower=1, upper=3)\n",
    "r2 = range(forest, :bagging_fraction, lower=0.4, upper=1.0)\n",
    "tm = TunedModel(model=forest, tuning=Grid(resolution=12),\n",
    "                resampling=CV(nfolds=6), ranges=[r1, r2],\n",
    "                measure=rms)\n",
    "m = machine(tm, X, y)\n",
    "fit!(m);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "A useful function to inspect a model after fitting it is the `report` function which collects information on the model and the tuning, for instance you can use it to recover the best measurement:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = report(m)\n",
    "r.best_result"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Let's visualise this"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "figure(figsize=(8,6))\n",
    "\n",
    "res = r.plotting\n",
    "\n",
    "vals_sf = res.parameter_values[:, 1]\n",
    "vals_bf = res.parameter_values[:, 2]\n",
    "\n",
    "tricontourf(vals_sf, vals_bf, res.measurements)\n",
    "xlabel(\"Number of sub-features\", fontsize=14)\n",
    "ylabel(\"Bagging fraction\", fontsize=14)\n",
    "xticks([1, 2, 3], fontsize=12)\n",
    "yticks(fontsize=12)\n",
    "\n",
    "savefig(joinpath(@OUTPUT, \"A-model-tuning-hm.svg\")) # hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "\\figalt{Hyperparameter heatmap}{A-model-tuning-hm.svg}"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "PyPlot.close_figs() # hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0-DEV.350"
  },
  "kernelspec": {
   "name": "julia-1.5",
   "display_name": "Julia 1.5.0-DEV.350",
   "language": "julia"
  }
 },
 "nbformat": 4
}
