{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the environment\n",
    "corresponding to [this `Project.toml`](https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/master/Project.toml) and [this `Manifest.toml`](https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/master/Manifest.toml)\n",
    "so that you get an environment which matches the one used to generate the tutorials:\n",
    "\n",
    "```julia\n",
    "cd(\"DataScienceTutorials\") # cd to folder with the *.toml\n",
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Main author**: [Clarman Cruz](https://github.com/drcxcruz).\n",
    "\n",
    "This juypter lab showcases MLJ in particular using the popular [GLM](https://github.com/JuliaStats/GLM.jl) Julia package. We are using two datasets.  One dataset was created manually for testing purposes.  The other data set is the CollegeDistance dataset from the [AER](https://cran.r-project.org/web/packages/AER/index.html) package in R.\n",
    "\n",
    "We can quickly define our models in MLJ and study their results.  It is very easy and consistent."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ, CategoricalArrays, PrettyPrinting\n",
    "import DataFrames: DataFrame, nrow\n",
    "using UrlDownload\n",
    "@load LinearRegressor pkg = GLM\n",
    "@load LinearBinaryClassifier pkg=GLM"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading the data\n",
    "\n",
    "The CollegeDistance dataset was stored in a CSV file.  Here, we read the input file."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "baseurl = \"https://raw.githubusercontent.com/tlienart/DataScienceTutorialsData.jl/master/data/glm/\"\n",
    "\n",
    "dfX = DataFrame(urldownload(baseurl * \"X3.csv\"))\n",
    "dfYbinary = DataFrame(urldownload(baseurl * \"Y3.csv\"))\n",
    "dfX1 = DataFrame(urldownload(baseurl * \"X1.csv\"))\n",
    "dfY1 = DataFrame(urldownload(baseurl * \"Y1.csv\"));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can have a look at those using `first`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "first(dfX, 3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "same for Y:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "first(dfY1, 3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Linear Model\n",
    "\n",
    "Let see how many MLJ models handle our kind of target which is the y variable."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ms = models() do m\n",
    "    AbstractVector{Count} <: m.target_scitype\n",
    "end\n",
    "foreach(m -> println(m.name), ms)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "How about if the type was Continuous:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ms = models() do m\n",
    "    Vector{Continuous} <: m.target_scitype\n",
    "end\n",
    "foreach(m -> println(m.name), ms)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can quickly define our models in MLJ.  It is very easy and consistent."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = copy(dfX1)\n",
    "y = copy(dfY1)\n",
    "\n",
    "coerce!(X, autotype(X, :string_to_multiclass))\n",
    "yv = Vector(y[:, 1])\n",
    "\n",
    "LinearRegressorPipe = @pipeline(Standardizer(),\n",
    "                                OneHotEncoder(drop_last = true),\n",
    "                                LinearRegressor())\n",
    "\n",
    "LinearModel = machine(LinearRegressorPipe, X, yv)\n",
    "fit!(LinearModel)\n",
    "fp = fitted_params(LinearModel)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading the Output of Fitting the Linear Model\n",
    "\n",
    "We can quickly read the results of our models in MLJ.  Remember to compute the accuracy of the linear model."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ŷ = MLJ.predict(LinearModel, X)\n",
    "yhatResponse = [ŷ[i,1].μ for i in 1:nrow(y)]\n",
    "residuals = y .- yhatResponse\n",
    "r = report(LinearModel)\n",
    "\n",
    "k = collect(keys(fp.fitted_params_given_machine))[3]\n",
    "println(\"\\n Coefficients:  \", fp.fitted_params_given_machine[k].coef)\n",
    "println(\"\\n y \\n \", y[1:5,1])\n",
    "println(\"\\n ŷ \\n \", ŷ[1:5])\n",
    "println(\"\\n yhatResponse \\n \", yhatResponse[1:5])\n",
    "println(\"\\n Residuals \\n \", y[1:5,1] .- yhatResponse[1:5])\n",
    "println(\"\\n Standard Error per Coefficient \\n\", r.report_given_machine[k].stderror)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and get the accuracy"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "round(rms(yhatResponse, y[:,1]), sigdigits=4)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Logistic Model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = copy(dfX)\n",
    "y = copy(dfYbinary)\n",
    "\n",
    "coerce!(X, autotype(X, :string_to_multiclass))\n",
    "yc = CategoricalArray(y[:, 1])\n",
    "yc = coerce(yc, OrderedFactor)\n",
    "\n",
    "LinearBinaryClassifierPipe = @pipeline(Standardizer(),\n",
    "                                       OneHotEncoder(drop_last = true),\n",
    "                                       LinearBinaryClassifier())\n",
    "\n",
    "LogisticModel = machine(LinearBinaryClassifierPipe, X, yc)\n",
    "fit!(LogisticModel)\n",
    "fp = fitted_params(LogisticModel)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading the Output from the Prediction of the Logistic Model\n",
    "\n",
    "The output of the MLJ model basically contain the same information as the R version of the model."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ŷ = MLJ.predict(LogisticModel, X)\n",
    "residuals = [1 - pdf(ŷ[i], y[i,1]) for i in 1:nrow(y)]\n",
    "r = report(LogisticModel)\n",
    "\n",
    "k = collect(keys(fp.fitted_params_given_machine))[3]\n",
    "println(\"\\n Coefficients:  \", fp.fitted_params_given_machine[k].coef)\n",
    "println(\"\\n y \\n \", y[1:5,1])\n",
    "println(\"\\n ŷ \\n \", ŷ[1:5])\n",
    "println(\"\\n residuals \\n \", residuals[1:5])\n",
    "println(\"\\n Standard Error per Coefficient \\n\", r.report_given_machine[k].stderror)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "No logistic analysis is complete without the confusion matrix:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "yMode = [mode(ŷ[i]) for i in 1:length(ŷ)]\n",
    "y = coerce(y[:,1], OrderedFactor)\n",
    "yMode = coerce(yMode, OrderedFactor)\n",
    "confusion_matrix(yMode, y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  },
  "kernelspec": {
   "name": "julia-1.4",
   "display_name": "Julia 1.4.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
