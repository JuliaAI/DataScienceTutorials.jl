{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before running this, please make sure to activate and instantiate the environment\n",
    "corresponding to [this `Project.toml`](https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/master/Project.toml) and [this `Manifest.toml`](https://raw.githubusercontent.com/alan-turing-institute/DataScienceTutorials.jl/master/Manifest.toml)\n",
    "so that you get an environment which matches the one used to generate the tutorials:\n",
    "\n",
    "```julia\n",
    "cd(\"DataScienceTutorials\") # cd to folder with the *.toml\n",
    "using Pkg; Pkg.activate(\".\"); Pkg.instantiate()\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Main author**: [Ashrya Agrawal](https://github.com/ashryaagr).\n",
    "\n",
    "## Getting started\n",
    "Here we use the [UCI \"Airfoil Self-Noise\" dataset](http://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise)\n",
    "### Loading and  preparing the data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "using PrettyPrinting\n",
    "import DataFrames\n",
    "import Statistics\n",
    "using CSV\n",
    "using PyPlot\n",
    "using HTTP\n",
    "using StableRNGs\n",
    "\n",
    "\n",
    "req = HTTP.get(\"https://raw.githubusercontent.com/rupakc/UCI-Data-Analysis/master/Airfoil%20Dataset/airfoil_self_noise.dat\");\n",
    "\n",
    "df = CSV.read(req.body; header=[\n",
    "                  \"Frequency\",\"Attack_Angle\",\"Chord+Length\",\n",
    "                  \"Free_Velocity\",\"Suction_Side\",\"Scaled_Sound\"\n",
    "              ]\n",
    "       );\n",
    "df[1:5, :] |> pretty"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "inspect the schema:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "unpack into the data and labels:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(df, ==(:Scaled_Sound), col -> true);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we Standardize the features using the transformer Standardizer()"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = transform(fit!(machine(Standardizer(), X)), X);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Partition into train and test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=true, rng=StableRNG(612));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's first see which models are compatible with the scientific type and machine type of our data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for model in models(matching(X, y))\n",
    "       print(\"Model Name: \" , model.name , \" , Package: \" , model.package_name , \"\\n\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that if we coerce `X.Frequency` to `Continuous`, many more models are available:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(X, :Frequency=>Continuous)\n",
    "\n",
    "for model in models(matching(X, y))\n",
    "       print(\"Model Name: \" , model.name , \" , Package: \" , model.package_name , \"\\n\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DecisionTreeRegressor\n",
    "\n",
    "We will first try out DecisionTreeRegressor:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dcr = @load DecisionTreeRegressor pkg=DecisionTree\n",
    "\n",
    "dcrm = machine(dcr, X, y)\n",
    "\n",
    "fit!(dcrm, rows=train)\n",
    "pred_dcrm = MLJ.predict(dcrm, rows=test);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you can call a loss function to assess the performance on test set."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rms(pred_dcrm, y[test])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RandomForestRegressor\n",
    "\n",
    "Now let's try out RandomForestRegressor:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rfr = @load RandomForestRegressor pkg=DecisionTree\n",
    "\n",
    "rfr_m = machine(rfr, X, y);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "train on the rows corresponding to train"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(rfr_m, rows=train);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "predict values on the rows corresponding to test"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pred_rfr = MLJ.predict(rfr_m, rows=test);\n",
    "rms(pred_rfr, y[test])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unsurprisingly, the RandomForestRegressor does a better job.\n",
    "\n",
    "Can we do even better? Yeah, we can!! We can make use of Model Tuning.\n",
    "\n",
    "## Tuning\n",
    "\n",
    "In case you are new to model tuning using MLJ, refer [lab5](https://alan-turing-institute.github.io/DataScienceTutorials.jl/isl/lab-5/) and [model-tuning](https://alan-turing-institute.github.io/DataScienceTutorials.jl/getting-started/model-tuning/)\n",
    "\n",
    "Range of values for parameters should be specified to do hyperparameter tuning"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r_maxD = range(rfr, :n_trees, lower=9, upper=15)\n",
    "r_samF = range(rfr, :sampling_fraction, lower=0.6, upper=0.8)\n",
    "r = [r_maxD, r_samF];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we specify how the tuning should be done. Let's just specify a coarse grid tuning with cross validation and instantiate a tuned model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuning = Grid(resolution=7)\n",
    "resampling = CV(nfolds=6)\n",
    "\n",
    "tm = TunedModel(model=rfr, tuning=tuning,\n",
    "                resampling=resampling, ranges=r, measure=rms)\n",
    "\n",
    "rfr_tm = machine(tm, X, y);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "train on the rows corresponding to train"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(rfr_tm, rows=train);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "predict values on the rows corresponding to test"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pred_rfr_tm = MLJ.predict(rfr_tm, rows=test);\n",
    "rms(pred_rfr_tm, y[test])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "That was great! We have further improved the accuracy\n",
    "\n",
    "Now to retrieve best model, You can use"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fitted_params(rfr_tm).best_model"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can investigate the tuning by using report.\n",
    "Let's plot a heatmap of the measurements:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = report(rfr_tm)\n",
    "res = r.plotting\n",
    "\n",
    "md = res.parameter_values[:,1]\n",
    "mcw = res.parameter_values[:,2]\n",
    "\n",
    "figure(figsize=(8,6))\n",
    "tricontourf(md, mcw, res.measurements)\n",
    "\n",
    "xlabel(\"Number of trees\", fontsize=14)\n",
    "ylabel(\"Sampling fraction\", fontsize=14)\n",
    "xticks(9:1:15, fontsize=12)\n",
    "yticks(fontsize=12)\n"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\figalt{Hyperparameter heatmap}{airfoil_heatmap.svg}"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  },
  "kernelspec": {
   "name": "julia-1.4",
   "display_name": "Julia 1.4.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
