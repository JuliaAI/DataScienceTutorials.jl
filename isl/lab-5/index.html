<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/DataScienceTutorials.jl/libs/highlight/github.min.css">
 
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/franklin.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/pure.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/side-menu.css">
  <link rel="stylesheet" href="/DataScienceTutorials.jl/css/extra.css">
  <!-- <link rel="icon" href="/DataScienceTutorials.jl/assets/infra/favicon.gif"> -->
   <title>Lab 5 - Cross validation and the bootstrap</title>  
  <!-- LUNR -->
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr.min.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunr_index.js"></script>
  <script src="/DataScienceTutorials.jl/libs/lunr/lunrclient.min.js"></script>
</head>
<body>
  <div id="layout">
    <!-- Menu toggle / hamburger icon -->
    <a href="#menu" id="menuLink" class="menu-link"><span></span></a>
    <div id="menu">
      <div class="pure-menu">
        <a href="/DataScienceTutorials.jl/" id="menu-logo-link">
          <div class="menu-logo">
            <!-- <img id="menu-logo" alt="MLJ Logo" src="/DataScienceTutorials.jl/assets/infra/MLJLogo2.svg" /> -->
            <p><strong>Data Science Tutorials</strong></p>
          </div>
        </a>
        <form id="lunrSearchForm" name="lunrSearchForm">
          <input class="search-input" name="q" placeholder="Enter search term" type="text">
          <input type="submit" value="Search" formaction="/DataScienceTutorials.jl/search/index.html" style="visibility:hidden">
        </form>
  <!-- LIST OF MENU ITEMS -->
  <ul class="pure-menu-list">
    <li class="pure-menu-item pure-menu-top-item "><a href="/DataScienceTutorials.jl/" class="pure-menu-link"><strong>Home</strong></a></li>

    <!-- DATA BASICS -->
    <li class="pure-menu-sublist-title"><strong>Data basics</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/loading/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Loading data</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/dataframe/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data Frames</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/categorical/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Categorical Arrays</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/scitype/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Scientific Type</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/data/processing/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Data processing</a></li>
    </ul>

    <!-- GETTING STARTED WITH MLJ -->
    <li class="pure-menu-sublist-title"><strong>Getting started</strong></li>
    <ul class="pure-menu-sublist">
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/choosing-a-model/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Choosing a model</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/fit-and-predict/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Fit, predict, transform</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/model-tuning/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Model tuning</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/ensembles-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Ensembles (3)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/composing-models/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Composing models</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/learning-networks-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Learning networks (2)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/getting-started/stacking/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Stacking</a></li>
    </ul>

    <!-- INTRO TO STATS LEARNING -->
    <li class="pure-menu-sublist-title"><strong>Intro to Stats Learning</strong></li>
    <ul class="pure-menu-sublist" id=isl>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-2/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 2</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-3/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 3</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-4/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 4</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-5/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 5</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-6b/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 6b</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-8/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 8</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-9/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 9</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/isl/lab-10/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Lab 10</a></li>
    </ul>

    <!-- END TO END EXAMPLES -->
    <li class="pure-menu-sublist-title"><strong>End to end examples</strong></li>
    <ul class="pure-menu-sublist" id=e2e>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/AMES/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> AMES</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/wine/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Wine</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/crabs-xgb/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Crabs (XGB)</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/horse/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Horse</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/HouseKingCounty/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> King County Houses</a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/airfoil" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Airfoil </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-lgbm" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (lgbm) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/glm/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Using GLM.jl </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/powergen/" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Power Generation </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/boston-flux" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Boston (Flux) </a></li>
      <li class="pure-menu-item "><a href="/DataScienceTutorials.jl/end-to-end/breastcancer" class="pure-menu-link"><span style="padding-right:0.5rem;">•</span> Breast Cancer</a></li>
    </ul>
  </ul>
  <!-- END OF LIST OF MENU ITEMS -->
      </div>
    </div>
    <div id="main"> <!-- Closed in foot -->
      

<!-- Content appended here -->
<div class="franklin-content"><h1 id="lab_5_-_cross_validation_and_the_bootstrap"><a href="#lab_5_-_cross_validation_and_the_bootstrap" class="header-anchor">Lab 5 - Cross validation and the bootstrap</a></h1>
<em>Download the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-5/tutorial.ipynb" target="_blank"><em>notebook</em></a>
  , the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-5/tutorial.jl" target="_blank"><em>annotated script</em></a>
   or the 
  <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-5/tutorial-raw.jl" target="_blank"><em>raw script</em></a>
   for this tutorial &#40;right-click on the relevant link and save-as&#41;. These rely on <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-5/Project.toml">this Project.toml</a> and <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-5/Manifest.toml">this Manifest.toml</a>.</em> <br/>   <em>You can also download the whole <a href="https://raw.githubusercontent.com/juliaai/DataScienceTutorials.jl/gh-pages/__generated/ISL-lab-5.tar.gz">project folder</a>.</em> <div class="franklin-toc"><ol><li><a href="#getting_started">Getting started</a><ol><li><a href="#polynomial_regression">Polynomial regression</a></li></ol></li><li><a href="#k-folds_cross_validation">K-Folds Cross Validation</a></li><li><a href="#the_bootstrap">The Bootstrap</a></li></ol></div>
<h2 id="getting_started"><a href="#getting_started" class="header-anchor">Getting started</a></h2>
<pre><code class="language-julia">using MLJ
import RDatasets: dataset
import DataFrames: DataFrame, select
auto &#61; dataset&#40;&quot;ISLR&quot;, &quot;Auto&quot;&#41;
y, X &#61; unpack&#40;auto, &#61;&#61;&#40;:MPG&#41;, col-&gt;true&#41;
train, test &#61; partition&#40;eachindex&#40;y&#41;, 0.5, shuffle&#61;true, rng&#61;444&#41;;</code></pre>
<p>Note the use of <code>rng&#61;</code> to seed the shuffling of indices so that the results are reproducible.</p>
<h3 id="polynomial_regression"><a href="#polynomial_regression" class="header-anchor">Polynomial regression</a></h3>
<pre><code class="language-julia">LR &#61; @load LinearRegressor pkg&#61;MLJLinearModels</code></pre><pre><code class="plaintext code-output">import MLJLinearModels ✔
MLJLinearModels.LinearRegressor</code></pre>
<p>In this part we only build models with the <code>Horsepower</code> feature.</p>
<pre><code class="language-julia">using PyPlot

figure&#40;figsize&#61;&#40;8,6&#41;&#41;
plot&#40;X.Horsepower, y, ls&#61;&quot;none&quot;, marker&#61;&quot;o&quot;&#41;

xlabel&#40;&quot;Horsepower&quot;, fontsize&#61;14&#41;
xticks&#40;50:50:250, fontsize&#61;12&#41;
yticks&#40;10:10:50, fontsize&#61;12&#41;
ylabel&#40;&quot;MPG&quot;, fontsize&#61;14&#41;</code></pre>
<img src="/DataScienceTutorials.jl/assets/isl/lab-5/code/output/ISL-lab-5-g1.svg" alt="MPG v Horsepower">
<p>Let&#39;s get a baseline:</p>
<pre><code class="language-julia">lm &#61; LR&#40;&#41;
mlm &#61; machine&#40;lm, select&#40;X, :Horsepower&#41;, y&#41;
fit&#33;&#40;mlm, rows&#61;train&#41;
rms&#40;MLJ.predict&#40;mlm, rows&#61;test&#41;, y&#91;test&#93;&#41;^2</code></pre><pre><code class="plaintext code-output">23.493990895007986</code></pre>
<p>Note that we square the measure to  match the results obtained in the ISL labs where the mean squared error &#40;here we use the <code>rms</code> which is the square root of that&#41;.</p>
<pre><code class="language-julia">xx &#61; &#40;Horsepower&#61;range&#40;50, 225, length&#61;100&#41; |&gt; collect, &#41;
yy &#61; MLJ.predict&#40;mlm, xx&#41;

figure&#40;figsize&#61;&#40;8,6&#41;&#41;
plot&#40;X.Horsepower, y, ls&#61;&quot;none&quot;, marker&#61;&quot;o&quot;&#41;
plot&#40;xx.Horsepower, yy, lw&#61;3&#41;

xlabel&#40;&quot;Horsepower&quot;, fontsize&#61;14&#41;
xticks&#40;50:50:250, fontsize&#61;12&#41;
yticks&#40;10:10:50, fontsize&#61;12&#41;
ylabel&#40;&quot;MPG&quot;, fontsize&#61;14&#41;</code></pre>
<img src="/DataScienceTutorials.jl/assets/isl/lab-5/code/output/ISL-lab-5-g2.svg" alt="1st order baseline">
<p>We now want to build three polynomial models of degree 1, 2 and 3 respectively; we start by forming the corresponding feature matrix:</p>
<pre><code class="language-julia">hp &#61; X.Horsepower
Xhp &#61; DataFrame&#40;hp1&#61;hp, hp2&#61;hp.^2, hp3&#61;hp.^3&#41;;</code></pre>
<p>Now we  can write a simple pipeline where the first step selects the features we want &#40;and with it the degree of the polynomial&#41; and the second is the linear regressor:</p>
<pre><code class="language-julia">LinMod &#61; @pipeline&#40;FeatureSelector&#40;features&#61;&#91;:hp1&#93;&#41;,
                   LR&#40;&#41;&#41;;</code></pre>
<p>Then we can  instantiate and fit 3 models where we specify the features each time:</p>
<pre><code class="language-julia">lr1 &#61; machine&#40;LinMod, Xhp, y&#41; # poly of degree 1 &#40;line&#41;
fit&#33;&#40;lr1, rows&#61;train&#41;

LinMod.feature_selector.features &#61; &#91;:hp1, :hp2&#93; # poly of degree 2
lr2 &#61; machine&#40;LinMod, Xhp, y&#41;
fit&#33;&#40;lr2, rows&#61;train&#41;

LinMod.feature_selector.features &#61; &#91;:hp1, :hp2, :hp3&#93; # poly of degree 3
lr3 &#61; machine&#40;LinMod, Xhp, y&#41;
fit&#33;&#40;lr3, rows&#61;train&#41;</code></pre><pre><code class="plaintext code-output">Machine{Pipeline323,…} @034 trained 1 time; caches data
  args: 
    1:	Source @106 ⏎ `ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}`
    2:	Source @303 ⏎ `AbstractVector{ScientificTypesBase.Continuous}`
</code></pre>
<p>Let&#39;s check the performances on the test set</p>
<pre><code class="language-julia">get_mse&#40;lr&#41; &#61; rms&#40;MLJ.predict&#40;lr, rows&#61;test&#41;, y&#91;test&#93;&#41;^2

@show get_mse&#40;lr1&#41;
@show get_mse&#40;lr2&#41;
@show get_mse&#40;lr3&#41;</code></pre><pre><code class="plaintext code-output">get_mse(lr1) = 23.493990895007986
get_mse(lr2) = 19.287175510952153
get_mse(lr3) = 19.381831638657914
</code></pre>
<p>Let&#39;s visualise the models</p>
<pre><code class="language-julia">hpn  &#61; xx.Horsepower
Xnew &#61; DataFrame&#40;hp1&#61;hpn, hp2&#61;hpn.^2, hp3&#61;hpn.^3&#41;

yy1 &#61; MLJ.predict&#40;lr1, Xnew&#41;
yy2 &#61; MLJ.predict&#40;lr2, Xnew&#41;
yy3 &#61; MLJ.predict&#40;lr3, Xnew&#41;

figure&#40;figsize&#61;&#40;8,6&#41;&#41;
plot&#40;X.Horsepower, y, ls&#61;&quot;none&quot;, marker&#61;&quot;o&quot;&#41;
plot&#40;xx.Horsepower, yy1, lw&#61;3, label&#61;&quot;Order 1&quot;&#41;
plot&#40;xx.Horsepower, yy2, lw&#61;3, label&#61;&quot;Order 2&quot;&#41;
plot&#40;xx.Horsepower, yy3, lw&#61;3, label&#61;&quot;Order 3&quot;&#41;

legend&#40;fontsize&#61;14&#41;

xlabel&#40;&quot;Horsepower&quot;, fontsize&#61;14&#41;
xticks&#40;50:50:250, fontsize&#61;12&#41;
yticks&#40;10:10:50, fontsize&#61;12&#41;
ylabel&#40;&quot;MPG&quot;, fontsize&#61;14&#41;</code></pre>
<img src="/DataScienceTutorials.jl/assets/isl/lab-5/code/output/ISL-lab-5-g3.svg" alt="1st, 2nd and 3d order fit">
<h2 id="k-folds_cross_validation"><a href="#k-folds_cross_validation" class="header-anchor">K-Folds Cross Validation</a></h2>
<p>Let&#39;s crossvalidate over the degree of the  polynomial.</p>
<p><strong>Note</strong>: there&#39;s a  bit of gymnastics here because MLJ doesn&#39;t directly support a polynomial regression; see our tutorial on <a href="/DataScienceTutorials.jl/getting-started/model-tuning/">tuning models</a> for a gentler introduction to model tuning. The gist of the following code is to create a dataframe where each column is a power of the <code>Horsepower</code> feature from 1 to 10 and we build a series of regression models using incrementally more of those features &#40;higher degree&#41;:</p>
<pre><code class="language-julia">Xhp &#61; DataFrame&#40;&#91;hp.^i for i in 1:10&#93;, :auto&#41;

cases &#61; &#91;&#91;Symbol&#40;&quot;x&#36;j&quot;&#41; for j in 1:i&#93; for i in 1:10&#93;
r &#61; range&#40;LinMod, :&#40;feature_selector.features&#41;, values&#61;cases&#41;

tm &#61; TunedModel&#40;model&#61;LinMod, ranges&#61;r, resampling&#61;CV&#40;nfolds&#61;10&#41;, measure&#61;rms&#41;</code></pre><pre><code class="plaintext code-output">DeterministicTunedModel(
    model = Pipeline323(
            feature_selector = FeatureSelector @622,
            linear_regressor = LinearRegressor @638),
    tuning = Grid(
            goal = nothing,
            resolution = 10,
            shuffle = true,
            rng = Random._GLOBAL_RNG()),
    resampling = CV(
            nfolds = 10,
            shuffle = false,
            rng = Random._GLOBAL_RNG()),
    measure = RootMeanSquaredError(),
    weights = nothing,
    operation = MLJModelInterface.predict,
    range = NominalRange(
            field = :(feature_selector.features),
            values = ([:x1], [:x1, :x2], [:x1, :x2, :x3], [:x1, :x2, :x3, :x4], [:x1, :x2, :x3, :x4, :x5], [:x1, :x2, :x3, :x4, :x5, :x6], [:x1, :x2, :x3, :x4, :x5, :x6, :x7], [:x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8], [:x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9], [:x1, :x2, :x3, :x4, :x5, :x6, :x7, :x8, :x9, :x10])),
    selection_heuristic = MLJTuning.NaiveSelection(nothing),
    train_best = true,
    repeats = 1,
    n = nothing,
    acceleration = ComputationalResources.CPU1{Nothing}(nothing),
    acceleration_resampling = ComputationalResources.CPU1{Nothing}(nothing),
    check_measure = true,
    cache = true) @313</code></pre>
<p>Now we&#39;re left with fitting the tuned model</p>
<pre><code class="language-julia">mtm &#61; machine&#40;tm, Xhp, y&#41;
fit&#33;&#40;mtm&#41;
rep &#61; report&#40;mtm&#41;

res &#61; rep.plotting

@show round.&#40;res.measurements.^2, digits&#61;2&#41;
@show argmin&#40;res.measurements&#41;</code></pre><pre><code class="plaintext code-output">round.(res.measurements .^ 2, digits = 2) = [25.66, 21.35, 223.98, 88.61, 20.96, 20.91, 27.44, 20.91, 21.34, 21.24]
argmin(res.measurements) = 8
</code></pre>
<p>So the conclusion here is that the 5th order polynomial does quite well.</p>
<p>In ISL they use a different seed so the results are a bit different but comparable.</p>
<pre><code class="language-julia">Xnew &#61; DataFrame&#40;&#91;hpn.^i for i in 1:10&#93;, :auto&#41;
yy5 &#61; MLJ.predict&#40;mtm, Xnew&#41;

figure&#40;figsize&#61;&#40;8,6&#41;&#41;
plot&#40;X.Horsepower, y, ls&#61;&quot;none&quot;, marker&#61;&quot;o&quot;&#41;
plot&#40;xx.Horsepower, yy5, lw&#61;3&#41;

xlabel&#40;&quot;Horsepower&quot;, fontsize&#61;14&#41;
xticks&#40;50:50:250, fontsize&#61;12&#41;
yticks&#40;10:10:50, fontsize&#61;12&#41;
ylabel&#40;&quot;MPG&quot;, fontsize&#61;14&#41;</code></pre>
<img src="/DataScienceTutorials.jl/assets/isl/lab-5/code/output/ISL-lab-5-g4.svg" alt="5th order fit">
<h2 id="the_bootstrap"><a href="#the_bootstrap" class="header-anchor">The Bootstrap</a></h2>
<p><em>Bootstrapping is not currently supported in MLJ.</em></p>


<div class="page-foot">
  <div class="copyright">
    &copy; Thibaut Lienart, Anthony Blaom, Sebastian Vollmer and collaborators. Last modified: August 09, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
      </div> <!-- end of id=main -->
  </div> <!-- end of id=layout -->
  <script src="/DataScienceTutorials.jl/libs/pure/ui.min.js"></script>
  
  
      <script src="/DataScienceTutorials.jl/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

  
</body>
</html>
